{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630303e2-1c93-4b37-b037-f505bc06e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from LTSF_LinearModel_lib import LTSF_FF_DLinear\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "# 调用BTC爬取部分\n",
    "import sys\n",
    "sys.path.append(\"L:/Python_WorkSpace/量化交易/\")  # 增加指定的绝对路径,进入系统路径,从而便于该目录下的库调用\n",
    "\n",
    "from BTCCrawl_To_DataFrame_Class import BTC_data_acquire as BTC\n",
    "from BTCCrawl_To_DataFrame_Class import get_api_key\n",
    "Folder_base = \"L:/Python_WorkSpace/量化交易/data/\"\n",
    "config_file_path = \"L:/Python_WorkSpace/量化交易/BTCCrawl_To_DataFrame_Class_config.ini\"\n",
    "# URL = \"https://api.coincap.io/v2/candles?exchange=binance&interval=h12&baseId=bitcoin&quoteId=tether\"\n",
    "URL = 'https://data.binance.com'\n",
    "StartDate = \"2023-01-20\"\n",
    "EndDate = \"2023-06-01\"\n",
    "BTC_json = \"BTC_h12.json\"\n",
    "BinanceBTC_json = \"BinanceBTC_h12.json\"\n",
    "\n",
    "api_key, api_secret = get_api_key(config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d0976b-ad5b-4638-b50e-93e4079d0175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binance Rest API 联通测试通过 !\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4010 entries, 2017-08-17 00:00:00+00:00 to 2023-02-12 00:00:00+00:00\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   open        4010 non-null   float32\n",
      " 1   high        4010 non-null   float32\n",
      " 2   low         4010 non-null   float32\n",
      " 3   close       4010 non-null   float32\n",
      " 4   volume      4010 non-null   float32\n",
      " 5   amount      4010 non-null   float32\n",
      " 6   num_trades  4010 non-null   float32\n",
      " 7   bid_volume  4010 non-null   float32\n",
      " 8   bid_amount  4010 non-null   float32\n",
      "dtypes: float32(9)\n",
      "memory usage: 172.3 KB\n",
      "从web中读出Data.info:None\n",
      "BTC数据合并存入:L:/Python_WorkSpace/量化交易/data/BinanceBTC_h12.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return</th>\n",
       "      <th>Roll_price_sma</th>\n",
       "      <th>Roll_price_min</th>\n",
       "      <th>Roll_price_max</th>\n",
       "      <th>Roll_return_mom</th>\n",
       "      <th>Roll_return_std</th>\n",
       "      <th>Mark_return</th>\n",
       "      <th>d_amplitude</th>\n",
       "      <th>volume</th>\n",
       "      <th>RSI_7</th>\n",
       "      <th>...</th>\n",
       "      <th>high_pre_close</th>\n",
       "      <th>low_pre_close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>amount</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>bid_volume</th>\n",
       "      <th>bid_amount</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3.976000e+03</td>\n",
       "      <td>3.976000e+03</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>3.976000e+03</td>\n",
       "      <td>3976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>19541.125348</td>\n",
       "      <td>18061.179725</td>\n",
       "      <td>21032.234847</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>0.523893</td>\n",
       "      <td>821.129517</td>\n",
       "      <td>36486.792969</td>\n",
       "      <td>51.640326</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019581</td>\n",
       "      <td>0.978850</td>\n",
       "      <td>19965.597656</td>\n",
       "      <td>19144.466797</td>\n",
       "      <td>19579.283203</td>\n",
       "      <td>7.800264e+08</td>\n",
       "      <td>6.750193e+05</td>\n",
       "      <td>18156.019531</td>\n",
       "      <td>3.863516e+08</td>\n",
       "      <td>19583.675781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.028543</td>\n",
       "      <td>16536.831112</td>\n",
       "      <td>15318.934098</td>\n",
       "      <td>17786.330959</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.499492</td>\n",
       "      <td>1001.359863</td>\n",
       "      <td>40455.117188</td>\n",
       "      <td>13.918065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022319</td>\n",
       "      <td>0.025512</td>\n",
       "      <td>16899.117188</td>\n",
       "      <td>16199.884766</td>\n",
       "      <td>16571.466797</td>\n",
       "      <td>9.815116e+08</td>\n",
       "      <td>9.080070e+05</td>\n",
       "      <td>20064.328125</td>\n",
       "      <td>4.856156e+08</td>\n",
       "      <td>16569.845703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.268357</td>\n",
       "      <td>3359.310486</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>3504.770020</td>\n",
       "      <td>-0.034640</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.820068</td>\n",
       "      <td>127.036331</td>\n",
       "      <td>10.604572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998651</td>\n",
       "      <td>0.699475</td>\n",
       "      <td>3249.000000</td>\n",
       "      <td>2817.000000</td>\n",
       "      <td>2870.899902</td>\n",
       "      <td>5.881363e+05</td>\n",
       "      <td>1.007000e+03</td>\n",
       "      <td>55.618614</td>\n",
       "      <td>2.577815e+05</td>\n",
       "      <td>2919.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.010005</td>\n",
       "      <td>7374.639923</td>\n",
       "      <td>6764.990234</td>\n",
       "      <td>8065.020020</td>\n",
       "      <td>-0.003078</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>194.997070</td>\n",
       "      <td>14827.649414</td>\n",
       "      <td>41.869966</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005812</td>\n",
       "      <td>0.973613</td>\n",
       "      <td>7548.954956</td>\n",
       "      <td>7282.042480</td>\n",
       "      <td>7402.797485</td>\n",
       "      <td>1.238645e+08</td>\n",
       "      <td>1.290382e+05</td>\n",
       "      <td>7601.138306</td>\n",
       "      <td>6.444989e+07</td>\n",
       "      <td>7403.602417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000775</td>\n",
       "      <td>10719.675488</td>\n",
       "      <td>9982.990234</td>\n",
       "      <td>11615.990234</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.022944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>416.659912</td>\n",
       "      <td>23725.975586</td>\n",
       "      <td>50.560679</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012631</td>\n",
       "      <td>0.986620</td>\n",
       "      <td>11077.854980</td>\n",
       "      <td>10600.650391</td>\n",
       "      <td>10872.345215</td>\n",
       "      <td>3.016264e+08</td>\n",
       "      <td>3.370070e+05</td>\n",
       "      <td>11896.850098</td>\n",
       "      <td>1.518339e+08</td>\n",
       "      <td>10877.780273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.012192</td>\n",
       "      <td>30520.438672</td>\n",
       "      <td>28715.320312</td>\n",
       "      <td>34093.333984</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.030934</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1143.797852</td>\n",
       "      <td>40278.950195</td>\n",
       "      <td>61.092960</td>\n",
       "      <td>...</td>\n",
       "      <td>1.025454</td>\n",
       "      <td>0.993806</td>\n",
       "      <td>31492.399902</td>\n",
       "      <td>29733.147949</td>\n",
       "      <td>30498.408203</td>\n",
       "      <td>1.182536e+09</td>\n",
       "      <td>7.993725e+05</td>\n",
       "      <td>19821.087891</td>\n",
       "      <td>5.830874e+08</td>\n",
       "      <td>30499.227051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.237092</td>\n",
       "      <td>64595.437500</td>\n",
       "      <td>60574.488281</td>\n",
       "      <td>67594.976562</td>\n",
       "      <td>0.027119</td>\n",
       "      <td>0.104382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11858.800781</td>\n",
       "      <td>474581.750000</td>\n",
       "      <td>94.898909</td>\n",
       "      <td>...</td>\n",
       "      <td>1.321000</td>\n",
       "      <td>1.000920</td>\n",
       "      <td>69000.000000</td>\n",
       "      <td>67015.203125</td>\n",
       "      <td>67594.976562</td>\n",
       "      <td>9.054959e+09</td>\n",
       "      <td>8.848036e+06</td>\n",
       "      <td>235625.812500</td>\n",
       "      <td>4.496810e+09</td>\n",
       "      <td>67594.976562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        log_return  Roll_price_sma  Roll_price_min  Roll_price_max  \\\n",
       "count  3976.000000     3976.000000     3976.000000     3976.000000   \n",
       "mean      0.000399    19541.125348    18061.179725    21032.234847   \n",
       "std       0.028543    16536.831112    15318.934098    17786.330959   \n",
       "min      -0.268357     3359.310486     2919.000000     3504.770020   \n",
       "25%      -0.010005     7374.639923     6764.990234     8065.020020   \n",
       "50%       0.000775    10719.675488     9982.990234    11615.990234   \n",
       "75%       0.012192    30520.438672    28715.320312    34093.333984   \n",
       "max       0.237092    64595.437500    60574.488281    67594.976562   \n",
       "\n",
       "       Roll_return_mom  Roll_return_std  Mark_return   d_amplitude  \\\n",
       "count      3976.000000      3976.000000  3976.000000   3976.000000   \n",
       "mean          0.000410         0.025323     0.523893    821.129517   \n",
       "std           0.006591         0.013094     0.499492   1001.359863   \n",
       "min          -0.034640         0.003899     0.000000     17.820068   \n",
       "25%          -0.003078         0.016594     0.000000    194.997070   \n",
       "50%           0.000477         0.022944     1.000000    416.659912   \n",
       "75%           0.004005         0.030934     1.000000   1143.797852   \n",
       "max           0.027119         0.104382     1.000000  11858.800781   \n",
       "\n",
       "              volume        RSI_7  ...  high_pre_close  low_pre_close  \\\n",
       "count    3976.000000  3976.000000  ...     3976.000000    3976.000000   \n",
       "mean    36486.792969    51.640326  ...        1.019581       0.978850   \n",
       "std     40455.117188    13.918065  ...        0.022319       0.025512   \n",
       "min       127.036331    10.604572  ...        0.998651       0.699475   \n",
       "25%     14827.649414    41.869966  ...        1.005812       0.973613   \n",
       "50%     23725.975586    50.560679  ...        1.012631       0.986620   \n",
       "75%     40278.950195    61.092960  ...        1.025454       0.993806   \n",
       "max    474581.750000    94.898909  ...        1.321000       1.000920   \n",
       "\n",
       "               high           low          open        amount    num_trades  \\\n",
       "count   3976.000000   3976.000000   3976.000000  3.976000e+03  3.976000e+03   \n",
       "mean   19965.597656  19144.466797  19579.283203  7.800264e+08  6.750193e+05   \n",
       "std    16899.117188  16199.884766  16571.466797  9.815116e+08  9.080070e+05   \n",
       "min     3249.000000   2817.000000   2870.899902  5.881363e+05  1.007000e+03   \n",
       "25%     7548.954956   7282.042480   7402.797485  1.238645e+08  1.290382e+05   \n",
       "50%    11077.854980  10600.650391  10872.345215  3.016264e+08  3.370070e+05   \n",
       "75%    31492.399902  29733.147949  30498.408203  1.182536e+09  7.993725e+05   \n",
       "max    69000.000000  67015.203125  67594.976562  9.054959e+09  8.848036e+06   \n",
       "\n",
       "          bid_volume    bid_amount         close  \n",
       "count    3976.000000  3.976000e+03   3976.000000  \n",
       "mean    18156.019531  3.863516e+08  19583.675781  \n",
       "std     20064.328125  4.856156e+08  16569.845703  \n",
       "min        55.618614  2.577815e+05   2919.000000  \n",
       "25%      7601.138306  6.444989e+07   7403.602417  \n",
       "50%     11896.850098  1.518339e+08  10877.780273  \n",
       "75%     19821.087891  5.830874e+08  30499.227051  \n",
       "max    235625.812500  4.496810e+09  67594.976562  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return</th>\n",
       "      <th>Roll_price_sma</th>\n",
       "      <th>Roll_price_min</th>\n",
       "      <th>Roll_price_max</th>\n",
       "      <th>Roll_return_mom</th>\n",
       "      <th>Roll_return_std</th>\n",
       "      <th>Mark_return</th>\n",
       "      <th>d_amplitude</th>\n",
       "      <th>volume</th>\n",
       "      <th>RSI_7</th>\n",
       "      <th>...</th>\n",
       "      <th>high_pre_close</th>\n",
       "      <th>low_pre_close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>amount</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>bid_volume</th>\n",
       "      <th>bid_amount</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-03 08:00:00+08:00</th>\n",
       "      <td>0.003094</td>\n",
       "      <td>4475.064014</td>\n",
       "      <td>4280.680176</td>\n",
       "      <td>4834.910156</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.021080</td>\n",
       "      <td>1</td>\n",
       "      <td>257.959961</td>\n",
       "      <td>335.535156</td>\n",
       "      <td>57.173478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054251</td>\n",
       "      <td>0.996570</td>\n",
       "      <td>4714.759766</td>\n",
       "      <td>4456.799805</td>\n",
       "      <td>4508.50000</td>\n",
       "      <td>1541936.75</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>123.085823</td>\n",
       "      <td>565981.3750</td>\n",
       "      <td>4486.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-03 20:00:00+08:00</th>\n",
       "      <td>0.005132</td>\n",
       "      <td>4484.717529</td>\n",
       "      <td>4280.680176</td>\n",
       "      <td>4834.910156</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>1</td>\n",
       "      <td>285.509766</td>\n",
       "      <td>355.681030</td>\n",
       "      <td>58.092390</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021810</td>\n",
       "      <td>0.958165</td>\n",
       "      <td>4583.839844</td>\n",
       "      <td>4298.330078</td>\n",
       "      <td>4475.22998</td>\n",
       "      <td>1579116.00</td>\n",
       "      <td>3031.0</td>\n",
       "      <td>135.848709</td>\n",
       "      <td>603663.3125</td>\n",
       "      <td>4509.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           log_return  Roll_price_sma  Roll_price_min  \\\n",
       "2017-09-03 08:00:00+08:00    0.003094     4475.064014     4280.680176   \n",
       "2017-09-03 20:00:00+08:00    0.005132     4484.717529     4280.680176   \n",
       "\n",
       "                           Roll_price_max  Roll_return_mom  Roll_return_std  \\\n",
       "2017-09-03 08:00:00+08:00     4834.910156         0.003270         0.021080   \n",
       "2017-09-03 20:00:00+08:00     4834.910156         0.002188         0.020353   \n",
       "\n",
       "                           Mark_return  d_amplitude      volume      RSI_7  \\\n",
       "2017-09-03 08:00:00+08:00            1   257.959961  335.535156  57.173478   \n",
       "2017-09-03 20:00:00+08:00            1   285.509766  355.681030  58.092390   \n",
       "\n",
       "                           ...  high_pre_close  low_pre_close         high  \\\n",
       "2017-09-03 08:00:00+08:00  ...        1.054251       0.996570  4714.759766   \n",
       "2017-09-03 20:00:00+08:00  ...        1.021810       0.958165  4583.839844   \n",
       "\n",
       "                                   low        open      amount  num_trades  \\\n",
       "2017-09-03 08:00:00+08:00  4456.799805  4508.50000  1541936.75      2991.0   \n",
       "2017-09-03 20:00:00+08:00  4298.330078  4475.22998  1579116.00      3031.0   \n",
       "\n",
       "                           bid_volume   bid_amount        close  \n",
       "2017-09-03 08:00:00+08:00  123.085823  565981.3750  4486.000000  \n",
       "2017-09-03 20:00:00+08:00  135.848709  603663.3125  4509.080078  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return</th>\n",
       "      <th>Roll_price_sma</th>\n",
       "      <th>Roll_price_min</th>\n",
       "      <th>Roll_price_max</th>\n",
       "      <th>Roll_return_mom</th>\n",
       "      <th>Roll_return_std</th>\n",
       "      <th>Mark_return</th>\n",
       "      <th>d_amplitude</th>\n",
       "      <th>volume</th>\n",
       "      <th>RSI_7</th>\n",
       "      <th>...</th>\n",
       "      <th>high_pre_close</th>\n",
       "      <th>low_pre_close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>amount</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>bid_volume</th>\n",
       "      <th>bid_amount</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-11 20:00:00+08:00</th>\n",
       "      <td>0.007581</td>\n",
       "      <td>22831.833008</td>\n",
       "      <td>21625.189453</td>\n",
       "      <td>23820.490234</td>\n",
       "      <td>-0.004104</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1</td>\n",
       "      <td>288.089844</td>\n",
       "      <td>90819.921875</td>\n",
       "      <td>36.903702</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009627</td>\n",
       "      <td>0.996349</td>\n",
       "      <td>21906.320312</td>\n",
       "      <td>21618.230469</td>\n",
       "      <td>21697.439453</td>\n",
       "      <td>1.973814e+09</td>\n",
       "      <td>2058634.0</td>\n",
       "      <td>45232.675781</td>\n",
       "      <td>983094976.0</td>\n",
       "      <td>21862.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-12 08:00:00+08:00</th>\n",
       "      <td>-0.002223</td>\n",
       "      <td>22731.508984</td>\n",
       "      <td>21625.189453</td>\n",
       "      <td>23534.130859</td>\n",
       "      <td>-0.004400</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0</td>\n",
       "      <td>104.990234</td>\n",
       "      <td>11278.625000</td>\n",
       "      <td>36.245423</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001263</td>\n",
       "      <td>0.996461</td>\n",
       "      <td>21890.160156</td>\n",
       "      <td>21785.169922</td>\n",
       "      <td>21862.019531</td>\n",
       "      <td>2.462188e+08</td>\n",
       "      <td>268911.0</td>\n",
       "      <td>5656.451172</td>\n",
       "      <td>123486984.0</td>\n",
       "      <td>21814.009766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           log_return  Roll_price_sma  Roll_price_min  \\\n",
       "2023-02-11 20:00:00+08:00    0.007581    22831.833008    21625.189453   \n",
       "2023-02-12 08:00:00+08:00   -0.002223    22731.508984    21625.189453   \n",
       "\n",
       "                           Roll_price_max  Roll_return_mom  Roll_return_std  \\\n",
       "2023-02-11 20:00:00+08:00    23820.490234        -0.004104         0.011300   \n",
       "2023-02-12 08:00:00+08:00    23534.130859        -0.004400         0.011162   \n",
       "\n",
       "                           Mark_return  d_amplitude        volume      RSI_7  \\\n",
       "2023-02-11 20:00:00+08:00            1   288.089844  90819.921875  36.903702   \n",
       "2023-02-12 08:00:00+08:00            0   104.990234  11278.625000  36.245423   \n",
       "\n",
       "                           ...  high_pre_close  low_pre_close          high  \\\n",
       "2023-02-11 20:00:00+08:00  ...        1.009627       0.996349  21906.320312   \n",
       "2023-02-12 08:00:00+08:00  ...        1.001263       0.996461  21890.160156   \n",
       "\n",
       "                                    low          open        amount  \\\n",
       "2023-02-11 20:00:00+08:00  21618.230469  21697.439453  1.973814e+09   \n",
       "2023-02-12 08:00:00+08:00  21785.169922  21862.019531  2.462188e+08   \n",
       "\n",
       "                           num_trades    bid_volume   bid_amount         close  \n",
       "2023-02-11 20:00:00+08:00   2058634.0  45232.675781  983094976.0  21862.550781  \n",
       "2023-02-12 08:00:00+08:00    268911.0   5656.451172  123486984.0  21814.009766  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "data.shape=(3976, 24)\n",
      "最后两行数据:\n",
      "[[0.54592667 0.31799076 0.32444768 0.31698634 0.49443445 0.07365666\n",
      "  1.         0.02282495 0.19115183 0.31199166 0.48330384 0.02611499\n",
      "  0.4705972  0.66961518 0.03404881 0.98483631 0.28375721 0.29286225\n",
      "  0.29087382 0.21793079 0.2325783  0.19177748 0.21857571 0.29289937]\n",
      " [0.52653072 0.31635244 0.32444768 0.31251828 0.48964423 0.07228042\n",
      "  0.         0.00736174 0.02350401 0.30418237 0.49038606 0.00543106\n",
      "  0.4831737  0.66862696 0.00810152 0.98520508 0.28351143 0.29546263\n",
      "  0.29341662 0.02712841 0.0302818  0.02377564 0.02740526 0.29214883]]\n"
     ]
    }
   ],
   "source": [
    "BTC_data = BTC(URL, StartDate, EndDate, Folder_base, BTC_json,\n",
    "               binance_api_key=api_key, binance_api_secret=api_secret)\n",
    "data0 = BTC_data.MarketFactor_ClosePriceFeatures(by_BinanceAPI=True,\n",
    "    FromWeb=True,close_colName='close',lags=0,window=20,DayH=2, MarketFactor=True, weekdays=7,)\n",
    "# data0[\"year\"] = (\n",
    "#     data0[\"year\"] - 2016\n",
    "# )  # 因为数据从2016年开始,减去2016,将年份变成0以上的整数,以使得Embedding词汇表范围缩小\n",
    "\n",
    "\n",
    "def dataset_Scaler(data):\n",
    "    # 将原始数据MinMax归一化,以提高特征辨识度; 注意:要小心,重复归一化,可能会导致数据变小\n",
    "    # 将close_price单独归一化,因为后面需要将close_price预测出后,还原\n",
    "    X_Scaler = MinMaxScaler()\n",
    "    y_Scaler = MinMaxScaler()\n",
    "\n",
    "    X_ds = X_Scaler.fit_transform(\n",
    "        data[data.columns[:-1]]\n",
    "    )  # 本是DataFrame的类型,经过转换,X变成了ndarray类型;\n",
    "    y_ds = y_Scaler.fit_transform(\n",
    "        data[\"close\"].to_numpy().reshape(-1, 1)\n",
    "    )  # y为series,标准化需要(-1,1)的shape\n",
    "    data = np.c_[X_ds, y_ds]\n",
    "\n",
    "    return data, X_Scaler, y_Scaler\n",
    "\n",
    "\n",
    "data, X_Scaler, y_Scaler = dataset_Scaler(data0)\n",
    "print(type(data))\n",
    "print(\"data.shape={}\".format(data.shape))\n",
    "print(\"最后两行数据:\\n{}\".format(data[-2:, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c3d1c2-948d-4cb0-bf61-ab8addca5a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data共有样本:3976;train/val分隔split:3161\n",
      "dataset_train元组长度:2\n",
      "dataset_train中xs.shape:(32, 208, 24)\n",
      "dataset_train中ys.shape:(32, 7, 1)\n",
      "--------------------------------------------------\n",
      "dataset_val元组长度:2\n",
      "dataset_val中xs.shape:(32, 208, 24)\n",
      "dataset_val中ys.shape:(32, 7, 1)\n",
      "--------------------------------------------------\n",
      "dataset_predict数据.shape:(32, 208, 24),从2021-11-13 20:00:00+08:00开始,共有22组*64个数据\n"
     ]
    }
   ],
   "source": [
    "# best hyperparameter-----\n",
    "Batch_size = 32\n",
    "kernel_size = 47\n",
    "L_seq = 208\n",
    "individual = (False,)\n",
    "L_pred = 7\n",
    "out_features = 1\n",
    "in_features = data.shape[1]\n",
    "\n",
    "\n",
    "def gen(data):\n",
    "    for i in range(data.shape[0]):\n",
    "        yield data[i, :]\n",
    "\n",
    "\n",
    "def xs_ys_dataset(\n",
    "    data,\n",
    "    L_seq,\n",
    "    L_pred,\n",
    "    Batch_size,\n",
    "    out_features=1,\n",
    "    shuffle=False,\n",
    "    buffer_size=10000,\n",
    "):\n",
    "    \"\"\"\n",
    "    生产xs与ys合并一起的dataset,样本总长度:L_seq+L_pred.\n",
    "    args:\n",
    "        data: Dataframe格式的数据(B,in_features);\n",
    "        L_seq: Linear模型输入的时序长度;\n",
    "        L_pred: Linear模型输出的预测时序长度;\n",
    "        out_features: target输出时的特征数,缺省=1,只取收盘价格\n",
    "        Batch_size:\n",
    "        shuffle: bool ; 是否shuffle\n",
    "    out:\n",
    "        (xs,ys): (input, target) ((B,L_seq,features),(B,L_pred,out_features))\n",
    "\n",
    "    \"\"\"\n",
    "    output_signature = tf.TensorSpec((in_features), tf.float64)  # 14列\n",
    "    # gen_f = gen(data)\n",
    "    x_y = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=output_signature,\n",
    "        args=(data,),\n",
    "    )  # args用于给gen传递参数,必须是元组的形式传入参数;\n",
    "    # x_y = tf.data.Dataset.from_tensor_slices(data)\n",
    "    x_y = x_y.window(L_seq + L_pred, shift=1, drop_remainder=True)\n",
    "    x_y = x_y.flat_map(lambda w: w.batch(L_seq + L_pred, drop_remainder=True))\n",
    "    xs = x_y.map(lambda w: w[:L_seq, :])  # 时序L_seq;in_features中,不包含时间戳部分;\n",
    "    ys = x_y.map(\n",
    "        lambda w: w[L_seq:, (out_features * -1):]\n",
    "    )  # 时序L_pred部分;in_features中,不包含时间戳部分;作为Target标签,这里只取最后的收盘价格,shape(B,L,1)\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((xs, ys))\n",
    "    if shuffle == True:\n",
    "        dataset.shuffle(buffer_size)\n",
    "\n",
    "    return dataset.batch(Batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "\n",
    "def xs_dataset(data, L_seq, Batch_size, shuffle=False, buffer_size=10000,):\n",
    "    \"\"\"\n",
    "    仅生产xs的dataset,不包含标签;dataset时序长度:L_seq\n",
    "    args:\n",
    "        data: Dataframe格式的数据(B,in_features);\n",
    "        L_seq: Linear模型输入的时序长度;\n",
    "        Batch_size:\n",
    "        shuffle: bool ; 是否shuffle\n",
    "    out:\n",
    "        xs: input (B,L_seq,features)\n",
    "    \"\"\"\n",
    "    output_signature = tf.TensorSpec((in_features), tf.float64)  # 14列\n",
    "    # gen_f = gen(data)\n",
    "    xs = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=output_signature,\n",
    "        args=(data,),\n",
    "    )  # args用于给gen传递参数,必须是元组的形式传入参数;\n",
    "    # xs = tf.data.Dataset.from_tensor_slices(data)\n",
    "    xs = xs.window(L_seq, shift=1, drop_remainder=True)\n",
    "    xs = xs.flat_map(lambda w: w.batch(L_seq, drop_remainder=True))\n",
    "\n",
    "    if shuffle == True:\n",
    "        xs.shuffle(buffer_size)\n",
    "\n",
    "    return xs.batch(Batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "\n",
    "# 以2022-01-01:00为起点分隔train,valid\n",
    "# split = int(data.shape[0] * 0.8)\n",
    "split = np.argwhere(data0.index==pd.Timestamp('2022-01-01',tz='UTC'))[0,0]\n",
    "# split = 2 # 为调试使用,缩短运行时间\n",
    "print(\"data共有样本:{};train/val分隔split:{}\".format(data.shape[0], split))\n",
    "\n",
    "dataset_train = xs_ys_dataset(\n",
    "    data[:split, :],\n",
    "    L_seq,\n",
    "    L_pred,\n",
    "    Batch_size,\n",
    "    out_features,\n",
    "    shuffle=True,\n",
    "    buffer_size=10000,\n",
    ")\n",
    "print(\"dataset_train元组长度:{}\".format(len(iter(dataset_train).next())))\n",
    "print(\"dataset_train中xs.shape:{}\".format(iter(dataset_train).next()[0].shape))\n",
    "print(\"dataset_train中ys.shape:{}\".format(iter(dataset_train).next()[1].shape))\n",
    "print('{}'.format(50*'-'))\n",
    "\n",
    "dataset_val = xs_ys_dataset(\n",
    "    data[split:, :],\n",
    "    L_seq,\n",
    "    L_pred,\n",
    "    Batch_size,\n",
    "    shuffle=True,\n",
    "    buffer_size=10000,\n",
    ")\n",
    "\n",
    "dataset_all = xs_ys_dataset(data, L_seq, L_pred, Batch_size,\n",
    "                            shuffle=True, buffer_size=10000,)\n",
    "print(\"dataset_val元组长度:{}\".format(len(iter(dataset_val).next())))\n",
    "print(\"dataset_val中xs.shape:{}\".format(iter(dataset_val).next()[0].shape))\n",
    "print(\"dataset_val中ys.shape:{}\".format(iter(dataset_val).next()[1].shape))\n",
    "print('{}'.format(50*'-'))\n",
    "\n",
    "# 为了batch后数据成batch不丢弃,创造n个batch(n*64),即n个batch,每个batch=Batch_size;使得总样本数在1年附近;\n",
    "# 最后一个batch时间是倒数L_seq天;第一个batch是倒数:5*Batch_size+L_seq序列开始:\n",
    "Batch_num = 365*2//Batch_size  # 1年除Batch_size,获得batch的数量;\n",
    "r_split = Batch_num*Batch_size+L_seq\n",
    "dataset_predict = xs_dataset(data[-r_split:, :], L_seq,\n",
    "                             Batch_size, shuffle=True, buffer_size=10000,)\n",
    "print('dataset_predict数据.shape:{},从{}开始,共有{}组*64个数据'.format(\n",
    "    iter(dataset_predict).next().shape, data0.index[-r_split], len(list(iter(dataset_predict)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a12f9dd1-abcf-4d64-b51f-37544b5d1c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230212\n"
     ]
    }
   ],
   "source": [
    "today_date = pd.Timestamp.today().strftime('%y%m%d')\n",
    "print(today_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcaa1e1b-2a1e-44e0-a2c8-1773ef95a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型:\n",
    "DLinear = LTSF_FF_DLinear(\n",
    "    seq_len=L_seq,\n",
    "    pred_len=L_pred,\n",
    "    channels=in_features,\n",
    "    kernel_size=kernel_size,\n",
    "    \n",
    ")\n",
    "\n",
    "# 1) 自定义loss,metrics:\n",
    "#  loss:\n",
    "loss_object = tf.keras.losses.MeanAbsoluteError(\n",
    "    reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
    ")  # 求和\n",
    "\n",
    "#  metric\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "train_MSE = tf.keras.metrics.MeanSquaredError(name=\"train_MSE\")\n",
    "val_MSE = tf.keras.metrics.MeanSquaredError(name=\"val_MSE\")\n",
    "\n",
    "# 2) 自定义learning_rate,从而自定义optimizer:\n",
    "# 自定义 learning_rate\n",
    "def dict_compare(\n",
    "    initial, lr_dict, step\n",
    "):  # 因为If等python语句不能在Tensorflow中转化成Graph,这里用py_function包装\n",
    "    \"\"\"\n",
    "    用于从lr列表中,提取与训练step相对应的lr\n",
    "    \"\"\"\n",
    "    lr = initial\n",
    "    index = tf.where(lr_dict[:, 0] <= step)  # 找到最接近step的index\n",
    "    if index.numpy().size != 0:\n",
    "        lr = lr_dict[:, 1].numpy()[max(index).numpy()]  # ndary shape:(1,)\n",
    "        lr = lr[0]\n",
    "    return lr\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):  # 定义Schedule类\n",
    "    def __init__(self, initial):  # 不能添加**kwargs;与自定义layer层不一样;\n",
    "        \"\"\"\n",
    "        args:\n",
    "            initial: learning_rate initial value, 5e-3 for example\n",
    "        \"\"\"\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.initial = initial\n",
    "        self.lr_dict = tf.convert_to_tensor(\n",
    "            (\n",
    "                (2, initial),\n",
    "                (4, initial / 5),\n",
    "                (6, initial / 10),\n",
    "                (8, initial / 50),\n",
    "                (10, initial / 100),\n",
    "                (15, initial / 500),\n",
    "                (20, initial / 1000),\n",
    "                #                 (80, initial / 5000),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __call__(self, step):\n",
    "        lr = tf.py_function(\n",
    "            dict_compare, inp=[self.initial, self.lr_dict, step], Tout=tf.float32\n",
    "        )  # py_function包装python函数\n",
    "        return lr\n",
    "\n",
    "\n",
    "lr = CustomSchedule(5e-03)  # build lr类;\n",
    "\n",
    "# for step in [2,4,6,8,10,15,20]:\n",
    "#     print(lr(step),end=',')\n",
    "\n",
    "# optimizer:\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# 3) 自定义Callbacks:\n",
    "\n",
    "\n",
    "# 非Keras方法,直接设立checkpoint;\n",
    "checkpoint_path = \"./checkpoint\"\n",
    "ckpt = tf.train.Checkpoint(DLinear=DLinear, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    ckpt,\n",
    "    checkpoint_path,\n",
    "    max_to_keep=1,\n",
    "    checkpoint_name=\"CusomModel_F20_{}\".format(today_date),\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.CallbackList(\n",
    "    callbacks=[], add_history=True, add_progbar=True, model=DLinear\n",
    ")  # callbacks=[]初始为空,即在训练时,出现进度条;其它callbacks使用append方法添加;\n",
    "# customcallback = CustomCallback()\n",
    "# callbacks.append(customcallback) #测试成功,没有实际意义,关闭;\n",
    "# callbacks.append(Modelcheckpoint) #keras与custom training在这点,兼容性有问题;建议采用tf.train.checkpoint方法;\n",
    "# callbacks.append(Earlystop) #keras与custom training兼容性不方便,建议直接在cutsom traning中代码实现;\n",
    "\n",
    "\n",
    "# 3) 自定义单步训练:\n",
    "@tf.function  # 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地执行。\n",
    "def train_step(dataset):  # dataset是xs与xs_timestamp合集\n",
    "    xs, ys = dataset[0], dataset[1]\n",
    "\n",
    "    # 求导,根据导数优化变量\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_ = DLinear(xs) #(batch,l_pred,1)\n",
    "        loss_value = loss_object(ys, y_)\n",
    "    gradients = tape.gradient(loss_value, DLinear.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, DLinear.trainable_variables))\n",
    "    # 计算metric: 每个单步经过batch次运算后,共batch次 loss的平均值\n",
    "    train_loss.update_state(loss_value)\n",
    "    train_MSE.update_state(ys, y_)\n",
    "    return {\"train_loss\": train_loss.result(), \"train_MSE\": train_MSE.result()}\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(dataset_val):  # validation, test 使用该单步训练\n",
    "    xs, ys = dataset_val[0], dataset_val[1]\n",
    "    y_ = DLinear(xs) #输出:(Batch,L_pred,channels)\n",
    "    loss_value = loss_object(ys, y_)\n",
    "    val_loss.update_state(loss_value)\n",
    "    val_MSE.update_state(ys, y_)\n",
    "    return {\"val_loss\": val_loss.result(), \"val_MSE\": val_MSE.result()}\n",
    "\n",
    "\n",
    "def Modelevaluation(dataset_val, training=False):  # 训练后的模型Evaluation,并输出target预测值\n",
    "    val_loss.reset_states()\n",
    "    val_MSE.reset_states()\n",
    "    target_spec = dataset_val.element_spec[1]\n",
    "    y_hat = tf.zeros(target_spec.shape, target_spec.dtype)\n",
    "    for batch_data in dataset_val:\n",
    "        xs, ys = batch_data[0], batch_data[1]\n",
    "        y_ = DLinear(xs)\n",
    "        loss_value = loss_object(ys, y_)\n",
    "        val_loss.update_state(loss_value)\n",
    "        val_MSE.update_state(ys, y_)\n",
    "        # y_hat = tf.stack([y_hat,y_.numpy()])\n",
    "        y_hat = tf.concat([y_hat, y_.numpy()], axis=0)\n",
    "    print(\n",
    "        \"training={},val_loss:{:.4f},val_MSE:{:.4f}\".format(\n",
    "            training, val_loss.result().numpy(), val_MSE.result().numpy()\n",
    "        )\n",
    "    )\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ac5fbe-2820-4054-adda-b85857fbd877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 6s 19ms/step - train_loss: 0.2525 - train_MSE: 0.1437 - val_loss: 0.4010 - val_MSE: 0.2327\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.1681 - train_MSE: 0.0732 - val_loss: 0.4007 - val_MSE: 0.2325\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1462 - train_MSE: 0.0575 - val_loss: 0.3374 - val_MSE: 0.1728\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1286 - train_MSE: 0.0457 - val_loss: 0.2860 - val_MSE: 0.1278\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1160 - train_MSE: 0.0375 - val_loss: 0.2413 - val_MSE: 0.0932\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1094 - train_MSE: 0.0324 - val_loss: 0.2045 - val_MSE: 0.0681\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1076 - train_MSE: 0.0294 - val_loss: 0.1765 - val_MSE: 0.0514\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.1079 - train_MSE: 0.0277 - val_loss: 0.1576 - val_MSE: 0.0411\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1082 - train_MSE: 0.0264 - val_loss: 0.1454 - val_MSE: 0.0350\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.1073 - train_MSE: 0.0248 - val_loss: 0.1367 - val_MSE: 0.0310\n",
      "epoch:10/1500 - 耗时:0.03分/总0.40分; train_loss 0.1466 train_MSE 0.0483; val_loss 0.1307 val_MSE 0.0283\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1082 - train_MSE: 0.0253 - val_loss: 0.1367 - val_MSE: 0.0310\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1079 - train_MSE: 0.0244 - val_loss: 0.1307 - val_MSE: 0.0283\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1073 - train_MSE: 0.0235 - val_loss: 0.1263 - val_MSE: 0.0263\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1065 - train_MSE: 0.0228 - val_loss: 0.1231 - val_MSE: 0.0248\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1056 - train_MSE: 0.0221 - val_loss: 0.1207 - val_MSE: 0.0236\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.1047 - train_MSE: 0.0214 - val_loss: 0.1191 - val_MSE: 0.0227\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1037 - train_MSE: 0.0208 - val_loss: 0.1178 - val_MSE: 0.0219\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1027 - train_MSE: 0.0203 - val_loss: 0.1166 - val_MSE: 0.0213\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1018 - train_MSE: 0.0198 - val_loss: 0.1155 - val_MSE: 0.0206\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1009 - train_MSE: 0.0193 - val_loss: 0.1146 - val_MSE: 0.0201\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0997 - train_MSE: 0.0187 - val_loss: 0.1139 - val_MSE: 0.0197\n",
      "epoch:20/1500 - 耗时:0.03分/总0.74分; train_loss 0.1261 train_MSE 0.0316; val_loss 0.1133 val_MSE 0.0194\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.1000 - train_MSE: 0.0189 - val_loss: 0.1139 - val_MSE: 0.0197\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0992 - train_MSE: 0.0185 - val_loss: 0.1133 - val_MSE: 0.0193\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0984 - train_MSE: 0.0181 - val_loss: 0.1126 - val_MSE: 0.0190\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0975 - train_MSE: 0.0178 - val_loss: 0.1119 - val_MSE: 0.0186\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0968 - train_MSE: 0.0174 - val_loss: 0.1114 - val_MSE: 0.0184\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0960 - train_MSE: 0.0171 - val_loss: 0.1109 - val_MSE: 0.0181\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0953 - train_MSE: 0.0168 - val_loss: 0.1105 - val_MSE: 0.0179\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0945 - train_MSE: 0.0165 - val_loss: 0.1102 - val_MSE: 0.0177\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0938 - train_MSE: 0.0163 - val_loss: 0.1098 - val_MSE: 0.0176\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0931 - train_MSE: 0.0160 - val_loss: 0.1095 - val_MSE: 0.0175\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0923 - train_MSE: 0.0157 - val_loss: 0.1092 - val_MSE: 0.0173\n",
      "epoch:30/1500 - 耗时:0.03分/总1.07分; train_loss 0.1148 train_MSE 0.0255; val_loss 0.1089 val_MSE 0.0172\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0925 - train_MSE: 0.0158 - val_loss: 0.1092 - val_MSE: 0.0173\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0918 - train_MSE: 0.0155 - val_loss: 0.1089 - val_MSE: 0.0172\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0912 - train_MSE: 0.0153 - val_loss: 0.1086 - val_MSE: 0.0171\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0906 - train_MSE: 0.0151 - val_loss: 0.1084 - val_MSE: 0.0170\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0900 - train_MSE: 0.0149 - val_loss: 0.1081 - val_MSE: 0.0169\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0894 - train_MSE: 0.0147 - val_loss: 0.1079 - val_MSE: 0.0168\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0888 - train_MSE: 0.0145 - val_loss: 0.1077 - val_MSE: 0.0168\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0882 - train_MSE: 0.0143 - val_loss: 0.1074 - val_MSE: 0.0167\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0876 - train_MSE: 0.0142 - val_loss: 0.1072 - val_MSE: 0.0167\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0871 - train_MSE: 0.0140 - val_loss: 0.1070 - val_MSE: 0.0166\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0863 - train_MSE: 0.0138 - val_loss: 0.1068 - val_MSE: 0.0165\n",
      "epoch:40/1500 - 耗时:0.03分/总1.41分; train_loss 0.1068 train_MSE 0.0222; val_loss 0.1065 val_MSE 0.0165\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0865 - train_MSE: 0.0138 - val_loss: 0.1068 - val_MSE: 0.0165\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0859 - train_MSE: 0.0137 - val_loss: 0.1065 - val_MSE: 0.0165\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0854 - train_MSE: 0.0135 - val_loss: 0.1063 - val_MSE: 0.0164\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0848 - train_MSE: 0.0133 - val_loss: 0.1060 - val_MSE: 0.0164\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0842 - train_MSE: 0.0132 - val_loss: 0.1058 - val_MSE: 0.0163\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0836 - train_MSE: 0.0130 - val_loss: 0.1055 - val_MSE: 0.0162\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0831 - train_MSE: 0.0129 - val_loss: 0.1052 - val_MSE: 0.0162\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0825 - train_MSE: 0.0127 - val_loss: 0.1049 - val_MSE: 0.0161\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0819 - train_MSE: 0.0126 - val_loss: 0.1047 - val_MSE: 0.0160\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0813 - train_MSE: 0.0124 - val_loss: 0.1044 - val_MSE: 0.0160\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0805 - train_MSE: 0.0122 - val_loss: 0.1041 - val_MSE: 0.0159\n",
      "epoch:50/1500 - 耗时:0.03分/总1.74分; train_loss 0.1000 train_MSE 0.0198; val_loss 0.1038 val_MSE 0.0158\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0807 - train_MSE: 0.0123 - val_loss: 0.1041 - val_MSE: 0.0159\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0802 - train_MSE: 0.0121 - val_loss: 0.1038 - val_MSE: 0.0158\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0796 - train_MSE: 0.0120 - val_loss: 0.1035 - val_MSE: 0.0158\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0790 - train_MSE: 0.0119 - val_loss: 0.1031 - val_MSE: 0.0157\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0784 - train_MSE: 0.0117 - val_loss: 0.1027 - val_MSE: 0.0156\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0778 - train_MSE: 0.0116 - val_loss: 0.1024 - val_MSE: 0.0155\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0772 - train_MSE: 0.0114 - val_loss: 0.1021 - val_MSE: 0.0154\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0766 - train_MSE: 0.0113 - val_loss: 0.1017 - val_MSE: 0.0154\n",
      "117/117 [==============================] - 2s 18ms/step - train_loss: 0.0761 - train_MSE: 0.0112 - val_loss: 0.1013 - val_MSE: 0.0153\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0755 - train_MSE: 0.0111 - val_loss: 0.1010 - val_MSE: 0.0152\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0748 - train_MSE: 0.0109 - val_loss: 0.1007 - val_MSE: 0.0151\n",
      "epoch:60/1500 - 耗时:0.03分/总2.08分; train_loss 0.0934 train_MSE 0.0178; val_loss 0.1003 val_MSE 0.0150\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0750 - train_MSE: 0.0109 - val_loss: 0.1006 - val_MSE: 0.0151\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0744 - train_MSE: 0.0108 - val_loss: 0.1003 - val_MSE: 0.0150\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0739 - train_MSE: 0.0107 - val_loss: 0.1000 - val_MSE: 0.0150\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0734 - train_MSE: 0.0106 - val_loss: 0.0997 - val_MSE: 0.0149\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0729 - train_MSE: 0.0105 - val_loss: 0.0994 - val_MSE: 0.0148\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0724 - train_MSE: 0.0104 - val_loss: 0.0991 - val_MSE: 0.0148\n",
      "117/117 [==============================] - 2s 18ms/step - train_loss: 0.0720 - train_MSE: 0.0103 - val_loss: 0.0987 - val_MSE: 0.0147\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0715 - train_MSE: 0.0102 - val_loss: 0.0983 - val_MSE: 0.0146\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0710 - train_MSE: 0.0101 - val_loss: 0.0979 - val_MSE: 0.0145\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0706 - train_MSE: 0.0099 - val_loss: 0.0976 - val_MSE: 0.0144\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0699 - train_MSE: 0.0098 - val_loss: 0.0972 - val_MSE: 0.0143\n",
      "epoch:70/1500 - 耗时:0.03分/总2.42分; train_loss 0.0877 train_MSE 0.0160; val_loss 0.0968 val_MSE 0.0142\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0702 - train_MSE: 0.0098 - val_loss: 0.0971 - val_MSE: 0.0143\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0698 - train_MSE: 0.0098 - val_loss: 0.0968 - val_MSE: 0.0142\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0694 - train_MSE: 0.0097 - val_loss: 0.0965 - val_MSE: 0.0141\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0690 - train_MSE: 0.0096 - val_loss: 0.0961 - val_MSE: 0.0141\n",
      "117/117 [==============================] - 2s 18ms/step - train_loss: 0.0686 - train_MSE: 0.0095 - val_loss: 0.0957 - val_MSE: 0.0140\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0682 - train_MSE: 0.0094 - val_loss: 0.0953 - val_MSE: 0.0139\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0678 - train_MSE: 0.0093 - val_loss: 0.0949 - val_MSE: 0.0138\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0675 - train_MSE: 0.0092 - val_loss: 0.0945 - val_MSE: 0.0137\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0671 - train_MSE: 0.0091 - val_loss: 0.0942 - val_MSE: 0.0136\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0667 - train_MSE: 0.0090 - val_loss: 0.0938 - val_MSE: 0.0135\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0662 - train_MSE: 0.0089 - val_loss: 0.0933 - val_MSE: 0.0134\n",
      "epoch:80/1500 - 耗时:0.03分/总2.76分; train_loss 0.0829 train_MSE 0.0144; val_loss 0.0929 val_MSE 0.0133\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0664 - train_MSE: 0.0089 - val_loss: 0.0933 - val_MSE: 0.0134\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0660 - train_MSE: 0.0089 - val_loss: 0.0928 - val_MSE: 0.0133\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0657 - train_MSE: 0.0088 - val_loss: 0.0924 - val_MSE: 0.0132\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0653 - train_MSE: 0.0087 - val_loss: 0.0919 - val_MSE: 0.0131\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0650 - train_MSE: 0.0086 - val_loss: 0.0914 - val_MSE: 0.0130\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0646 - train_MSE: 0.0085 - val_loss: 0.0909 - val_MSE: 0.0129\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0643 - train_MSE: 0.0084 - val_loss: 0.0905 - val_MSE: 0.0127\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0639 - train_MSE: 0.0084 - val_loss: 0.0900 - val_MSE: 0.0126\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0636 - train_MSE: 0.0083 - val_loss: 0.0896 - val_MSE: 0.0125\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0632 - train_MSE: 0.0082 - val_loss: 0.0891 - val_MSE: 0.0124\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0627 - train_MSE: 0.0080 - val_loss: 0.0887 - val_MSE: 0.0123\n",
      "epoch:90/1500 - 耗时:0.03分/总3.09分; train_loss 0.0784 train_MSE 0.0130; val_loss 0.0882 val_MSE 0.0122\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0629 - train_MSE: 0.0081 - val_loss: 0.0887 - val_MSE: 0.0123\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0625 - train_MSE: 0.0080 - val_loss: 0.0882 - val_MSE: 0.0122\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0622 - train_MSE: 0.0079 - val_loss: 0.0877 - val_MSE: 0.0121\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0618 - train_MSE: 0.0079 - val_loss: 0.0872 - val_MSE: 0.0120\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0615 - train_MSE: 0.0078 - val_loss: 0.0867 - val_MSE: 0.0119\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0611 - train_MSE: 0.0077 - val_loss: 0.0862 - val_MSE: 0.0118\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0608 - train_MSE: 0.0076 - val_loss: 0.0857 - val_MSE: 0.0117\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0604 - train_MSE: 0.0075 - val_loss: 0.0852 - val_MSE: 0.0115\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0601 - train_MSE: 0.0074 - val_loss: 0.0847 - val_MSE: 0.0114\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0597 - train_MSE: 0.0074 - val_loss: 0.0841 - val_MSE: 0.0113\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0592 - train_MSE: 0.0072 - val_loss: 0.0837 - val_MSE: 0.0112\n",
      "epoch:100/1500 - 耗时:0.03分/总3.43分; train_loss 0.0739 train_MSE 0.0116; val_loss 0.0831 val_MSE 0.0111\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0594 - train_MSE: 0.0073 - val_loss: 0.0837 - val_MSE: 0.0112\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0590 - train_MSE: 0.0072 - val_loss: 0.0831 - val_MSE: 0.0111\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0587 - train_MSE: 0.0071 - val_loss: 0.0826 - val_MSE: 0.0110\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0583 - train_MSE: 0.0070 - val_loss: 0.0820 - val_MSE: 0.0108\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0580 - train_MSE: 0.0070 - val_loss: 0.0815 - val_MSE: 0.0107\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0576 - train_MSE: 0.0069 - val_loss: 0.0810 - val_MSE: 0.0106\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0573 - train_MSE: 0.0068 - val_loss: 0.0804 - val_MSE: 0.0105\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0569 - train_MSE: 0.0067 - val_loss: 0.0799 - val_MSE: 0.0103\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0565 - train_MSE: 0.0066 - val_loss: 0.0794 - val_MSE: 0.0102\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0562 - train_MSE: 0.0066 - val_loss: 0.0788 - val_MSE: 0.0101\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0557 - train_MSE: 0.0064 - val_loss: 0.0782 - val_MSE: 0.0100\n",
      "epoch:110/1500 - 耗时:0.03分/总3.76分; train_loss 0.0693 train_MSE 0.0103; val_loss 0.0776 val_MSE 0.0099\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0558 - train_MSE: 0.0065 - val_loss: 0.0782 - val_MSE: 0.0100\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0555 - train_MSE: 0.0064 - val_loss: 0.0776 - val_MSE: 0.0099\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0551 - train_MSE: 0.0063 - val_loss: 0.0770 - val_MSE: 0.0097\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0548 - train_MSE: 0.0062 - val_loss: 0.0764 - val_MSE: 0.0096\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0544 - train_MSE: 0.0062 - val_loss: 0.0759 - val_MSE: 0.0095\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0541 - train_MSE: 0.0061 - val_loss: 0.0753 - val_MSE: 0.0094\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0537 - train_MSE: 0.0060 - val_loss: 0.0748 - val_MSE: 0.0092\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0534 - train_MSE: 0.0059 - val_loss: 0.0742 - val_MSE: 0.0091\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0530 - train_MSE: 0.0059 - val_loss: 0.0736 - val_MSE: 0.0090\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0527 - train_MSE: 0.0058 - val_loss: 0.0730 - val_MSE: 0.0089\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0522 - train_MSE: 0.0057 - val_loss: 0.0724 - val_MSE: 0.0087\n",
      "epoch:120/1500 - 耗时:0.03分/总4.09分; train_loss 0.0646 train_MSE 0.0090; val_loss 0.0718 val_MSE 0.0086\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0524 - train_MSE: 0.0057 - val_loss: 0.0724 - val_MSE: 0.0087\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0520 - train_MSE: 0.0056 - val_loss: 0.0718 - val_MSE: 0.0086\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0517 - train_MSE: 0.0056 - val_loss: 0.0712 - val_MSE: 0.0085\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0513 - train_MSE: 0.0055 - val_loss: 0.0707 - val_MSE: 0.0084\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0510 - train_MSE: 0.0054 - val_loss: 0.0701 - val_MSE: 0.0082\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0506 - train_MSE: 0.0054 - val_loss: 0.0695 - val_MSE: 0.0081\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0503 - train_MSE: 0.0053 - val_loss: 0.0689 - val_MSE: 0.0080\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0500 - train_MSE: 0.0052 - val_loss: 0.0684 - val_MSE: 0.0079\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0496 - train_MSE: 0.0052 - val_loss: 0.0678 - val_MSE: 0.0078\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0493 - train_MSE: 0.0051 - val_loss: 0.0673 - val_MSE: 0.0077\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0489 - train_MSE: 0.0050 - val_loss: 0.0668 - val_MSE: 0.0076\n",
      "epoch:130/1500 - 耗时:0.03分/总4.43分; train_loss 0.0601 train_MSE 0.0078; val_loss 0.0662 val_MSE 0.0074\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0490 - train_MSE: 0.0050 - val_loss: 0.0668 - val_MSE: 0.0076\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0487 - train_MSE: 0.0050 - val_loss: 0.0662 - val_MSE: 0.0074\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0483 - train_MSE: 0.0049 - val_loss: 0.0657 - val_MSE: 0.0073\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0480 - train_MSE: 0.0048 - val_loss: 0.0651 - val_MSE: 0.0072\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0477 - train_MSE: 0.0048 - val_loss: 0.0647 - val_MSE: 0.0071\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0474 - train_MSE: 0.0047 - val_loss: 0.0642 - val_MSE: 0.0070\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0471 - train_MSE: 0.0046 - val_loss: 0.0636 - val_MSE: 0.0069\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0468 - train_MSE: 0.0046 - val_loss: 0.0631 - val_MSE: 0.0068\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0465 - train_MSE: 0.0045 - val_loss: 0.0627 - val_MSE: 0.0067\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0462 - train_MSE: 0.0045 - val_loss: 0.0622 - val_MSE: 0.0066\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0458 - train_MSE: 0.0044 - val_loss: 0.0618 - val_MSE: 0.0066\n",
      "epoch:140/1500 - 耗时:0.03分/总4.76分; train_loss 0.0559 train_MSE 0.0067; val_loss 0.0613 val_MSE 0.0065\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0459 - train_MSE: 0.0044 - val_loss: 0.0618 - val_MSE: 0.0066\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0457 - train_MSE: 0.0043 - val_loss: 0.0613 - val_MSE: 0.0065\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0454 - train_MSE: 0.0043 - val_loss: 0.0608 - val_MSE: 0.0064\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0451 - train_MSE: 0.0042 - val_loss: 0.0603 - val_MSE: 0.0063\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0448 - train_MSE: 0.0042 - val_loss: 0.0599 - val_MSE: 0.0062\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0445 - train_MSE: 0.0041 - val_loss: 0.0594 - val_MSE: 0.0061\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0443 - train_MSE: 0.0041 - val_loss: 0.0590 - val_MSE: 0.0060\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0440 - train_MSE: 0.0040 - val_loss: 0.0586 - val_MSE: 0.0059\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0438 - train_MSE: 0.0040 - val_loss: 0.0582 - val_MSE: 0.0059\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0435 - train_MSE: 0.0039 - val_loss: 0.0578 - val_MSE: 0.0058\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0431 - train_MSE: 0.0039 - val_loss: 0.0574 - val_MSE: 0.0057\n",
      "epoch:150/1500 - 耗时:0.03分/总5.09分; train_loss 0.0521 train_MSE 0.0058; val_loss 0.0569 val_MSE 0.0056\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0433 - train_MSE: 0.0039 - val_loss: 0.0574 - val_MSE: 0.0057\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0430 - train_MSE: 0.0038 - val_loss: 0.0569 - val_MSE: 0.0056\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0428 - train_MSE: 0.0038 - val_loss: 0.0566 - val_MSE: 0.0056\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0425 - train_MSE: 0.0037 - val_loss: 0.0563 - val_MSE: 0.0055\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0423 - train_MSE: 0.0037 - val_loss: 0.0558 - val_MSE: 0.0054\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0421 - train_MSE: 0.0037 - val_loss: 0.0554 - val_MSE: 0.0053\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0419 - train_MSE: 0.0036 - val_loss: 0.0551 - val_MSE: 0.0053\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0416 - train_MSE: 0.0036 - val_loss: 0.0547 - val_MSE: 0.0052\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0414 - train_MSE: 0.0035 - val_loss: 0.0543 - val_MSE: 0.0051\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0412 - train_MSE: 0.0035 - val_loss: 0.0539 - val_MSE: 0.0051\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0410 - train_MSE: 0.0034 - val_loss: 0.0536 - val_MSE: 0.0050\n",
      "epoch:160/1500 - 耗时:0.03分/总5.42分; train_loss 0.0488 train_MSE 0.0051; val_loss 0.0532 val_MSE 0.0049\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0410 - train_MSE: 0.0034 - val_loss: 0.0536 - val_MSE: 0.0050\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0408 - train_MSE: 0.0034 - val_loss: 0.0532 - val_MSE: 0.0049\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0406 - train_MSE: 0.0034 - val_loss: 0.0529 - val_MSE: 0.0049\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0404 - train_MSE: 0.0033 - val_loss: 0.0526 - val_MSE: 0.0048\n",
      "117/117 [==============================] - 2s 18ms/step - train_loss: 0.0403 - train_MSE: 0.0033 - val_loss: 0.0523 - val_MSE: 0.0048\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0401 - train_MSE: 0.0033 - val_loss: 0.0519 - val_MSE: 0.0047\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0399 - train_MSE: 0.0032 - val_loss: 0.0516 - val_MSE: 0.0047\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0397 - train_MSE: 0.0032 - val_loss: 0.0513 - val_MSE: 0.0046\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0395 - train_MSE: 0.0032 - val_loss: 0.0510 - val_MSE: 0.0045\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0394 - train_MSE: 0.0031 - val_loss: 0.0507 - val_MSE: 0.0045\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0391 - train_MSE: 0.0031 - val_loss: 0.0504 - val_MSE: 0.0044\n",
      "epoch:170/1500 - 耗时:0.03分/总5.76分; train_loss 0.0460 train_MSE 0.0044; val_loss 0.0501 val_MSE 0.0044\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0392 - train_MSE: 0.0031 - val_loss: 0.0504 - val_MSE: 0.0044\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0390 - train_MSE: 0.0031 - val_loss: 0.0501 - val_MSE: 0.0044\n",
      "117/117 [==============================] - 2s 18ms/step - train_loss: 0.0389 - train_MSE: 0.0030 - val_loss: 0.0498 - val_MSE: 0.0043\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0387 - train_MSE: 0.0030 - val_loss: 0.0495 - val_MSE: 0.0043\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0386 - train_MSE: 0.0030 - val_loss: 0.0491 - val_MSE: 0.0042\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0384 - train_MSE: 0.0029 - val_loss: 0.0489 - val_MSE: 0.0042\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0383 - train_MSE: 0.0029 - val_loss: 0.0485 - val_MSE: 0.0041\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0381 - train_MSE: 0.0029 - val_loss: 0.0482 - val_MSE: 0.0041\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0380 - train_MSE: 0.0029 - val_loss: 0.0479 - val_MSE: 0.0040\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0378 - train_MSE: 0.0028 - val_loss: 0.0477 - val_MSE: 0.0040\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0376 - train_MSE: 0.0028 - val_loss: 0.0474 - val_MSE: 0.0040\n",
      "epoch:180/1500 - 耗时:0.03分/总6.10分; train_loss 0.0435 train_MSE 0.0039; val_loss 0.0471 val_MSE 0.0039\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0377 - train_MSE: 0.0028 - val_loss: 0.0474 - val_MSE: 0.0040\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0375 - train_MSE: 0.0028 - val_loss: 0.0471 - val_MSE: 0.0039\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0374 - train_MSE: 0.0027 - val_loss: 0.0468 - val_MSE: 0.0039\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0373 - train_MSE: 0.0027 - val_loss: 0.0466 - val_MSE: 0.0038\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0371 - train_MSE: 0.0027 - val_loss: 0.0463 - val_MSE: 0.0038\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0370 - train_MSE: 0.0027 - val_loss: 0.0461 - val_MSE: 0.0038\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0369 - train_MSE: 0.0026 - val_loss: 0.0458 - val_MSE: 0.0037\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0367 - train_MSE: 0.0026 - val_loss: 0.0455 - val_MSE: 0.0037\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0366 - train_MSE: 0.0026 - val_loss: 0.0453 - val_MSE: 0.0036\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0365 - train_MSE: 0.0026 - val_loss: 0.0451 - val_MSE: 0.0036\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0363 - train_MSE: 0.0026 - val_loss: 0.0448 - val_MSE: 0.0036\n",
      "epoch:190/1500 - 耗时:0.03分/总6.43分; train_loss 0.0413 train_MSE 0.0034; val_loss 0.0446 val_MSE 0.0035\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0363 - train_MSE: 0.0026 - val_loss: 0.0448 - val_MSE: 0.0036\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0362 - train_MSE: 0.0025 - val_loss: 0.0446 - val_MSE: 0.0035\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0361 - train_MSE: 0.0025 - val_loss: 0.0443 - val_MSE: 0.0035\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0360 - train_MSE: 0.0025 - val_loss: 0.0441 - val_MSE: 0.0035\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0358 - train_MSE: 0.0025 - val_loss: 0.0439 - val_MSE: 0.0034\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0357 - train_MSE: 0.0024 - val_loss: 0.0436 - val_MSE: 0.0034\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0356 - train_MSE: 0.0024 - val_loss: 0.0433 - val_MSE: 0.0034\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0355 - train_MSE: 0.0024 - val_loss: 0.0431 - val_MSE: 0.0033\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0354 - train_MSE: 0.0024 - val_loss: 0.0429 - val_MSE: 0.0033\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0352 - train_MSE: 0.0024 - val_loss: 0.0426 - val_MSE: 0.0033\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0350 - train_MSE: 0.0023 - val_loss: 0.0425 - val_MSE: 0.0032\n",
      "epoch:200/1500 - 耗时:0.02分/总6.74分; train_loss 0.0394 train_MSE 0.0031; val_loss 0.0423 val_MSE 0.0032\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0351 - train_MSE: 0.0024 - val_loss: 0.0425 - val_MSE: 0.0032\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0350 - train_MSE: 0.0023 - val_loss: 0.0423 - val_MSE: 0.0032\n",
      "117/117 [==============================] - 1s 12ms/step - train_loss: 0.0349 - train_MSE: 0.0023 - val_loss: 0.0421 - val_MSE: 0.0032\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0348 - train_MSE: 0.0023 - val_loss: 0.0419 - val_MSE: 0.0032\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0347 - train_MSE: 0.0023 - val_loss: 0.0417 - val_MSE: 0.0031\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0346 - train_MSE: 0.0023 - val_loss: 0.0415 - val_MSE: 0.0031\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0345 - train_MSE: 0.0022 - val_loss: 0.0414 - val_MSE: 0.0031\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0344 - train_MSE: 0.0022 - val_loss: 0.0412 - val_MSE: 0.0031\n",
      "117/117 [==============================] - 1s 12ms/step - train_loss: 0.0343 - train_MSE: 0.0022 - val_loss: 0.0410 - val_MSE: 0.0030\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0341 - train_MSE: 0.0022 - val_loss: 0.0408 - val_MSE: 0.0030\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0339 - train_MSE: 0.0022 - val_loss: 0.0406 - val_MSE: 0.0030\n",
      "epoch:210/1500 - 耗时:0.02分/总6.96分; train_loss 0.0376 train_MSE 0.0028; val_loss 0.0405 val_MSE 0.0029\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0340 - train_MSE: 0.0022 - val_loss: 0.0406 - val_MSE: 0.0030\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0339 - train_MSE: 0.0022 - val_loss: 0.0405 - val_MSE: 0.0029\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0338 - train_MSE: 0.0021 - val_loss: 0.0403 - val_MSE: 0.0029\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0337 - train_MSE: 0.0021 - val_loss: 0.0401 - val_MSE: 0.0029\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0336 - train_MSE: 0.0021 - val_loss: 0.0399 - val_MSE: 0.0029\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0335 - train_MSE: 0.0021 - val_loss: 0.0398 - val_MSE: 0.0029\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0334 - train_MSE: 0.0021 - val_loss: 0.0396 - val_MSE: 0.0028\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0333 - train_MSE: 0.0021 - val_loss: 0.0394 - val_MSE: 0.0028\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0332 - train_MSE: 0.0021 - val_loss: 0.0393 - val_MSE: 0.0028\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0331 - train_MSE: 0.0020 - val_loss: 0.0391 - val_MSE: 0.0028\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0330 - train_MSE: 0.0020 - val_loss: 0.0389 - val_MSE: 0.0027\n",
      "epoch:220/1500 - 耗时:0.02分/总7.17分; train_loss 0.0361 train_MSE 0.0025; val_loss 0.0388 val_MSE 0.0027\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0330 - train_MSE: 0.0020 - val_loss: 0.0389 - val_MSE: 0.0027\n",
      "117/117 [==============================] - 1s 12ms/step - train_loss: 0.0329 - train_MSE: 0.0020 - val_loss: 0.0388 - val_MSE: 0.0027\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0329 - train_MSE: 0.0020 - val_loss: 0.0387 - val_MSE: 0.0027\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0328 - train_MSE: 0.0020 - val_loss: 0.0385 - val_MSE: 0.0027\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0327 - train_MSE: 0.0020 - val_loss: 0.0384 - val_MSE: 0.0027\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0326 - train_MSE: 0.0020 - val_loss: 0.0382 - val_MSE: 0.0026\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0325 - train_MSE: 0.0020 - val_loss: 0.0381 - val_MSE: 0.0026\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0324 - train_MSE: 0.0019 - val_loss: 0.0379 - val_MSE: 0.0026\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0323 - train_MSE: 0.0019 - val_loss: 0.0378 - val_MSE: 0.0026\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0322 - train_MSE: 0.0019 - val_loss: 0.0377 - val_MSE: 0.0026\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0321 - train_MSE: 0.0019 - val_loss: 0.0375 - val_MSE: 0.0026\n",
      "epoch:230/1500 - 耗时:0.02分/总7.39分; train_loss 0.0347 train_MSE 0.0023; val_loss 0.0374 val_MSE 0.0025\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0321 - train_MSE: 0.0019 - val_loss: 0.0375 - val_MSE: 0.0026\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0320 - train_MSE: 0.0019 - val_loss: 0.0374 - val_MSE: 0.0025\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0319 - train_MSE: 0.0019 - val_loss: 0.0373 - val_MSE: 0.0025\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0319 - train_MSE: 0.0019 - val_loss: 0.0371 - val_MSE: 0.0025\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0318 - train_MSE: 0.0019 - val_loss: 0.0370 - val_MSE: 0.0025\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0317 - train_MSE: 0.0018 - val_loss: 0.0368 - val_MSE: 0.0025\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0316 - train_MSE: 0.0018 - val_loss: 0.0367 - val_MSE: 0.0024\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0315 - train_MSE: 0.0018 - val_loss: 0.0366 - val_MSE: 0.0024\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0314 - train_MSE: 0.0018 - val_loss: 0.0364 - val_MSE: 0.0024\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0314 - train_MSE: 0.0018 - val_loss: 0.0363 - val_MSE: 0.0024\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0312 - train_MSE: 0.0018 - val_loss: 0.0362 - val_MSE: 0.0024\n",
      "epoch:240/1500 - 耗时:0.02分/总7.60分; train_loss 0.0335 train_MSE 0.0021; val_loss 0.0360 val_MSE 0.0024\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0313 - train_MSE: 0.0018 - val_loss: 0.0362 - val_MSE: 0.0024\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0312 - train_MSE: 0.0018 - val_loss: 0.0360 - val_MSE: 0.0024\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0311 - train_MSE: 0.0018 - val_loss: 0.0359 - val_MSE: 0.0023\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0310 - train_MSE: 0.0018 - val_loss: 0.0357 - val_MSE: 0.0023\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0309 - train_MSE: 0.0018 - val_loss: 0.0356 - val_MSE: 0.0023\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0309 - train_MSE: 0.0017 - val_loss: 0.0355 - val_MSE: 0.0023\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0308 - train_MSE: 0.0017 - val_loss: 0.0353 - val_MSE: 0.0023\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0307 - train_MSE: 0.0017 - val_loss: 0.0353 - val_MSE: 0.0023\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0306 - train_MSE: 0.0017 - val_loss: 0.0351 - val_MSE: 0.0022\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0305 - train_MSE: 0.0017 - val_loss: 0.0350 - val_MSE: 0.0022\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0304 - train_MSE: 0.0017 - val_loss: 0.0349 - val_MSE: 0.0022\n",
      "epoch:250/1500 - 耗时:0.02分/总7.81分; train_loss 0.0324 train_MSE 0.0020; val_loss 0.0348 val_MSE 0.0022\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0305 - train_MSE: 0.0017 - val_loss: 0.0349 - val_MSE: 0.0022\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0304 - train_MSE: 0.0017 - val_loss: 0.0348 - val_MSE: 0.0022\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0303 - train_MSE: 0.0017 - val_loss: 0.0347 - val_MSE: 0.0022\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0302 - train_MSE: 0.0017 - val_loss: 0.0346 - val_MSE: 0.0022\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0302 - train_MSE: 0.0017 - val_loss: 0.0345 - val_MSE: 0.0022\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0301 - train_MSE: 0.0017 - val_loss: 0.0344 - val_MSE: 0.0022\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0300 - train_MSE: 0.0016 - val_loss: 0.0343 - val_MSE: 0.0022\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0299 - train_MSE: 0.0016 - val_loss: 0.0342 - val_MSE: 0.0021\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0299 - train_MSE: 0.0016 - val_loss: 0.0341 - val_MSE: 0.0021\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0298 - train_MSE: 0.0016 - val_loss: 0.0340 - val_MSE: 0.0021\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0296 - train_MSE: 0.0016 - val_loss: 0.0339 - val_MSE: 0.0021\n",
      "epoch:260/1500 - 耗时:0.02分/总8.02分; train_loss 0.0314 train_MSE 0.0018; val_loss 0.0338 val_MSE 0.0021\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0297 - train_MSE: 0.0016 - val_loss: 0.0339 - val_MSE: 0.0021\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0296 - train_MSE: 0.0016 - val_loss: 0.0338 - val_MSE: 0.0021\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0296 - train_MSE: 0.0016 - val_loss: 0.0337 - val_MSE: 0.0021\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0295 - train_MSE: 0.0016 - val_loss: 0.0335 - val_MSE: 0.0021\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0294 - train_MSE: 0.0016 - val_loss: 0.0334 - val_MSE: 0.0020\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0293 - train_MSE: 0.0016 - val_loss: 0.0333 - val_MSE: 0.0020\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0293 - train_MSE: 0.0016 - val_loss: 0.0332 - val_MSE: 0.0020\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0292 - train_MSE: 0.0016 - val_loss: 0.0331 - val_MSE: 0.0020\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0291 - train_MSE: 0.0016 - val_loss: 0.0330 - val_MSE: 0.0020\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0291 - train_MSE: 0.0015 - val_loss: 0.0329 - val_MSE: 0.0020\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0289 - train_MSE: 0.0015 - val_loss: 0.0329 - val_MSE: 0.0020\n",
      "epoch:270/1500 - 耗时:0.02分/总8.23分; train_loss 0.0305 train_MSE 0.0017; val_loss 0.0328 val_MSE 0.0020\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0290 - train_MSE: 0.0015 - val_loss: 0.0329 - val_MSE: 0.0020\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0289 - train_MSE: 0.0015 - val_loss: 0.0328 - val_MSE: 0.0020\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0289 - train_MSE: 0.0015 - val_loss: 0.0327 - val_MSE: 0.0020\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0288 - train_MSE: 0.0015 - val_loss: 0.0326 - val_MSE: 0.0019\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0287 - train_MSE: 0.0015 - val_loss: 0.0325 - val_MSE: 0.0019\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0286 - train_MSE: 0.0015 - val_loss: 0.0324 - val_MSE: 0.0019\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0286 - train_MSE: 0.0015 - val_loss: 0.0323 - val_MSE: 0.0019\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0285 - train_MSE: 0.0015 - val_loss: 0.0322 - val_MSE: 0.0019\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0284 - train_MSE: 0.0015 - val_loss: 0.0321 - val_MSE: 0.0019\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0284 - train_MSE: 0.0015 - val_loss: 0.0320 - val_MSE: 0.0019\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0283 - train_MSE: 0.0015 - val_loss: 0.0319 - val_MSE: 0.0019\n",
      "epoch:280/1500 - 耗时:0.02分/总8.44分; train_loss 0.0296 train_MSE 0.0016; val_loss 0.0318 val_MSE 0.0019\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0283 - train_MSE: 0.0015 - val_loss: 0.0319 - val_MSE: 0.0019\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0282 - train_MSE: 0.0015 - val_loss: 0.0318 - val_MSE: 0.0019\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0282 - train_MSE: 0.0015 - val_loss: 0.0317 - val_MSE: 0.0018\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0281 - train_MSE: 0.0014 - val_loss: 0.0316 - val_MSE: 0.0018\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0280 - train_MSE: 0.0014 - val_loss: 0.0315 - val_MSE: 0.0018\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0280 - train_MSE: 0.0014 - val_loss: 0.0314 - val_MSE: 0.0018\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0279 - train_MSE: 0.0014 - val_loss: 0.0313 - val_MSE: 0.0018\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0278 - train_MSE: 0.0014 - val_loss: 0.0312 - val_MSE: 0.0018\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0278 - train_MSE: 0.0014 - val_loss: 0.0311 - val_MSE: 0.0018\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0277 - train_MSE: 0.0014 - val_loss: 0.0310 - val_MSE: 0.0018\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0276 - train_MSE: 0.0014 - val_loss: 0.0309 - val_MSE: 0.0018\n",
      "epoch:290/1500 - 耗时:0.02分/总8.65分; train_loss 0.0288 train_MSE 0.0016; val_loss 0.0309 val_MSE 0.0018\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0276 - train_MSE: 0.0014 - val_loss: 0.0309 - val_MSE: 0.0018\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0276 - train_MSE: 0.0014 - val_loss: 0.0309 - val_MSE: 0.0018\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0275 - train_MSE: 0.0014 - val_loss: 0.0308 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0275 - train_MSE: 0.0014 - val_loss: 0.0307 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0274 - train_MSE: 0.0014 - val_loss: 0.0306 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0273 - train_MSE: 0.0014 - val_loss: 0.0305 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0273 - train_MSE: 0.0014 - val_loss: 0.0304 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0272 - train_MSE: 0.0014 - val_loss: 0.0304 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0272 - train_MSE: 0.0014 - val_loss: 0.0303 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0271 - train_MSE: 0.0013 - val_loss: 0.0302 - val_MSE: 0.0017\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0270 - train_MSE: 0.0013 - val_loss: 0.0302 - val_MSE: 0.0017\n",
      "epoch:300/1500 - 耗时:0.02分/总8.87分; train_loss 0.0282 train_MSE 0.0015; val_loss 0.0301 val_MSE 0.0017\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0270 - train_MSE: 0.0013 - val_loss: 0.0302 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0270 - train_MSE: 0.0013 - val_loss: 0.0301 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0269 - train_MSE: 0.0013 - val_loss: 0.0300 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0269 - train_MSE: 0.0013 - val_loss: 0.0300 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0268 - train_MSE: 0.0013 - val_loss: 0.0299 - val_MSE: 0.0017\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0267 - train_MSE: 0.0013 - val_loss: 0.0298 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0267 - train_MSE: 0.0013 - val_loss: 0.0297 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0266 - train_MSE: 0.0013 - val_loss: 0.0296 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0266 - train_MSE: 0.0013 - val_loss: 0.0295 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0265 - train_MSE: 0.0013 - val_loss: 0.0294 - val_MSE: 0.0016\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0264 - train_MSE: 0.0013 - val_loss: 0.0293 - val_MSE: 0.0016\n",
      "epoch:310/1500 - 耗时:0.02分/总9.08分; train_loss 0.0274 train_MSE 0.0014; val_loss 0.0292 val_MSE 0.0016\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0264 - train_MSE: 0.0013 - val_loss: 0.0293 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 12ms/step - train_loss: 0.0264 - train_MSE: 0.0013 - val_loss: 0.0292 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0263 - train_MSE: 0.0013 - val_loss: 0.0292 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0263 - train_MSE: 0.0013 - val_loss: 0.0291 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0262 - train_MSE: 0.0013 - val_loss: 0.0290 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0262 - train_MSE: 0.0013 - val_loss: 0.0289 - val_MSE: 0.0016\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0261 - train_MSE: 0.0013 - val_loss: 0.0289 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0260 - train_MSE: 0.0013 - val_loss: 0.0288 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0260 - train_MSE: 0.0012 - val_loss: 0.0287 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0259 - train_MSE: 0.0012 - val_loss: 0.0286 - val_MSE: 0.0015\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0259 - train_MSE: 0.0012 - val_loss: 0.0286 - val_MSE: 0.0015\n",
      "epoch:320/1500 - 耗时:0.02分/总9.30分; train_loss 0.0268 train_MSE 0.0013; val_loss 0.0285 val_MSE 0.0015\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0259 - train_MSE: 0.0012 - val_loss: 0.0286 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0258 - train_MSE: 0.0012 - val_loss: 0.0285 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0258 - train_MSE: 0.0012 - val_loss: 0.0284 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0257 - train_MSE: 0.0012 - val_loss: 0.0283 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0257 - train_MSE: 0.0012 - val_loss: 0.0283 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0256 - train_MSE: 0.0012 - val_loss: 0.0283 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0256 - train_MSE: 0.0012 - val_loss: 0.0282 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0255 - train_MSE: 0.0012 - val_loss: 0.0282 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0255 - train_MSE: 0.0012 - val_loss: 0.0281 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0254 - train_MSE: 0.0012 - val_loss: 0.0280 - val_MSE: 0.0015\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0253 - train_MSE: 0.0012 - val_loss: 0.0280 - val_MSE: 0.0015\n",
      "epoch:330/1500 - 耗时:0.02分/总9.51分; train_loss 0.0262 train_MSE 0.0013; val_loss 0.0279 val_MSE 0.0015\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0254 - train_MSE: 0.0012 - val_loss: 0.0280 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0253 - train_MSE: 0.0012 - val_loss: 0.0279 - val_MSE: 0.0015\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0253 - train_MSE: 0.0012 - val_loss: 0.0278 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0252 - train_MSE: 0.0012 - val_loss: 0.0277 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0251 - train_MSE: 0.0012 - val_loss: 0.0276 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0251 - train_MSE: 0.0012 - val_loss: 0.0275 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0250 - train_MSE: 0.0012 - val_loss: 0.0275 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0250 - train_MSE: 0.0012 - val_loss: 0.0274 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0249 - train_MSE: 0.0012 - val_loss: 0.0273 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0249 - train_MSE: 0.0011 - val_loss: 0.0272 - val_MSE: 0.0014\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0248 - train_MSE: 0.0011 - val_loss: 0.0271 - val_MSE: 0.0014\n",
      "epoch:340/1500 - 耗时:0.02分/总9.72分; train_loss 0.0255 train_MSE 0.0012; val_loss 0.0270 val_MSE 0.0014\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0248 - train_MSE: 0.0011 - val_loss: 0.0271 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0248 - train_MSE: 0.0011 - val_loss: 0.0270 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0247 - train_MSE: 0.0011 - val_loss: 0.0270 - val_MSE: 0.0014\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0247 - train_MSE: 0.0011 - val_loss: 0.0269 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0246 - train_MSE: 0.0011 - val_loss: 0.0268 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0246 - train_MSE: 0.0011 - val_loss: 0.0268 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0245 - train_MSE: 0.0011 - val_loss: 0.0267 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0245 - train_MSE: 0.0011 - val_loss: 0.0267 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0244 - train_MSE: 0.0011 - val_loss: 0.0266 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0244 - train_MSE: 0.0011 - val_loss: 0.0266 - val_MSE: 0.0013\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0243 - train_MSE: 0.0011 - val_loss: 0.0265 - val_MSE: 0.0013\n",
      "epoch:350/1500 - 耗时:0.02分/总9.93分; train_loss 0.0250 train_MSE 0.0012; val_loss 0.0265 val_MSE 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0243 - train_MSE: 0.0011 - val_loss: 0.0265 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0243 - train_MSE: 0.0011 - val_loss: 0.0265 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 10ms/step - train_loss: 0.0242 - train_MSE: 0.0011 - val_loss: 0.0264 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0242 - train_MSE: 0.0011 - val_loss: 0.0264 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0241 - train_MSE: 0.0011 - val_loss: 0.0263 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0241 - train_MSE: 0.0011 - val_loss: 0.0263 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0240 - train_MSE: 0.0011 - val_loss: 0.0262 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 11ms/step - train_loss: 0.0240 - train_MSE: 0.0011 - val_loss: 0.0261 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 12ms/step - train_loss: 0.0239 - train_MSE: 0.0011 - val_loss: 0.0261 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 2s 13ms/step - train_loss: 0.0239 - train_MSE: 0.0011 - val_loss: 0.0260 - val_MSE: 0.0013\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0238 - train_MSE: 0.0011 - val_loss: 0.0260 - val_MSE: 0.0013\n",
      "epoch:360/1500 - 耗时:0.02分/总10.15分; train_loss 0.0244 train_MSE 0.0011; val_loss 0.0259 val_MSE 0.0013\n",
      "117/117 [==============================] - 1s 12ms/step - train_loss: 0.0239 - train_MSE: 0.0011 - val_loss: 0.0260 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 1s 13ms/step - train_loss: 0.0238 - train_MSE: 0.0011 - val_loss: 0.0259 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0238 - train_MSE: 0.0011 - val_loss: 0.0259 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0237 - train_MSE: 0.0011 - val_loss: 0.0258 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0237 - train_MSE: 0.0010 - val_loss: 0.0258 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0236 - train_MSE: 0.0010 - val_loss: 0.0257 - val_MSE: 0.0013\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0236 - train_MSE: 0.0010 - val_loss: 0.0257 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0235 - train_MSE: 0.0010 - val_loss: 0.0256 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0235 - train_MSE: 0.0010 - val_loss: 0.0255 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0234 - train_MSE: 0.0010 - val_loss: 0.0255 - val_MSE: 0.0012\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0234 - train_MSE: 0.0010 - val_loss: 0.0254 - val_MSE: 0.0012\n",
      "epoch:370/1500 - 耗时:0.03分/总10.48分; train_loss 0.0238 train_MSE 0.0011; val_loss 0.0253 val_MSE 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0234 - train_MSE: 0.0010 - val_loss: 0.0254 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0233 - train_MSE: 0.0010 - val_loss: 0.0253 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0233 - train_MSE: 0.0010 - val_loss: 0.0253 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0232 - train_MSE: 0.0010 - val_loss: 0.0252 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0232 - train_MSE: 0.0010 - val_loss: 0.0251 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0231 - train_MSE: 0.0010 - val_loss: 0.0250 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0231 - train_MSE: 0.0010 - val_loss: 0.0250 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0230 - train_MSE: 9.9662e-04 - val_loss: 0.0249 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 18ms/step - train_loss: 0.0230 - train_MSE: 9.9328e-04 - val_loss: 0.0249 - val_MSE: 0.0012\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0230 - train_MSE: 9.9034e-04 - val_loss: 0.0248 - val_MSE: 0.0011\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0229 - train_MSE: 9.8541e-04 - val_loss: 0.0247 - val_MSE: 0.0011\n",
      "epoch:380/1500 - 耗时:0.03分/总10.81分; train_loss 0.0233 train_MSE 0.0010; val_loss 0.0247 val_MSE 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0229 - train_MSE: 9.8605e-04 - val_loss: 0.0247 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0229 - train_MSE: 9.8264e-04 - val_loss: 0.0247 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0228 - train_MSE: 9.7988e-04 - val_loss: 0.0246 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0228 - train_MSE: 9.7704e-04 - val_loss: 0.0246 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0227 - train_MSE: 9.7349e-04 - val_loss: 0.0245 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0227 - train_MSE: 9.7019e-04 - val_loss: 0.0245 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0227 - train_MSE: 9.6754e-04 - val_loss: 0.0244 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0226 - train_MSE: 9.6359e-04 - val_loss: 0.0244 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0226 - train_MSE: 9.6042e-04 - val_loss: 0.0244 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0225 - train_MSE: 9.5711e-04 - val_loss: 0.0243 - val_MSE: 0.0011\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0225 - train_MSE: 9.5400e-04 - val_loss: 0.0243 - val_MSE: 0.0011\n",
      "epoch:390/1500 - 耗时:0.03分/总11.14分; train_loss 0.0229 train_MSE 0.0010; val_loss 0.0243 val_MSE 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0225 - train_MSE: 9.5472e-04 - val_loss: 0.0243 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0225 - train_MSE: 9.5099e-04 - val_loss: 0.0243 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0224 - train_MSE: 9.4797e-04 - val_loss: 0.0242 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0224 - train_MSE: 9.4468e-04 - val_loss: 0.0242 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 19ms/step - train_loss: 0.0224 - train_MSE: 9.4061e-04 - val_loss: 0.0242 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0223 - train_MSE: 9.3767e-04 - val_loss: 0.0241 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0223 - train_MSE: 9.3497e-04 - val_loss: 0.0241 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0222 - train_MSE: 9.3080e-04 - val_loss: 0.0240 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0222 - train_MSE: 9.2804e-04 - val_loss: 0.0240 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0221 - train_MSE: 9.2424e-04 - val_loss: 0.0239 - val_MSE: 0.0011\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0221 - train_MSE: 9.2136e-04 - val_loss: 0.0239 - val_MSE: 0.0011\n",
      "epoch:400/1500 - 耗时:0.03分/总11.47分; train_loss 0.0223 train_MSE 0.0010; val_loss 0.0238 val_MSE 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0221 - train_MSE: 9.2154e-04 - val_loss: 0.0239 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0221 - train_MSE: 9.1771e-04 - val_loss: 0.0238 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0220 - train_MSE: 9.1539e-04 - val_loss: 0.0237 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0220 - train_MSE: 9.1148e-04 - val_loss: 0.0237 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0219 - train_MSE: 9.0854e-04 - val_loss: 0.0236 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0219 - train_MSE: 9.0535e-04 - val_loss: 0.0236 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0218 - train_MSE: 9.0238e-04 - val_loss: 0.0235 - val_MSE: 0.0011\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0218 - train_MSE: 8.9895e-04 - val_loss: 0.0234 - val_MSE: 0.0010\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0217 - train_MSE: 8.9572e-04 - val_loss: 0.0234 - val_MSE: 0.0010\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0217 - train_MSE: 8.9356e-04 - val_loss: 0.0233 - val_MSE: 0.0010\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0217 - train_MSE: 8.8985e-04 - val_loss: 0.0233 - val_MSE: 0.0010\n",
      "epoch:410/1500 - 耗时:0.03分/总11.80分; train_loss 0.0218 train_MSE 0.0009; val_loss 0.0232 val_MSE 0.0010\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0217 - train_MSE: 8.8997e-04 - val_loss: 0.0233 - val_MSE: 0.0010\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0216 - train_MSE: 8.8771e-04 - val_loss: 0.0232 - val_MSE: 0.0010\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0216 - train_MSE: 8.8495e-04 - val_loss: 0.0232 - val_MSE: 0.0010\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0215 - train_MSE: 8.8223e-04 - val_loss: 0.0231 - val_MSE: 0.0010\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0215 - train_MSE: 8.7931e-04 - val_loss: 0.0230 - val_MSE: 9.9873e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0215 - train_MSE: 8.7706e-04 - val_loss: 0.0230 - val_MSE: 9.9025e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0214 - train_MSE: 8.7370e-04 - val_loss: 0.0229 - val_MSE: 9.8860e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0214 - train_MSE: 8.7067e-04 - val_loss: 0.0229 - val_MSE: 9.8567e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0214 - train_MSE: 8.6843e-04 - val_loss: 0.0228 - val_MSE: 9.7823e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0213 - train_MSE: 8.6574e-04 - val_loss: 0.0228 - val_MSE: 9.7282e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0213 - train_MSE: 8.6163e-04 - val_loss: 0.0228 - val_MSE: 9.7077e-04\n",
      "epoch:420/1500 - 耗时:0.03分/总12.13分; train_loss 0.0214 train_MSE 0.0009; val_loss 0.0227 val_MSE 0.0010\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0213 - train_MSE: 8.6190e-04 - val_loss: 0.0228 - val_MSE: 9.7075e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0212 - train_MSE: 8.5988e-04 - val_loss: 0.0227 - val_MSE: 9.6559e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0212 - train_MSE: 8.5746e-04 - val_loss: 0.0227 - val_MSE: 9.6250e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0212 - train_MSE: 8.5478e-04 - val_loss: 0.0226 - val_MSE: 9.5780e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0211 - train_MSE: 8.5208e-04 - val_loss: 0.0226 - val_MSE: 9.5923e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0211 - train_MSE: 8.4996e-04 - val_loss: 0.0226 - val_MSE: 9.5594e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0211 - train_MSE: 8.4719e-04 - val_loss: 0.0225 - val_MSE: 9.5680e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0210 - train_MSE: 8.4424e-04 - val_loss: 0.0225 - val_MSE: 9.5527e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0210 - train_MSE: 8.4164e-04 - val_loss: 0.0224 - val_MSE: 9.5663e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0210 - train_MSE: 8.3933e-04 - val_loss: 0.0224 - val_MSE: 9.5355e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0209 - train_MSE: 8.3597e-04 - val_loss: 0.0224 - val_MSE: 9.5767e-04\n",
      "epoch:430/1500 - 耗时:0.03分/总12.46分; train_loss 0.0211 train_MSE 0.0009; val_loss 0.0224 val_MSE 0.0010\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0209 - train_MSE: 8.3660e-04 - val_loss: 0.0224 - val_MSE: 9.5767e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0209 - train_MSE: 8.3393e-04 - val_loss: 0.0224 - val_MSE: 9.5896e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0209 - train_MSE: 8.3129e-04 - val_loss: 0.0223 - val_MSE: 9.5842e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0208 - train_MSE: 8.2925e-04 - val_loss: 0.0223 - val_MSE: 9.5925e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0208 - train_MSE: 8.2600e-04 - val_loss: 0.0223 - val_MSE: 9.6355e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0208 - train_MSE: 8.2472e-04 - val_loss: 0.0222 - val_MSE: 9.6010e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0207 - train_MSE: 8.2172e-04 - val_loss: 0.0222 - val_MSE: 9.6182e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0207 - train_MSE: 8.1952e-04 - val_loss: 0.0222 - val_MSE: 9.6211e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0207 - train_MSE: 8.1700e-04 - val_loss: 0.0221 - val_MSE: 9.5652e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0206 - train_MSE: 8.1373e-04 - val_loss: 0.0221 - val_MSE: 9.5703e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0206 - train_MSE: 8.1071e-04 - val_loss: 0.0220 - val_MSE: 9.5305e-04\n",
      "epoch:440/1500 - 耗时:0.03分/总12.79分; train_loss 0.0206 train_MSE 0.0008; val_loss 0.0220 val_MSE 0.0010\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0206 - train_MSE: 8.1146e-04 - val_loss: 0.0220 - val_MSE: 9.5305e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0206 - train_MSE: 8.0819e-04 - val_loss: 0.0220 - val_MSE: 9.5138e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0205 - train_MSE: 8.0616e-04 - val_loss: 0.0220 - val_MSE: 9.4794e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0205 - train_MSE: 8.0376e-04 - val_loss: 0.0219 - val_MSE: 9.4187e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0205 - train_MSE: 8.0112e-04 - val_loss: 0.0218 - val_MSE: 9.3255e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0204 - train_MSE: 7.9823e-04 - val_loss: 0.0218 - val_MSE: 9.2637e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0204 - train_MSE: 7.9623e-04 - val_loss: 0.0217 - val_MSE: 9.1659e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0203 - train_MSE: 7.9330e-04 - val_loss: 0.0217 - val_MSE: 9.0925e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0203 - train_MSE: 7.9084e-04 - val_loss: 0.0216 - val_MSE: 8.9913e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0203 - train_MSE: 7.8847e-04 - val_loss: 0.0216 - val_MSE: 8.8981e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0202 - train_MSE: 7.8610e-04 - val_loss: 0.0215 - val_MSE: 8.8434e-04\n",
      "epoch:450/1500 - 耗时:0.03分/总13.12分; train_loss 0.0201 train_MSE 0.0008; val_loss 0.0215 val_MSE 0.0009\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0202 - train_MSE: 7.8619e-04 - val_loss: 0.0215 - val_MSE: 8.8431e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0202 - train_MSE: 7.8329e-04 - val_loss: 0.0214 - val_MSE: 8.7742e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0202 - train_MSE: 7.8119e-04 - val_loss: 0.0214 - val_MSE: 8.6797e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0201 - train_MSE: 7.7886e-04 - val_loss: 0.0214 - val_MSE: 8.6108e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0201 - train_MSE: 7.7641e-04 - val_loss: 0.0213 - val_MSE: 8.5427e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0200 - train_MSE: 7.7374e-04 - val_loss: 0.0213 - val_MSE: 8.5161e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0200 - train_MSE: 7.7202e-04 - val_loss: 0.0212 - val_MSE: 8.4626e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0200 - train_MSE: 7.6912e-04 - val_loss: 0.0212 - val_MSE: 8.4255e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0199 - train_MSE: 7.6707e-04 - val_loss: 0.0212 - val_MSE: 8.3824e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0199 - train_MSE: 7.6516e-04 - val_loss: 0.0212 - val_MSE: 8.3308e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0199 - train_MSE: 7.6200e-04 - val_loss: 0.0211 - val_MSE: 8.3177e-04\n",
      "epoch:460/1500 - 耗时:0.03分/总13.46分; train_loss 0.0198 train_MSE 0.0008; val_loss 0.0211 val_MSE 0.0008\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0199 - train_MSE: 7.6216e-04 - val_loss: 0.0211 - val_MSE: 8.3176e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0198 - train_MSE: 7.6061e-04 - val_loss: 0.0211 - val_MSE: 8.2896e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0198 - train_MSE: 7.5786e-04 - val_loss: 0.0211 - val_MSE: 8.2392e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0198 - train_MSE: 7.5531e-04 - val_loss: 0.0210 - val_MSE: 8.2486e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0197 - train_MSE: 7.5373e-04 - val_loss: 0.0210 - val_MSE: 8.2018e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0197 - train_MSE: 7.5145e-04 - val_loss: 0.0210 - val_MSE: 8.1929e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0197 - train_MSE: 7.4925e-04 - val_loss: 0.0209 - val_MSE: 8.1667e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0196 - train_MSE: 7.4736e-04 - val_loss: 0.0209 - val_MSE: 8.1573e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0196 - train_MSE: 7.4556e-04 - val_loss: 0.0209 - val_MSE: 8.1326e-04\n",
      "117/117 [==============================] - 2s 18ms/step - train_loss: 0.0196 - train_MSE: 7.4310e-04 - val_loss: 0.0208 - val_MSE: 8.1612e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0196 - train_MSE: 7.4115e-04 - val_loss: 0.0208 - val_MSE: 8.1400e-04\n",
      "epoch:470/1500 - 耗时:0.03分/总13.78分; train_loss 0.0196 train_MSE 0.0008; val_loss 0.0207 val_MSE 0.0008\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0196 - train_MSE: 7.4144e-04 - val_loss: 0.0208 - val_MSE: 8.1400e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0195 - train_MSE: 7.3913e-04 - val_loss: 0.0207 - val_MSE: 8.1480e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0195 - train_MSE: 7.3716e-04 - val_loss: 0.0207 - val_MSE: 8.1459e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0195 - train_MSE: 7.3507e-04 - val_loss: 0.0206 - val_MSE: 8.1489e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0195 - train_MSE: 7.3392e-04 - val_loss: 0.0206 - val_MSE: 8.1433e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0194 - train_MSE: 7.3174e-04 - val_loss: 0.0206 - val_MSE: 8.2080e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0194 - train_MSE: 7.3014e-04 - val_loss: 0.0205 - val_MSE: 8.1868e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0194 - train_MSE: 7.2794e-04 - val_loss: 0.0205 - val_MSE: 8.2535e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0193 - train_MSE: 7.2597e-04 - val_loss: 0.0205 - val_MSE: 8.2244e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0193 - train_MSE: 7.2354e-04 - val_loss: 0.0204 - val_MSE: 8.2627e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0193 - train_MSE: 7.2180e-04 - val_loss: 0.0204 - val_MSE: 8.2289e-04\n",
      "epoch:480/1500 - 耗时:0.03分/总14.12分; train_loss 0.0192 train_MSE 0.0007; val_loss 0.0204 val_MSE 0.0008\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0193 - train_MSE: 7.2199e-04 - val_loss: 0.0204 - val_MSE: 8.2289e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0193 - train_MSE: 7.2056e-04 - val_loss: 0.0204 - val_MSE: 8.2236e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0192 - train_MSE: 7.1879e-04 - val_loss: 0.0203 - val_MSE: 8.1915e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0192 - train_MSE: 7.1612e-04 - val_loss: 0.0203 - val_MSE: 8.2136e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0192 - train_MSE: 7.1475e-04 - val_loss: 0.0203 - val_MSE: 8.1650e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0192 - train_MSE: 7.1266e-04 - val_loss: 0.0203 - val_MSE: 8.1587e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0191 - train_MSE: 7.1004e-04 - val_loss: 0.0202 - val_MSE: 8.1193e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0191 - train_MSE: 7.0833e-04 - val_loss: 0.0202 - val_MSE: 8.0772e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0191 - train_MSE: 7.0620e-04 - val_loss: 0.0201 - val_MSE: 8.0259e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0190 - train_MSE: 7.0464e-04 - val_loss: 0.0201 - val_MSE: 7.9291e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0190 - train_MSE: 7.0218e-04 - val_loss: 0.0200 - val_MSE: 7.8773e-04\n",
      "epoch:490/1500 - 耗时:0.03分/总14.45分; train_loss 0.0188 train_MSE 0.0007; val_loss 0.0200 val_MSE 0.0008\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0190 - train_MSE: 7.0216e-04 - val_loss: 0.0200 - val_MSE: 7.8771e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0190 - train_MSE: 7.0021e-04 - val_loss: 0.0200 - val_MSE: 7.8302e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0189 - train_MSE: 6.9817e-04 - val_loss: 0.0199 - val_MSE: 7.7649e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0189 - train_MSE: 6.9550e-04 - val_loss: 0.0199 - val_MSE: 7.7174e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0189 - train_MSE: 6.9376e-04 - val_loss: 0.0198 - val_MSE: 7.6539e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0188 - train_MSE: 6.9135e-04 - val_loss: 0.0198 - val_MSE: 7.6189e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0188 - train_MSE: 6.8946e-04 - val_loss: 0.0197 - val_MSE: 7.5621e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0188 - train_MSE: 6.8723e-04 - val_loss: 0.0197 - val_MSE: 7.5100e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0187 - train_MSE: 6.8544e-04 - val_loss: 0.0196 - val_MSE: 7.4655e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0187 - train_MSE: 6.8369e-04 - val_loss: 0.0196 - val_MSE: 7.3893e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0187 - train_MSE: 6.8140e-04 - val_loss: 0.0196 - val_MSE: 7.3729e-04\n",
      "epoch:500/1500 - 耗时:0.03分/总14.78分; train_loss 0.0184 train_MSE 0.0007; val_loss 0.0195 val_MSE 0.0007\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0187 - train_MSE: 6.8134e-04 - val_loss: 0.0196 - val_MSE: 7.3725e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0186 - train_MSE: 6.7980e-04 - val_loss: 0.0195 - val_MSE: 7.2729e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0186 - train_MSE: 6.7723e-04 - val_loss: 0.0195 - val_MSE: 7.2520e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0186 - train_MSE: 6.7565e-04 - val_loss: 0.0195 - val_MSE: 7.2214e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0185 - train_MSE: 6.7396e-04 - val_loss: 0.0195 - val_MSE: 7.1522e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0185 - train_MSE: 6.7233e-04 - val_loss: 0.0195 - val_MSE: 7.1032e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0185 - train_MSE: 6.7013e-04 - val_loss: 0.0194 - val_MSE: 7.0826e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0184 - train_MSE: 6.6908e-04 - val_loss: 0.0194 - val_MSE: 7.0176e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0184 - train_MSE: 6.6653e-04 - val_loss: 0.0194 - val_MSE: 7.0000e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0184 - train_MSE: 6.6534e-04 - val_loss: 0.0194 - val_MSE: 6.9597e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0184 - train_MSE: 6.6338e-04 - val_loss: 0.0194 - val_MSE: 6.9472e-04\n",
      "epoch:510/1500 - 耗时:0.03分/总15.09分; train_loss 0.0181 train_MSE 0.0007; val_loss 0.0194 val_MSE 0.0007\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0184 - train_MSE: 6.6341e-04 - val_loss: 0.0194 - val_MSE: 6.9471e-04\n",
      "117/117 [==============================] - 2s 18ms/step - train_loss: 0.0183 - train_MSE: 6.6198e-04 - val_loss: 0.0194 - val_MSE: 6.9246e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0183 - train_MSE: 6.5976e-04 - val_loss: 0.0193 - val_MSE: 6.9286e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0183 - train_MSE: 6.5831e-04 - val_loss: 0.0193 - val_MSE: 6.8900e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0183 - train_MSE: 6.5731e-04 - val_loss: 0.0193 - val_MSE: 6.8616e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0182 - train_MSE: 6.5500e-04 - val_loss: 0.0193 - val_MSE: 6.8835e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0182 - train_MSE: 6.5378e-04 - val_loss: 0.0192 - val_MSE: 6.8622e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0182 - train_MSE: 6.5229e-04 - val_loss: 0.0192 - val_MSE: 6.8582e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0182 - train_MSE: 6.5088e-04 - val_loss: 0.0192 - val_MSE: 6.8366e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0181 - train_MSE: 6.4961e-04 - val_loss: 0.0191 - val_MSE: 6.8536e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0181 - train_MSE: 6.4783e-04 - val_loss: 0.0191 - val_MSE: 6.8582e-04\n",
      "epoch:520/1500 - 耗时:0.03分/总15.43分; train_loss 0.0180 train_MSE 0.0007; val_loss 0.0191 val_MSE 0.0007\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0181 - train_MSE: 6.4799e-04 - val_loss: 0.0191 - val_MSE: 6.8583e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0181 - train_MSE: 6.4651e-04 - val_loss: 0.0191 - val_MSE: 6.8851e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0181 - train_MSE: 6.4462e-04 - val_loss: 0.0190 - val_MSE: 6.8802e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0181 - train_MSE: 6.4382e-04 - val_loss: 0.0190 - val_MSE: 6.9165e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0180 - train_MSE: 6.4172e-04 - val_loss: 0.0189 - val_MSE: 6.9381e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0180 - train_MSE: 6.4056e-04 - val_loss: 0.0189 - val_MSE: 6.9847e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0180 - train_MSE: 6.3853e-04 - val_loss: 0.0188 - val_MSE: 7.0516e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0180 - train_MSE: 6.3699e-04 - val_loss: 0.0188 - val_MSE: 7.0156e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0179 - train_MSE: 6.3525e-04 - val_loss: 0.0188 - val_MSE: 7.0732e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0179 - train_MSE: 6.3427e-04 - val_loss: 0.0188 - val_MSE: 7.0641e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0179 - train_MSE: 6.3204e-04 - val_loss: 0.0187 - val_MSE: 7.0705e-04\n",
      "epoch:530/1500 - 耗时:0.03分/总15.76分; train_loss 0.0177 train_MSE 0.0006; val_loss 0.0187 val_MSE 0.0007\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0179 - train_MSE: 6.3214e-04 - val_loss: 0.0187 - val_MSE: 7.0705e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0179 - train_MSE: 6.3050e-04 - val_loss: 0.0187 - val_MSE: 7.0838e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0178 - train_MSE: 6.2899e-04 - val_loss: 0.0187 - val_MSE: 7.0902e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0178 - train_MSE: 6.2727e-04 - val_loss: 0.0187 - val_MSE: 7.0767e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0178 - train_MSE: 6.2573e-04 - val_loss: 0.0187 - val_MSE: 7.0985e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0178 - train_MSE: 6.2403e-04 - val_loss: 0.0187 - val_MSE: 7.0607e-04\n",
      "117/117 [==============================] - 2s 13ms/step - train_loss: 0.0177 - train_MSE: 6.2270e-04 - val_loss: 0.0186 - val_MSE: 7.0632e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0177 - train_MSE: 6.2053e-04 - val_loss: 0.0186 - val_MSE: 7.0593e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0177 - train_MSE: 6.1913e-04 - val_loss: 0.0186 - val_MSE: 7.0133e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0177 - train_MSE: 6.1771e-04 - val_loss: 0.0185 - val_MSE: 6.9484e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0176 - train_MSE: 6.1553e-04 - val_loss: 0.0185 - val_MSE: 6.9031e-04\n",
      "epoch:540/1500 - 耗时:0.03分/总16.08分; train_loss 0.0173 train_MSE 0.0006; val_loss 0.0184 val_MSE 0.0007\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0176 - train_MSE: 6.1545e-04 - val_loss: 0.0185 - val_MSE: 6.9028e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0176 - train_MSE: 6.1402e-04 - val_loss: 0.0184 - val_MSE: 6.8412e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0176 - train_MSE: 6.1193e-04 - val_loss: 0.0184 - val_MSE: 6.7553e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0176 - train_MSE: 6.1052e-04 - val_loss: 0.0183 - val_MSE: 6.6661e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0175 - train_MSE: 6.0848e-04 - val_loss: 0.0182 - val_MSE: 6.6158e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0175 - train_MSE: 6.0773e-04 - val_loss: 0.0182 - val_MSE: 6.5109e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0175 - train_MSE: 6.0520e-04 - val_loss: 0.0181 - val_MSE: 6.4795e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0174 - train_MSE: 6.0384e-04 - val_loss: 0.0180 - val_MSE: 6.4039e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0174 - train_MSE: 6.0177e-04 - val_loss: 0.0180 - val_MSE: 6.3376e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0174 - train_MSE: 6.0058e-04 - val_loss: 0.0180 - val_MSE: 6.2674e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0173 - train_MSE: 5.9861e-04 - val_loss: 0.0180 - val_MSE: 6.2340e-04\n",
      "epoch:550/1500 - 耗时:0.03分/总16.40分; train_loss 0.0170 train_MSE 0.0006; val_loss 0.0180 val_MSE 0.0006\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0173 - train_MSE: 5.9855e-04 - val_loss: 0.0180 - val_MSE: 6.2337e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0173 - train_MSE: 5.9742e-04 - val_loss: 0.0180 - val_MSE: 6.1707e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0173 - train_MSE: 5.9549e-04 - val_loss: 0.0180 - val_MSE: 6.1428e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0173 - train_MSE: 5.9464e-04 - val_loss: 0.0180 - val_MSE: 6.0921e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0172 - train_MSE: 5.9324e-04 - val_loss: 0.0179 - val_MSE: 6.0656e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0172 - train_MSE: 5.9184e-04 - val_loss: 0.0179 - val_MSE: 6.0413e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0172 - train_MSE: 5.9057e-04 - val_loss: 0.0179 - val_MSE: 6.0088e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0172 - train_MSE: 5.8918e-04 - val_loss: 0.0180 - val_MSE: 5.9891e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0171 - train_MSE: 5.8761e-04 - val_loss: 0.0180 - val_MSE: 5.9724e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0171 - train_MSE: 5.8668e-04 - val_loss: 0.0180 - val_MSE: 5.9487e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0171 - train_MSE: 5.8543e-04 - val_loss: 0.0180 - val_MSE: 5.9478e-04\n",
      "epoch:560/1500 - 耗时:0.03分/总16.70分; train_loss 0.0168 train_MSE 0.0006; val_loss 0.0180 val_MSE 0.0006\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0171 - train_MSE: 5.8535e-04 - val_loss: 0.0180 - val_MSE: 5.9478e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0171 - train_MSE: 5.8409e-04 - val_loss: 0.0180 - val_MSE: 5.9291e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0171 - train_MSE: 5.8287e-04 - val_loss: 0.0180 - val_MSE: 5.9276e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0170 - train_MSE: 5.8154e-04 - val_loss: 0.0180 - val_MSE: 5.9155e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0170 - train_MSE: 5.8061e-04 - val_loss: 0.0179 - val_MSE: 5.9054e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0170 - train_MSE: 5.7923e-04 - val_loss: 0.0179 - val_MSE: 5.9110e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0170 - train_MSE: 5.7771e-04 - val_loss: 0.0179 - val_MSE: 5.9066e-04\n",
      "117/117 [==============================] - 2s 18ms/step - train_loss: 0.0170 - train_MSE: 5.7648e-04 - val_loss: 0.0178 - val_MSE: 5.9007e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0169 - train_MSE: 5.7624e-04 - val_loss: 0.0178 - val_MSE: 5.8856e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0169 - train_MSE: 5.7421e-04 - val_loss: 0.0178 - val_MSE: 5.9080e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0169 - train_MSE: 5.7351e-04 - val_loss: 0.0177 - val_MSE: 5.9148e-04\n",
      "epoch:570/1500 - 耗时:0.03分/总17.02分; train_loss 0.0167 train_MSE 0.0006; val_loss 0.0177 val_MSE 0.0006\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0169 - train_MSE: 5.7358e-04 - val_loss: 0.0177 - val_MSE: 5.9149e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0169 - train_MSE: 5.7244e-04 - val_loss: 0.0177 - val_MSE: 5.9349e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0169 - train_MSE: 5.7098e-04 - val_loss: 0.0176 - val_MSE: 5.9371e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0169 - train_MSE: 5.6990e-04 - val_loss: 0.0176 - val_MSE: 5.9652e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0168 - train_MSE: 5.6886e-04 - val_loss: 0.0175 - val_MSE: 5.9991e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0168 - train_MSE: 5.6761e-04 - val_loss: 0.0175 - val_MSE: 6.0119e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0168 - train_MSE: 5.6623e-04 - val_loss: 0.0174 - val_MSE: 6.0268e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0168 - train_MSE: 5.6473e-04 - val_loss: 0.0174 - val_MSE: 6.0696e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0167 - train_MSE: 5.6334e-04 - val_loss: 0.0174 - val_MSE: 6.1227e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0167 - train_MSE: 5.6141e-04 - val_loss: 0.0174 - val_MSE: 6.1433e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0167 - train_MSE: 5.6057e-04 - val_loss: 0.0173 - val_MSE: 6.1601e-04\n",
      "epoch:580/1500 - 耗时:0.03分/总17.34分; train_loss 0.0165 train_MSE 0.0006; val_loss 0.0173 val_MSE 0.0006\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0167 - train_MSE: 5.6061e-04 - val_loss: 0.0173 - val_MSE: 6.1602e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0167 - train_MSE: 5.5924e-04 - val_loss: 0.0173 - val_MSE: 6.1851e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0167 - train_MSE: 5.5716e-04 - val_loss: 0.0173 - val_MSE: 6.2058e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0167 - train_MSE: 5.5616e-04 - val_loss: 0.0173 - val_MSE: 6.2327e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0166 - train_MSE: 5.5464e-04 - val_loss: 0.0173 - val_MSE: 6.2094e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0166 - train_MSE: 5.5300e-04 - val_loss: 0.0173 - val_MSE: 6.2397e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0166 - train_MSE: 5.5276e-04 - val_loss: 0.0173 - val_MSE: 6.1769e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0166 - train_MSE: 5.5088e-04 - val_loss: 0.0173 - val_MSE: 6.1825e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0166 - train_MSE: 5.4976e-04 - val_loss: 0.0173 - val_MSE: 6.1682e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0165 - train_MSE: 5.4851e-04 - val_loss: 0.0172 - val_MSE: 6.1094e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0165 - train_MSE: 5.4791e-04 - val_loss: 0.0171 - val_MSE: 6.0480e-04\n",
      "epoch:590/1500 - 耗时:0.03分/总17.65分; train_loss 0.0162 train_MSE 0.0005; val_loss 0.0171 val_MSE 0.0006\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0165 - train_MSE: 5.4772e-04 - val_loss: 0.0171 - val_MSE: 6.0478e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0165 - train_MSE: 5.4588e-04 - val_loss: 0.0171 - val_MSE: 6.0026e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0165 - train_MSE: 5.4480e-04 - val_loss: 0.0170 - val_MSE: 5.9276e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0165 - train_MSE: 5.4369e-04 - val_loss: 0.0169 - val_MSE: 5.8560e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0164 - train_MSE: 5.4292e-04 - val_loss: 0.0169 - val_MSE: 5.7737e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0164 - train_MSE: 5.4128e-04 - val_loss: 0.0168 - val_MSE: 5.6918e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0164 - train_MSE: 5.3981e-04 - val_loss: 0.0168 - val_MSE: 5.6240e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0164 - train_MSE: 5.3830e-04 - val_loss: 0.0167 - val_MSE: 5.5826e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0163 - train_MSE: 5.3697e-04 - val_loss: 0.0167 - val_MSE: 5.4995e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0163 - train_MSE: 5.3528e-04 - val_loss: 0.0167 - val_MSE: 5.4477e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0163 - train_MSE: 5.3402e-04 - val_loss: 0.0166 - val_MSE: 5.4015e-04\n",
      "epoch:600/1500 - 耗时:0.03分/总17.98分; train_loss 0.0159 train_MSE 0.0005; val_loss 0.0166 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0163 - train_MSE: 5.3394e-04 - val_loss: 0.0166 - val_MSE: 5.4013e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0162 - train_MSE: 5.3222e-04 - val_loss: 0.0166 - val_MSE: 5.3551e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0162 - train_MSE: 5.3049e-04 - val_loss: 0.0166 - val_MSE: 5.3437e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0162 - train_MSE: 5.2978e-04 - val_loss: 0.0166 - val_MSE: 5.2947e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0161 - train_MSE: 5.2850e-04 - val_loss: 0.0167 - val_MSE: 5.2730e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0161 - train_MSE: 5.2706e-04 - val_loss: 0.0167 - val_MSE: 5.2585e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0161 - train_MSE: 5.2654e-04 - val_loss: 0.0167 - val_MSE: 5.2261e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0161 - train_MSE: 5.2515e-04 - val_loss: 0.0167 - val_MSE: 5.2177e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0161 - train_MSE: 5.2411e-04 - val_loss: 0.0167 - val_MSE: 5.2001e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0161 - train_MSE: 5.2297e-04 - val_loss: 0.0168 - val_MSE: 5.1934e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0160 - train_MSE: 5.2215e-04 - val_loss: 0.0168 - val_MSE: 5.1843e-04\n",
      "epoch:610/1500 - 耗时:0.03分/总18.27分; train_loss 0.0157 train_MSE 0.0005; val_loss 0.0168 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0160 - train_MSE: 5.2206e-04 - val_loss: 0.0168 - val_MSE: 5.1843e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0160 - train_MSE: 5.2105e-04 - val_loss: 0.0168 - val_MSE: 5.1792e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0160 - train_MSE: 5.1985e-04 - val_loss: 0.0168 - val_MSE: 5.1755e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0160 - train_MSE: 5.1891e-04 - val_loss: 0.0168 - val_MSE: 5.1766e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0160 - train_MSE: 5.1839e-04 - val_loss: 0.0168 - val_MSE: 5.1622e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0159 - train_MSE: 5.1743e-04 - val_loss: 0.0168 - val_MSE: 5.1694e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0159 - train_MSE: 5.1639e-04 - val_loss: 0.0168 - val_MSE: 5.1533e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0159 - train_MSE: 5.1621e-04 - val_loss: 0.0167 - val_MSE: 5.1678e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0159 - train_MSE: 5.1464e-04 - val_loss: 0.0167 - val_MSE: 5.1630e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0159 - train_MSE: 5.1430e-04 - val_loss: 0.0166 - val_MSE: 5.1724e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0159 - train_MSE: 5.1274e-04 - val_loss: 0.0166 - val_MSE: 5.1709e-04\n",
      "epoch:620/1500 - 耗时:0.03分/总18.57分; train_loss 0.0156 train_MSE 0.0005; val_loss 0.0166 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0159 - train_MSE: 5.1276e-04 - val_loss: 0.0166 - val_MSE: 5.1709e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0159 - train_MSE: 5.1290e-04 - val_loss: 0.0166 - val_MSE: 5.1835e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0159 - train_MSE: 5.1108e-04 - val_loss: 0.0165 - val_MSE: 5.2011e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0158 - train_MSE: 5.1088e-04 - val_loss: 0.0165 - val_MSE: 5.1887e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0158 - train_MSE: 5.0953e-04 - val_loss: 0.0164 - val_MSE: 5.2074e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0158 - train_MSE: 5.0848e-04 - val_loss: 0.0163 - val_MSE: 5.2154e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0158 - train_MSE: 5.0631e-04 - val_loss: 0.0163 - val_MSE: 5.2457e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0158 - train_MSE: 5.0637e-04 - val_loss: 0.0162 - val_MSE: 5.2333e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0157 - train_MSE: 5.0474e-04 - val_loss: 0.0162 - val_MSE: 5.2717e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0157 - train_MSE: 5.0384e-04 - val_loss: 0.0162 - val_MSE: 5.2989e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0157 - train_MSE: 5.0255e-04 - val_loss: 0.0161 - val_MSE: 5.3641e-04\n",
      "epoch:630/1500 - 耗时:0.03分/总18.90分; train_loss 0.0155 train_MSE 0.0005; val_loss 0.0161 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0157 - train_MSE: 5.0256e-04 - val_loss: 0.0161 - val_MSE: 5.3642e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0157 - train_MSE: 5.0179e-04 - val_loss: 0.0161 - val_MSE: 5.3776e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0157 - train_MSE: 5.0014e-04 - val_loss: 0.0161 - val_MSE: 5.4401e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0157 - train_MSE: 4.9890e-04 - val_loss: 0.0162 - val_MSE: 5.4589e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0156 - train_MSE: 4.9807e-04 - val_loss: 0.0162 - val_MSE: 5.4871e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0156 - train_MSE: 4.9644e-04 - val_loss: 0.0162 - val_MSE: 5.4921e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0156 - train_MSE: 4.9570e-04 - val_loss: 0.0162 - val_MSE: 5.5211e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0156 - train_MSE: 4.9439e-04 - val_loss: 0.0162 - val_MSE: 5.5201e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0156 - train_MSE: 4.9355e-04 - val_loss: 0.0162 - val_MSE: 5.5114e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0156 - train_MSE: 4.9279e-04 - val_loss: 0.0161 - val_MSE: 5.4602e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0156 - train_MSE: 4.9168e-04 - val_loss: 0.0161 - val_MSE: 5.4450e-04\n",
      "epoch:640/1500 - 耗时:0.03分/总19.19分; train_loss 0.0152 train_MSE 0.0005; val_loss 0.0160 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0156 - train_MSE: 4.9155e-04 - val_loss: 0.0161 - val_MSE: 5.4448e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0156 - train_MSE: 4.9092e-04 - val_loss: 0.0160 - val_MSE: 5.3939e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0155 - train_MSE: 4.9032e-04 - val_loss: 0.0160 - val_MSE: 5.3313e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0155 - train_MSE: 4.8957e-04 - val_loss: 0.0159 - val_MSE: 5.2641e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0155 - train_MSE: 4.8866e-04 - val_loss: 0.0158 - val_MSE: 5.2232e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0155 - train_MSE: 4.8807e-04 - val_loss: 0.0158 - val_MSE: 5.1450e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0155 - train_MSE: 4.8676e-04 - val_loss: 0.0157 - val_MSE: 5.0852e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0155 - train_MSE: 4.8583e-04 - val_loss: 0.0157 - val_MSE: 5.0302e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0154 - train_MSE: 4.8467e-04 - val_loss: 0.0157 - val_MSE: 4.9811e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0154 - train_MSE: 4.8319e-04 - val_loss: 0.0156 - val_MSE: 4.9126e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0154 - train_MSE: 4.8132e-04 - val_loss: 0.0156 - val_MSE: 4.8692e-04\n",
      "epoch:650/1500 - 耗时:0.03分/总19.53分; train_loss 0.0150 train_MSE 0.0005; val_loss 0.0156 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0154 - train_MSE: 4.8123e-04 - val_loss: 0.0156 - val_MSE: 4.8690e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0153 - train_MSE: 4.8050e-04 - val_loss: 0.0156 - val_MSE: 4.8101e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0153 - train_MSE: 4.7910e-04 - val_loss: 0.0155 - val_MSE: 4.7595e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0153 - train_MSE: 4.7782e-04 - val_loss: 0.0155 - val_MSE: 4.7199e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0153 - train_MSE: 4.7653e-04 - val_loss: 0.0155 - val_MSE: 4.6837e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0152 - train_MSE: 4.7526e-04 - val_loss: 0.0155 - val_MSE: 4.6640e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0152 - train_MSE: 4.7422e-04 - val_loss: 0.0155 - val_MSE: 4.6444e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0152 - train_MSE: 4.7275e-04 - val_loss: 0.0155 - val_MSE: 4.6277e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0152 - train_MSE: 4.7186e-04 - val_loss: 0.0156 - val_MSE: 4.6132e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0151 - train_MSE: 4.7116e-04 - val_loss: 0.0156 - val_MSE: 4.6021e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0151 - train_MSE: 4.7047e-04 - val_loss: 0.0156 - val_MSE: 4.5971e-04\n",
      "epoch:660/1500 - 耗时:0.03分/总19.82分; train_loss 0.0147 train_MSE 0.0005; val_loss 0.0157 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0151 - train_MSE: 4.7027e-04 - val_loss: 0.0156 - val_MSE: 4.5971e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0151 - train_MSE: 4.6955e-04 - val_loss: 0.0157 - val_MSE: 4.5848e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0151 - train_MSE: 4.6863e-04 - val_loss: 0.0158 - val_MSE: 4.5840e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0151 - train_MSE: 4.6782e-04 - val_loss: 0.0157 - val_MSE: 4.5774e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0151 - train_MSE: 4.6731e-04 - val_loss: 0.0158 - val_MSE: 4.5754e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0151 - train_MSE: 4.6653e-04 - val_loss: 0.0158 - val_MSE: 4.5832e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0150 - train_MSE: 4.6546e-04 - val_loss: 0.0158 - val_MSE: 4.5769e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0150 - train_MSE: 4.6529e-04 - val_loss: 0.0157 - val_MSE: 4.5673e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0150 - train_MSE: 4.6430e-04 - val_loss: 0.0158 - val_MSE: 4.5735e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0150 - train_MSE: 4.6338e-04 - val_loss: 0.0158 - val_MSE: 4.5795e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0150 - train_MSE: 4.6319e-04 - val_loss: 0.0156 - val_MSE: 4.5659e-04\n",
      "epoch:670/1500 - 耗时:0.03分/总20.10分; train_loss 0.0147 train_MSE 0.0005; val_loss 0.0157 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0150 - train_MSE: 4.6318e-04 - val_loss: 0.0156 - val_MSE: 4.5660e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0150 - train_MSE: 4.6236e-04 - val_loss: 0.0157 - val_MSE: 4.5930e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0150 - train_MSE: 4.6123e-04 - val_loss: 0.0156 - val_MSE: 4.5916e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0150 - train_MSE: 4.6119e-04 - val_loss: 0.0155 - val_MSE: 4.5966e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0149 - train_MSE: 4.6036e-04 - val_loss: 0.0155 - val_MSE: 4.6005e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0149 - train_MSE: 4.5940e-04 - val_loss: 0.0155 - val_MSE: 4.6108e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0149 - train_MSE: 4.5881e-04 - val_loss: 0.0154 - val_MSE: 4.6078e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0149 - train_MSE: 4.5822e-04 - val_loss: 0.0154 - val_MSE: 4.6271e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0149 - train_MSE: 4.5664e-04 - val_loss: 0.0153 - val_MSE: 4.6252e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0149 - train_MSE: 4.5592e-04 - val_loss: 0.0153 - val_MSE: 4.6524e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0148 - train_MSE: 4.5476e-04 - val_loss: 0.0152 - val_MSE: 4.6515e-04\n",
      "epoch:680/1500 - 耗时:0.03分/总20.41分; train_loss 0.0146 train_MSE 0.0005; val_loss 0.0152 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0148 - train_MSE: 4.5478e-04 - val_loss: 0.0152 - val_MSE: 4.6516e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0148 - train_MSE: 4.5380e-04 - val_loss: 0.0152 - val_MSE: 4.6787e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0148 - train_MSE: 4.5212e-04 - val_loss: 0.0151 - val_MSE: 4.7093e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0148 - train_MSE: 4.5223e-04 - val_loss: 0.0151 - val_MSE: 4.7406e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0148 - train_MSE: 4.5040e-04 - val_loss: 0.0151 - val_MSE: 4.7855e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0148 - train_MSE: 4.4928e-04 - val_loss: 0.0151 - val_MSE: 4.8240e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0147 - train_MSE: 4.4831e-04 - val_loss: 0.0151 - val_MSE: 4.8498e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0147 - train_MSE: 4.4749e-04 - val_loss: 0.0152 - val_MSE: 4.8747e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0147 - train_MSE: 4.4604e-04 - val_loss: 0.0152 - val_MSE: 4.9132e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0147 - train_MSE: 4.4571e-04 - val_loss: 0.0153 - val_MSE: 4.9314e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0147 - train_MSE: 4.4507e-04 - val_loss: 0.0152 - val_MSE: 4.9226e-04\n",
      "epoch:690/1500 - 耗时:0.03分/总20.70分; train_loss 0.0143 train_MSE 0.0004; val_loss 0.0152 val_MSE 0.0005\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0147 - train_MSE: 4.4492e-04 - val_loss: 0.0152 - val_MSE: 4.9225e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0147 - train_MSE: 4.4388e-04 - val_loss: 0.0152 - val_MSE: 4.8980e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0147 - train_MSE: 4.4350e-04 - val_loss: 0.0152 - val_MSE: 4.8639e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0147 - train_MSE: 4.4322e-04 - val_loss: 0.0151 - val_MSE: 4.8034e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0147 - train_MSE: 4.4280e-04 - val_loss: 0.0150 - val_MSE: 4.7612e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0147 - train_MSE: 4.4193e-04 - val_loss: 0.0149 - val_MSE: 4.6961e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0147 - train_MSE: 4.4137e-04 - val_loss: 0.0148 - val_MSE: 4.6488e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0147 - train_MSE: 4.4116e-04 - val_loss: 0.0147 - val_MSE: 4.5698e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0147 - train_MSE: 4.4035e-04 - val_loss: 0.0146 - val_MSE: 4.5118e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0147 - train_MSE: 4.3996e-04 - val_loss: 0.0146 - val_MSE: 4.4488e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0146 - train_MSE: 4.3952e-04 - val_loss: 0.0146 - val_MSE: 4.3905e-04\n",
      "epoch:700/1500 - 耗时:0.03分/总21.02分; train_loss 0.0143 train_MSE 0.0004; val_loss 0.0146 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0146 - train_MSE: 4.3928e-04 - val_loss: 0.0146 - val_MSE: 4.3904e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0146 - train_MSE: 4.3808e-04 - val_loss: 0.0146 - val_MSE: 4.3658e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0146 - train_MSE: 4.3658e-04 - val_loss: 0.0146 - val_MSE: 4.3335e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0145 - train_MSE: 4.3504e-04 - val_loss: 0.0146 - val_MSE: 4.3070e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0145 - train_MSE: 4.3330e-04 - val_loss: 0.0145 - val_MSE: 4.2716e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0145 - train_MSE: 4.3232e-04 - val_loss: 0.0145 - val_MSE: 4.2466e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0144 - train_MSE: 4.3164e-04 - val_loss: 0.0145 - val_MSE: 4.2264e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0144 - train_MSE: 4.3038e-04 - val_loss: 0.0146 - val_MSE: 4.2106e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0144 - train_MSE: 4.2927e-04 - val_loss: 0.0146 - val_MSE: 4.1880e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0144 - train_MSE: 4.2821e-04 - val_loss: 0.0146 - val_MSE: 4.1776e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0143 - train_MSE: 4.2791e-04 - val_loss: 0.0146 - val_MSE: 4.1674e-04\n",
      "epoch:710/1500 - 耗时:0.03分/总21.31分; train_loss 0.0139 train_MSE 0.0004; val_loss 0.0146 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0143 - train_MSE: 4.2768e-04 - val_loss: 0.0146 - val_MSE: 4.1674e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0143 - train_MSE: 4.2633e-04 - val_loss: 0.0146 - val_MSE: 4.1478e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0143 - train_MSE: 4.2578e-04 - val_loss: 0.0146 - val_MSE: 4.1420e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0143 - train_MSE: 4.2498e-04 - val_loss: 0.0146 - val_MSE: 4.1373e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0143 - train_MSE: 4.2427e-04 - val_loss: 0.0147 - val_MSE: 4.1232e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0143 - train_MSE: 4.2332e-04 - val_loss: 0.0147 - val_MSE: 4.1265e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0142 - train_MSE: 4.2318e-04 - val_loss: 0.0147 - val_MSE: 4.1189e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0142 - train_MSE: 4.2293e-04 - val_loss: 0.0148 - val_MSE: 4.1153e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0142 - train_MSE: 4.2146e-04 - val_loss: 0.0148 - val_MSE: 4.1097e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0142 - train_MSE: 4.2128e-04 - val_loss: 0.0147 - val_MSE: 4.1013e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0142 - train_MSE: 4.2118e-04 - val_loss: 0.0147 - val_MSE: 4.1033e-04\n",
      "epoch:720/1500 - 耗时:0.03分/总21.59分; train_loss 0.0138 train_MSE 0.0004; val_loss 0.0148 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0142 - train_MSE: 4.2107e-04 - val_loss: 0.0147 - val_MSE: 4.1033e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0142 - train_MSE: 4.1972e-04 - val_loss: 0.0148 - val_MSE: 4.1040e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0142 - train_MSE: 4.1970e-04 - val_loss: 0.0147 - val_MSE: 4.0948e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0142 - train_MSE: 4.1887e-04 - val_loss: 0.0146 - val_MSE: 4.0907e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0141 - train_MSE: 4.1797e-04 - val_loss: 0.0146 - val_MSE: 4.0904e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0142 - train_MSE: 4.1744e-04 - val_loss: 0.0145 - val_MSE: 4.0784e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0141 - train_MSE: 4.1763e-04 - val_loss: 0.0145 - val_MSE: 4.0704e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0141 - train_MSE: 4.1591e-04 - val_loss: 0.0145 - val_MSE: 4.0857e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0141 - train_MSE: 4.1604e-04 - val_loss: 0.0144 - val_MSE: 4.0716e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0141 - train_MSE: 4.1514e-04 - val_loss: 0.0143 - val_MSE: 4.0829e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0141 - train_MSE: 4.1459e-04 - val_loss: 0.0143 - val_MSE: 4.1035e-04\n",
      "epoch:730/1500 - 耗时:0.03分/总21.91分; train_loss 0.0138 train_MSE 0.0004; val_loss 0.0142 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0141 - train_MSE: 4.1455e-04 - val_loss: 0.0143 - val_MSE: 4.1035e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0141 - train_MSE: 4.1365e-04 - val_loss: 0.0142 - val_MSE: 4.0992e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0141 - train_MSE: 4.1337e-04 - val_loss: 0.0141 - val_MSE: 4.1041e-04\n",
      "117/117 [==============================] - 3s 27ms/step - train_loss: 0.0140 - train_MSE: 4.1198e-04 - val_loss: 0.0141 - val_MSE: 4.1254e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0140 - train_MSE: 4.1137e-04 - val_loss: 0.0140 - val_MSE: 4.1191e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0140 - train_MSE: 4.1059e-04 - val_loss: 0.0140 - val_MSE: 4.1502e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0140 - train_MSE: 4.0960e-04 - val_loss: 0.0140 - val_MSE: 4.1641e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0140 - train_MSE: 4.0876e-04 - val_loss: 0.0140 - val_MSE: 4.2260e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0140 - train_MSE: 4.0847e-04 - val_loss: 0.0140 - val_MSE: 4.2574e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0700e-04 - val_loss: 0.0141 - val_MSE: 4.2893e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0139 - train_MSE: 4.0662e-04 - val_loss: 0.0141 - val_MSE: 4.3394e-04\n",
      "epoch:740/1500 - 耗时:0.03分/总22.24分; train_loss 0.0136 train_MSE 0.0004; val_loss 0.0142 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0659e-04 - val_loss: 0.0141 - val_MSE: 4.3397e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0514e-04 - val_loss: 0.0142 - val_MSE: 4.3986e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0461e-04 - val_loss: 0.0143 - val_MSE: 4.4020e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0345e-04 - val_loss: 0.0143 - val_MSE: 4.4312e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0336e-04 - val_loss: 0.0143 - val_MSE: 4.4234e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0220e-04 - val_loss: 0.0144 - val_MSE: 4.4520e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0227e-04 - val_loss: 0.0144 - val_MSE: 4.4365e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0164e-04 - val_loss: 0.0144 - val_MSE: 4.4081e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0123e-04 - val_loss: 0.0144 - val_MSE: 4.3801e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0139 - train_MSE: 4.0059e-04 - val_loss: 0.0142 - val_MSE: 4.3117e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0139 - train_MSE: 4.0124e-04 - val_loss: 0.0142 - val_MSE: 4.2576e-04\n",
      "epoch:750/1500 - 耗时:0.03分/总22.53分; train_loss 0.0136 train_MSE 0.0004; val_loss 0.0139 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0139 - train_MSE: 4.0074e-04 - val_loss: 0.0142 - val_MSE: 4.2571e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0139 - train_MSE: 3.9971e-04 - val_loss: 0.0139 - val_MSE: 4.1407e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0139 - train_MSE: 4.0020e-04 - val_loss: 0.0137 - val_MSE: 4.0440e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0139 - train_MSE: 3.9921e-04 - val_loss: 0.0137 - val_MSE: 3.9791e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0139 - train_MSE: 3.9819e-04 - val_loss: 0.0136 - val_MSE: 3.9251e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0138 - train_MSE: 3.9709e-04 - val_loss: 0.0135 - val_MSE: 3.8391e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0138 - train_MSE: 3.9626e-04 - val_loss: 0.0135 - val_MSE: 3.8207e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0138 - train_MSE: 3.9445e-04 - val_loss: 0.0135 - val_MSE: 3.7864e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0138 - train_MSE: 3.9358e-04 - val_loss: 0.0136 - val_MSE: 3.7509e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0137 - train_MSE: 3.9227e-04 - val_loss: 0.0136 - val_MSE: 3.7394e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0137 - train_MSE: 3.9069e-04 - val_loss: 0.0137 - val_MSE: 3.7086e-04\n",
      "epoch:760/1500 - 耗时:0.03分/总22.83分; train_loss 0.0133 train_MSE 0.0004; val_loss 0.0137 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0137 - train_MSE: 3.9044e-04 - val_loss: 0.0137 - val_MSE: 3.7086e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0137 - train_MSE: 3.8938e-04 - val_loss: 0.0137 - val_MSE: 3.7022e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0136 - train_MSE: 3.8859e-04 - val_loss: 0.0138 - val_MSE: 3.6939e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0136 - train_MSE: 3.8700e-04 - val_loss: 0.0139 - val_MSE: 3.6989e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0136 - train_MSE: 3.8653e-04 - val_loss: 0.0139 - val_MSE: 3.7034e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0136 - train_MSE: 3.8591e-04 - val_loss: 0.0140 - val_MSE: 3.7019e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8488e-04 - val_loss: 0.0141 - val_MSE: 3.7194e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8438e-04 - val_loss: 0.0142 - val_MSE: 3.7277e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8431e-04 - val_loss: 0.0142 - val_MSE: 3.7329e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8341e-04 - val_loss: 0.0145 - val_MSE: 3.7821e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0135 - train_MSE: 3.8328e-04 - val_loss: 0.0145 - val_MSE: 3.7771e-04\n",
      "epoch:770/1500 - 耗时:0.03分/总23.11分; train_loss 0.0131 train_MSE 0.0004; val_loss 0.0145 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8300e-04 - val_loss: 0.0145 - val_MSE: 3.7771e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8277e-04 - val_loss: 0.0145 - val_MSE: 3.7772e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8279e-04 - val_loss: 0.0147 - val_MSE: 3.8151e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8245e-04 - val_loss: 0.0146 - val_MSE: 3.8013e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8324e-04 - val_loss: 0.0145 - val_MSE: 3.7913e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8266e-04 - val_loss: 0.0145 - val_MSE: 3.7914e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0136 - train_MSE: 3.8303e-04 - val_loss: 0.0143 - val_MSE: 3.7674e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0136 - train_MSE: 3.8324e-04 - val_loss: 0.0142 - val_MSE: 3.7673e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0136 - train_MSE: 3.8291e-04 - val_loss: 0.0141 - val_MSE: 3.7726e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0136 - train_MSE: 3.8190e-04 - val_loss: 0.0139 - val_MSE: 3.7652e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0135 - train_MSE: 3.8156e-04 - val_loss: 0.0139 - val_MSE: 3.7624e-04\n",
      "epoch:780/1500 - 耗时:0.03分/总23.40分; train_loss 0.0135 train_MSE 0.0004; val_loss 0.0137 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8162e-04 - val_loss: 0.0139 - val_MSE: 3.7624e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0135 - train_MSE: 3.8003e-04 - val_loss: 0.0137 - val_MSE: 3.7607e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0135 - train_MSE: 3.7951e-04 - val_loss: 0.0136 - val_MSE: 3.7508e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0135 - train_MSE: 3.7873e-04 - val_loss: 0.0135 - val_MSE: 3.7461e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0135 - train_MSE: 3.7899e-04 - val_loss: 0.0135 - val_MSE: 3.7591e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0134 - train_MSE: 3.7711e-04 - val_loss: 0.0133 - val_MSE: 3.7732e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0134 - train_MSE: 3.7693e-04 - val_loss: 0.0133 - val_MSE: 3.8005e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0134 - train_MSE: 3.7613e-04 - val_loss: 0.0133 - val_MSE: 3.8110e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0134 - train_MSE: 3.7572e-04 - val_loss: 0.0133 - val_MSE: 3.8440e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0134 - train_MSE: 3.7446e-04 - val_loss: 0.0134 - val_MSE: 3.9186e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0134 - train_MSE: 3.7406e-04 - val_loss: 0.0135 - val_MSE: 3.9627e-04\n",
      "epoch:790/1500 - 耗时:0.03分/总23.71分; train_loss 0.0132 train_MSE 0.0004; val_loss 0.0136 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0134 - train_MSE: 3.7404e-04 - val_loss: 0.0135 - val_MSE: 3.9629e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0133 - train_MSE: 3.7291e-04 - val_loss: 0.0136 - val_MSE: 4.0354e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0133 - train_MSE: 3.7268e-04 - val_loss: 0.0137 - val_MSE: 4.0654e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0133 - train_MSE: 3.7170e-04 - val_loss: 0.0138 - val_MSE: 4.1119e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0133 - train_MSE: 3.7184e-04 - val_loss: 0.0139 - val_MSE: 4.1410e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0133 - train_MSE: 3.7150e-04 - val_loss: 0.0140 - val_MSE: 4.1882e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0133 - train_MSE: 3.7140e-04 - val_loss: 0.0140 - val_MSE: 4.1947e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0134 - train_MSE: 3.7155e-04 - val_loss: 0.0140 - val_MSE: 4.1775e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0134 - train_MSE: 3.7152e-04 - val_loss: 0.0140 - val_MSE: 4.1273e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0134 - train_MSE: 3.7168e-04 - val_loss: 0.0139 - val_MSE: 4.0887e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0134 - train_MSE: 3.7101e-04 - val_loss: 0.0138 - val_MSE: 4.0098e-04\n",
      "epoch:800/1500 - 耗时:0.03分/总23.99分; train_loss 0.0131 train_MSE 0.0004; val_loss 0.0136 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0134 - train_MSE: 3.7094e-04 - val_loss: 0.0138 - val_MSE: 4.0095e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0134 - train_MSE: 3.7080e-04 - val_loss: 0.0136 - val_MSE: 3.9525e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0134 - train_MSE: 3.7022e-04 - val_loss: 0.0134 - val_MSE: 3.8485e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0134 - train_MSE: 3.6969e-04 - val_loss: 0.0133 - val_MSE: 3.7885e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0133 - train_MSE: 3.6911e-04 - val_loss: 0.0130 - val_MSE: 3.6674e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0134 - train_MSE: 3.6900e-04 - val_loss: 0.0129 - val_MSE: 3.5917e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0133 - train_MSE: 3.6747e-04 - val_loss: 0.0129 - val_MSE: 3.5269e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0133 - train_MSE: 3.6635e-04 - val_loss: 0.0128 - val_MSE: 3.4743e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0132 - train_MSE: 3.6471e-04 - val_loss: 0.0129 - val_MSE: 3.4476e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0132 - train_MSE: 3.6350e-04 - val_loss: 0.0129 - val_MSE: 3.4406e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0132 - train_MSE: 3.6200e-04 - val_loss: 0.0129 - val_MSE: 3.4210e-04\n",
      "epoch:810/1500 - 耗时:0.03分/总24.30分; train_loss 0.0129 train_MSE 0.0003; val_loss 0.0130 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0132 - train_MSE: 3.6179e-04 - val_loss: 0.0129 - val_MSE: 3.4210e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0131 - train_MSE: 3.6042e-04 - val_loss: 0.0130 - val_MSE: 3.4066e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0131 - train_MSE: 3.5898e-04 - val_loss: 0.0130 - val_MSE: 3.3975e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0130 - train_MSE: 3.5745e-04 - val_loss: 0.0130 - val_MSE: 3.3858e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0130 - train_MSE: 3.5659e-04 - val_loss: 0.0131 - val_MSE: 3.3923e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0130 - train_MSE: 3.5563e-04 - val_loss: 0.0132 - val_MSE: 3.3883e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0130 - train_MSE: 3.5497e-04 - val_loss: 0.0132 - val_MSE: 3.3937e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5450e-04 - val_loss: 0.0133 - val_MSE: 3.3999e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5403e-04 - val_loss: 0.0134 - val_MSE: 3.4163e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5343e-04 - val_loss: 0.0135 - val_MSE: 3.4268e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0129 - train_MSE: 3.5309e-04 - val_loss: 0.0136 - val_MSE: 3.4441e-04\n",
      "epoch:820/1500 - 耗时:0.03分/总24.59分; train_loss 0.0125 train_MSE 0.0003; val_loss 0.0136 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5304e-04 - val_loss: 0.0136 - val_MSE: 3.4441e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5284e-04 - val_loss: 0.0136 - val_MSE: 3.4445e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5248e-04 - val_loss: 0.0138 - val_MSE: 3.4813e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5237e-04 - val_loss: 0.0138 - val_MSE: 3.4793e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5219e-04 - val_loss: 0.0139 - val_MSE: 3.4885e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5154e-04 - val_loss: 0.0139 - val_MSE: 3.5047e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5192e-04 - val_loss: 0.0138 - val_MSE: 3.4859e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5165e-04 - val_loss: 0.0139 - val_MSE: 3.5075e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5158e-04 - val_loss: 0.0139 - val_MSE: 3.5099e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5147e-04 - val_loss: 0.0137 - val_MSE: 3.4810e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0129 - train_MSE: 3.5139e-04 - val_loss: 0.0136 - val_MSE: 3.4844e-04\n",
      "epoch:830/1500 - 耗时:0.03分/总24.87分; train_loss 0.0128 train_MSE 0.0004; val_loss 0.0136 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5140e-04 - val_loss: 0.0136 - val_MSE: 3.4844e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5099e-04 - val_loss: 0.0136 - val_MSE: 3.4772e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5042e-04 - val_loss: 0.0133 - val_MSE: 3.4539e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.5070e-04 - val_loss: 0.0132 - val_MSE: 3.4495e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.4988e-04 - val_loss: 0.0132 - val_MSE: 3.4613e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.4924e-04 - val_loss: 0.0130 - val_MSE: 3.4560e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.4861e-04 - val_loss: 0.0129 - val_MSE: 3.4576e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0129 - train_MSE: 3.4841e-04 - val_loss: 0.0129 - val_MSE: 3.4561e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4774e-04 - val_loss: 0.0127 - val_MSE: 3.4513e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0128 - train_MSE: 3.4741e-04 - val_loss: 0.0127 - val_MSE: 3.4928e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0128 - train_MSE: 3.4607e-04 - val_loss: 0.0126 - val_MSE: 3.4965e-04\n",
      "epoch:840/1500 - 耗时:0.03分/总25.17分; train_loss 0.0127 train_MSE 0.0003; val_loss 0.0127 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4608e-04 - val_loss: 0.0126 - val_MSE: 3.4966e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4633e-04 - val_loss: 0.0127 - val_MSE: 3.5270e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4586e-04 - val_loss: 0.0127 - val_MSE: 3.5769e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4473e-04 - val_loss: 0.0129 - val_MSE: 3.6629e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4444e-04 - val_loss: 0.0130 - val_MSE: 3.7081e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4397e-04 - val_loss: 0.0132 - val_MSE: 3.7769e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4331e-04 - val_loss: 0.0133 - val_MSE: 3.8427e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4330e-04 - val_loss: 0.0134 - val_MSE: 3.8608e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4319e-04 - val_loss: 0.0134 - val_MSE: 3.8662e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4322e-04 - val_loss: 0.0136 - val_MSE: 3.9014e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0128 - train_MSE: 3.4334e-04 - val_loss: 0.0136 - val_MSE: 3.9050e-04\n",
      "epoch:850/1500 - 耗时:0.03分/总25.45分; train_loss 0.0126 train_MSE 0.0003; val_loss 0.0135 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4299e-04 - val_loss: 0.0136 - val_MSE: 3.9049e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.4385e-04 - val_loss: 0.0135 - val_MSE: 3.8667e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.4391e-04 - val_loss: 0.0134 - val_MSE: 3.7767e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0129 - train_MSE: 3.4392e-04 - val_loss: 0.0131 - val_MSE: 3.6779e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0129 - train_MSE: 3.4334e-04 - val_loss: 0.0129 - val_MSE: 3.5870e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0129 - train_MSE: 3.4349e-04 - val_loss: 0.0126 - val_MSE: 3.4613e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0128 - train_MSE: 3.4241e-04 - val_loss: 0.0125 - val_MSE: 3.3938e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0128 - train_MSE: 3.4186e-04 - val_loss: 0.0123 - val_MSE: 3.3159e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0128 - train_MSE: 3.4070e-04 - val_loss: 0.0123 - val_MSE: 3.2682e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0128 - train_MSE: 3.3998e-04 - val_loss: 0.0123 - val_MSE: 3.2222e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0127 - train_MSE: 3.3795e-04 - val_loss: 0.0123 - val_MSE: 3.1994e-04\n",
      "epoch:860/1500 - 耗时:0.03分/总25.76分; train_loss 0.0126 train_MSE 0.0003; val_loss 0.0123 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0127 - train_MSE: 3.3790e-04 - val_loss: 0.0123 - val_MSE: 3.1993e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0127 - train_MSE: 3.3659e-04 - val_loss: 0.0123 - val_MSE: 3.1847e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0126 - train_MSE: 3.3464e-04 - val_loss: 0.0123 - val_MSE: 3.1664e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0126 - train_MSE: 3.3344e-04 - val_loss: 0.0123 - val_MSE: 3.1583e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0125 - train_MSE: 3.3238e-04 - val_loss: 0.0124 - val_MSE: 3.1505e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0125 - train_MSE: 3.3081e-04 - val_loss: 0.0124 - val_MSE: 3.1401e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0125 - train_MSE: 3.2958e-04 - val_loss: 0.0125 - val_MSE: 3.1402e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2912e-04 - val_loss: 0.0124 - val_MSE: 3.1323e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2852e-04 - val_loss: 0.0126 - val_MSE: 3.1389e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2734e-04 - val_loss: 0.0127 - val_MSE: 3.1438e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0124 - train_MSE: 3.2692e-04 - val_loss: 0.0127 - val_MSE: 3.1541e-04\n",
      "epoch:870/1500 - 耗时:0.03分/总26.05分; train_loss 0.0120 train_MSE 0.0003; val_loss 0.0127 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2686e-04 - val_loss: 0.0127 - val_MSE: 3.1541e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2634e-04 - val_loss: 0.0127 - val_MSE: 3.1544e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2598e-04 - val_loss: 0.0129 - val_MSE: 3.1741e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2541e-04 - val_loss: 0.0129 - val_MSE: 3.1807e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2529e-04 - val_loss: 0.0131 - val_MSE: 3.2064e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2499e-04 - val_loss: 0.0131 - val_MSE: 3.2014e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2485e-04 - val_loss: 0.0133 - val_MSE: 3.2466e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2449e-04 - val_loss: 0.0134 - val_MSE: 3.2525e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2501e-04 - val_loss: 0.0133 - val_MSE: 3.2406e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2406e-04 - val_loss: 0.0135 - val_MSE: 3.2940e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0123 - train_MSE: 3.2470e-04 - val_loss: 0.0133 - val_MSE: 3.2536e-04\n",
      "epoch:880/1500 - 耗时:0.03分/总26.33分; train_loss 0.0121 train_MSE 0.0003; val_loss 0.0134 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2470e-04 - val_loss: 0.0133 - val_MSE: 3.2537e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2479e-04 - val_loss: 0.0134 - val_MSE: 3.2678e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2467e-04 - val_loss: 0.0133 - val_MSE: 3.2773e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2457e-04 - val_loss: 0.0131 - val_MSE: 3.2290e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2500e-04 - val_loss: 0.0130 - val_MSE: 3.2322e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2417e-04 - val_loss: 0.0129 - val_MSE: 3.2097e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2436e-04 - val_loss: 0.0127 - val_MSE: 3.2179e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.2385e-04 - val_loss: 0.0126 - val_MSE: 3.2053e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2324e-04 - val_loss: 0.0125 - val_MSE: 3.2074e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.2314e-04 - val_loss: 0.0124 - val_MSE: 3.1914e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0123 - train_MSE: 3.2261e-04 - val_loss: 0.0123 - val_MSE: 3.2282e-04\n",
      "epoch:890/1500 - 耗时:0.03分/总26.62分; train_loss 0.0123 train_MSE 0.0003; val_loss 0.0122 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0123 - train_MSE: 3.2264e-04 - val_loss: 0.0123 - val_MSE: 3.2281e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0123 - train_MSE: 3.2137e-04 - val_loss: 0.0122 - val_MSE: 3.2009e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0123 - train_MSE: 3.2117e-04 - val_loss: 0.0121 - val_MSE: 3.2033e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0123 - train_MSE: 3.2033e-04 - val_loss: 0.0121 - val_MSE: 3.2482e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0122 - train_MSE: 3.2035e-04 - val_loss: 0.0121 - val_MSE: 3.2650e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0122 - train_MSE: 3.2021e-04 - val_loss: 0.0121 - val_MSE: 3.3081e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0122 - train_MSE: 3.1938e-04 - val_loss: 0.0122 - val_MSE: 3.3642e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0122 - train_MSE: 3.1873e-04 - val_loss: 0.0124 - val_MSE: 3.4371e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0122 - train_MSE: 3.1863e-04 - val_loss: 0.0125 - val_MSE: 3.4789e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0122 - train_MSE: 3.1814e-04 - val_loss: 0.0127 - val_MSE: 3.5417e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0122 - train_MSE: 3.1808e-04 - val_loss: 0.0128 - val_MSE: 3.5828e-04\n",
      "epoch:900/1500 - 耗时:0.03分/总26.92分; train_loss 0.0121 train_MSE 0.0003; val_loss 0.0132 val_MSE 0.0004\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0122 - train_MSE: 3.1805e-04 - val_loss: 0.0128 - val_MSE: 3.5831e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0122 - train_MSE: 3.1773e-04 - val_loss: 0.0132 - val_MSE: 3.6814e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.1820e-04 - val_loss: 0.0131 - val_MSE: 3.6566e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.1807e-04 - val_loss: 0.0132 - val_MSE: 3.6825e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.1871e-04 - val_loss: 0.0131 - val_MSE: 3.6358e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.1854e-04 - val_loss: 0.0130 - val_MSE: 3.5534e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.1933e-04 - val_loss: 0.0128 - val_MSE: 3.4815e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0124 - train_MSE: 3.1873e-04 - val_loss: 0.0125 - val_MSE: 3.3627e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0124 - train_MSE: 3.1939e-04 - val_loss: 0.0123 - val_MSE: 3.2686e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0124 - train_MSE: 3.1849e-04 - val_loss: 0.0120 - val_MSE: 3.1359e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0124 - train_MSE: 3.1841e-04 - val_loss: 0.0118 - val_MSE: 3.0723e-04\n",
      "epoch:910/1500 - 耗时:0.03分/总27.22分; train_loss 0.0125 train_MSE 0.0003; val_loss 0.0117 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0124 - train_MSE: 3.1838e-04 - val_loss: 0.0118 - val_MSE: 3.0720e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0123 - train_MSE: 3.1753e-04 - val_loss: 0.0117 - val_MSE: 2.9931e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.1656e-04 - val_loss: 0.0117 - val_MSE: 2.9725e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0123 - train_MSE: 3.1493e-04 - val_loss: 0.0118 - val_MSE: 2.9469e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0122 - train_MSE: 3.1335e-04 - val_loss: 0.0118 - val_MSE: 2.9418e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0121 - train_MSE: 3.1088e-04 - val_loss: 0.0118 - val_MSE: 2.9379e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0121 - train_MSE: 3.0961e-04 - val_loss: 0.0118 - val_MSE: 2.9385e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0120 - train_MSE: 3.0830e-04 - val_loss: 0.0118 - val_MSE: 2.9322e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0120 - train_MSE: 3.0711e-04 - val_loss: 0.0119 - val_MSE: 2.9254e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0120 - train_MSE: 3.0629e-04 - val_loss: 0.0119 - val_MSE: 2.9261e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0119 - train_MSE: 3.0522e-04 - val_loss: 0.0120 - val_MSE: 2.9231e-04\n",
      "epoch:920/1500 - 耗时:0.03分/总27.51分; train_loss 0.0116 train_MSE 0.0003; val_loss 0.0120 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0119 - train_MSE: 3.0512e-04 - val_loss: 0.0120 - val_MSE: 2.9231e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0119 - train_MSE: 3.0430e-04 - val_loss: 0.0120 - val_MSE: 2.9258e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0119 - train_MSE: 3.0345e-04 - val_loss: 0.0120 - val_MSE: 2.9223e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0295e-04 - val_loss: 0.0122 - val_MSE: 2.9366e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0227e-04 - val_loss: 0.0122 - val_MSE: 2.9405e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0231e-04 - val_loss: 0.0123 - val_MSE: 2.9567e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0176e-04 - val_loss: 0.0123 - val_MSE: 2.9588e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0167e-04 - val_loss: 0.0126 - val_MSE: 3.0005e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0136e-04 - val_loss: 0.0125 - val_MSE: 2.9831e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0156e-04 - val_loss: 0.0126 - val_MSE: 3.0036e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0118 - train_MSE: 3.0075e-04 - val_loss: 0.0129 - val_MSE: 3.0476e-04\n",
      "epoch:930/1500 - 耗时:0.03分/总27.80分; train_loss 0.0115 train_MSE 0.0003; val_loss 0.0129 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0062e-04 - val_loss: 0.0129 - val_MSE: 3.0476e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0077e-04 - val_loss: 0.0129 - val_MSE: 3.0412e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0118e-04 - val_loss: 0.0128 - val_MSE: 3.0294e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0087e-04 - val_loss: 0.0129 - val_MSE: 3.0743e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0083e-04 - val_loss: 0.0129 - val_MSE: 3.0658e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0109e-04 - val_loss: 0.0127 - val_MSE: 3.0404e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0087e-04 - val_loss: 0.0129 - val_MSE: 3.0683e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0046e-04 - val_loss: 0.0128 - val_MSE: 3.0774e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0096e-04 - val_loss: 0.0125 - val_MSE: 3.0143e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0165e-04 - val_loss: 0.0125 - val_MSE: 3.0216e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0118 - train_MSE: 2.9993e-04 - val_loss: 0.0123 - val_MSE: 3.0013e-04\n",
      "epoch:940/1500 - 耗时:0.03分/总28.09分; train_loss 0.0118 train_MSE 0.0003; val_loss 0.0121 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0008e-04 - val_loss: 0.0123 - val_MSE: 3.0012e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0046e-04 - val_loss: 0.0121 - val_MSE: 2.9829e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 3.0082e-04 - val_loss: 0.0120 - val_MSE: 2.9797e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 2.9981e-04 - val_loss: 0.0119 - val_MSE: 2.9927e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0118 - train_MSE: 2.9853e-04 - val_loss: 0.0117 - val_MSE: 2.9708e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 2.9889e-04 - val_loss: 0.0116 - val_MSE: 2.9677e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0118 - train_MSE: 2.9831e-04 - val_loss: 0.0116 - val_MSE: 2.9770e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 2.9783e-04 - val_loss: 0.0116 - val_MSE: 3.0027e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0117 - train_MSE: 2.9691e-04 - val_loss: 0.0116 - val_MSE: 3.0464e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0117 - train_MSE: 2.9732e-04 - val_loss: 0.0116 - val_MSE: 3.0605e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0117 - train_MSE: 2.9632e-04 - val_loss: 0.0118 - val_MSE: 3.1532e-04\n",
      "epoch:950/1500 - 耗时:0.03分/总28.38分; train_loss 0.0116 train_MSE 0.0003; val_loss 0.0119 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0117 - train_MSE: 2.9632e-04 - val_loss: 0.0118 - val_MSE: 3.1535e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0117 - train_MSE: 2.9621e-04 - val_loss: 0.0119 - val_MSE: 3.2171e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0117 - train_MSE: 2.9555e-04 - val_loss: 0.0122 - val_MSE: 3.3174e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0117 - train_MSE: 2.9625e-04 - val_loss: 0.0123 - val_MSE: 3.3396e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0117 - train_MSE: 2.9522e-04 - val_loss: 0.0125 - val_MSE: 3.4140e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0117 - train_MSE: 2.9542e-04 - val_loss: 0.0127 - val_MSE: 3.4652e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 2.9564e-04 - val_loss: 0.0128 - val_MSE: 3.4731e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 2.9629e-04 - val_loss: 0.0128 - val_MSE: 3.4550e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 2.9646e-04 - val_loss: 0.0128 - val_MSE: 3.4402e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0119 - train_MSE: 2.9731e-04 - val_loss: 0.0127 - val_MSE: 3.3735e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0119 - train_MSE: 2.9737e-04 - val_loss: 0.0123 - val_MSE: 3.2359e-04\n",
      "epoch:960/1500 - 耗时:0.03分/总28.67分; train_loss 0.0120 train_MSE 0.0003; val_loss 0.0119 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0119 - train_MSE: 2.9731e-04 - val_loss: 0.0123 - val_MSE: 3.2354e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0119 - train_MSE: 2.9786e-04 - val_loss: 0.0119 - val_MSE: 3.0992e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0119 - train_MSE: 2.9736e-04 - val_loss: 0.0116 - val_MSE: 2.9854e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0119 - train_MSE: 2.9722e-04 - val_loss: 0.0114 - val_MSE: 2.9102e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0119 - train_MSE: 2.9662e-04 - val_loss: 0.0113 - val_MSE: 2.8147e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0119 - train_MSE: 2.9597e-04 - val_loss: 0.0112 - val_MSE: 2.7733e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 2.9390e-04 - val_loss: 0.0113 - val_MSE: 2.7565e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0118 - train_MSE: 2.9252e-04 - val_loss: 0.0113 - val_MSE: 2.7507e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0117 - train_MSE: 2.9052e-04 - val_loss: 0.0113 - val_MSE: 2.7479e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0116 - train_MSE: 2.8867e-04 - val_loss: 0.0113 - val_MSE: 2.7458e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0116 - train_MSE: 2.8753e-04 - val_loss: 0.0113 - val_MSE: 2.7425e-04\n",
      "epoch:970/1500 - 耗时:0.03分/总28.97分; train_loss 0.0114 train_MSE 0.0003; val_loss 0.0113 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0116 - train_MSE: 2.8732e-04 - val_loss: 0.0113 - val_MSE: 2.7424e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0115 - train_MSE: 2.8605e-04 - val_loss: 0.0113 - val_MSE: 2.7384e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0115 - train_MSE: 2.8536e-04 - val_loss: 0.0114 - val_MSE: 2.7386e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0114 - train_MSE: 2.8378e-04 - val_loss: 0.0114 - val_MSE: 2.7318e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0114 - train_MSE: 2.8337e-04 - val_loss: 0.0115 - val_MSE: 2.7358e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0114 - train_MSE: 2.8257e-04 - val_loss: 0.0115 - val_MSE: 2.7334e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0114 - train_MSE: 2.8188e-04 - val_loss: 0.0116 - val_MSE: 2.7385e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.8128e-04 - val_loss: 0.0116 - val_MSE: 2.7371e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.8110e-04 - val_loss: 0.0117 - val_MSE: 2.7522e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.8035e-04 - val_loss: 0.0119 - val_MSE: 2.7749e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0113 - train_MSE: 2.8054e-04 - val_loss: 0.0119 - val_MSE: 2.7796e-04\n",
      "epoch:980/1500 - 耗时:0.03分/总29.26分; train_loss 0.0110 train_MSE 0.0003; val_loss 0.0119 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.8036e-04 - val_loss: 0.0119 - val_MSE: 2.7796e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7983e-04 - val_loss: 0.0119 - val_MSE: 2.7783e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7991e-04 - val_loss: 0.0121 - val_MSE: 2.8029e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7929e-04 - val_loss: 0.0123 - val_MSE: 2.8400e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7966e-04 - val_loss: 0.0122 - val_MSE: 2.8154e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7906e-04 - val_loss: 0.0126 - val_MSE: 2.8867e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7941e-04 - val_loss: 0.0125 - val_MSE: 2.8731e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7902e-04 - val_loss: 0.0128 - val_MSE: 2.9190e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7930e-04 - val_loss: 0.0124 - val_MSE: 2.8632e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7875e-04 - val_loss: 0.0127 - val_MSE: 2.9198e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0113 - train_MSE: 2.7867e-04 - val_loss: 0.0125 - val_MSE: 2.8917e-04\n",
      "epoch:990/1500 - 耗时:0.03分/总29.54分; train_loss 0.0111 train_MSE 0.0003; val_loss 0.0124 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7873e-04 - val_loss: 0.0125 - val_MSE: 2.8917e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7882e-04 - val_loss: 0.0124 - val_MSE: 2.8833e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7965e-04 - val_loss: 0.0124 - val_MSE: 2.8922e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7858e-04 - val_loss: 0.0123 - val_MSE: 2.8888e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7876e-04 - val_loss: 0.0121 - val_MSE: 2.8414e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7903e-04 - val_loss: 0.0120 - val_MSE: 2.8408e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7899e-04 - val_loss: 0.0120 - val_MSE: 2.8481e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7858e-04 - val_loss: 0.0117 - val_MSE: 2.8111e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7912e-04 - val_loss: 0.0115 - val_MSE: 2.7880e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7767e-04 - val_loss: 0.0114 - val_MSE: 2.7817e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0113 - train_MSE: 2.7752e-04 - val_loss: 0.0112 - val_MSE: 2.7737e-04\n",
      "epoch:1000/1500 - 耗时:0.03分/总29.83分; train_loss 0.0113 train_MSE 0.0003; val_loss 0.0112 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0113 - train_MSE: 2.7766e-04 - val_loss: 0.0112 - val_MSE: 2.7737e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0113 - train_MSE: 2.7762e-04 - val_loss: 0.0112 - val_MSE: 2.7864e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7711e-04 - val_loss: 0.0111 - val_MSE: 2.7891e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7640e-04 - val_loss: 0.0111 - val_MSE: 2.8260e-04\n",
      "117/117 [==============================] - 3s 25ms/step - train_loss: 0.0113 - train_MSE: 2.7698e-04 - val_loss: 0.0112 - val_MSE: 2.8693e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7594e-04 - val_loss: 0.0113 - val_MSE: 2.9157e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7570e-04 - val_loss: 0.0114 - val_MSE: 2.9716e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7566e-04 - val_loss: 0.0116 - val_MSE: 3.0532e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7553e-04 - val_loss: 0.0119 - val_MSE: 3.1290e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7569e-04 - val_loss: 0.0121 - val_MSE: 3.2087e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0113 - train_MSE: 2.7566e-04 - val_loss: 0.0123 - val_MSE: 3.2461e-04\n",
      "epoch:1010/1500 - 耗时:0.03分/总30.15分; train_loss 0.0113 train_MSE 0.0003; val_loss 0.0125 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7558e-04 - val_loss: 0.0123 - val_MSE: 3.2463e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7596e-04 - val_loss: 0.0125 - val_MSE: 3.2937e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0114 - train_MSE: 2.7672e-04 - val_loss: 0.0125 - val_MSE: 3.2926e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0114 - train_MSE: 2.7711e-04 - val_loss: 0.0126 - val_MSE: 3.2912e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0115 - train_MSE: 2.7798e-04 - val_loss: 0.0124 - val_MSE: 3.2169e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0115 - train_MSE: 2.7770e-04 - val_loss: 0.0121 - val_MSE: 3.0981e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0115 - train_MSE: 2.7799e-04 - val_loss: 0.0118 - val_MSE: 2.9985e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0115 - train_MSE: 2.7844e-04 - val_loss: 0.0113 - val_MSE: 2.8082e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0116 - train_MSE: 2.7859e-04 - val_loss: 0.0110 - val_MSE: 2.7095e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0115 - train_MSE: 2.7788e-04 - val_loss: 0.0108 - val_MSE: 2.6198e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0115 - train_MSE: 2.7709e-04 - val_loss: 0.0108 - val_MSE: 2.5950e-04\n",
      "epoch:1020/1500 - 耗时:0.03分/总30.44分; train_loss 0.0118 train_MSE 0.0003; val_loss 0.0109 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0115 - train_MSE: 2.7709e-04 - val_loss: 0.0108 - val_MSE: 2.5950e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0114 - train_MSE: 2.7490e-04 - val_loss: 0.0109 - val_MSE: 2.5791e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0113 - train_MSE: 2.7315e-04 - val_loss: 0.0109 - val_MSE: 2.5707e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0112 - train_MSE: 2.7039e-04 - val_loss: 0.0109 - val_MSE: 2.5812e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0112 - train_MSE: 2.6905e-04 - val_loss: 0.0108 - val_MSE: 2.5794e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0111 - train_MSE: 2.6742e-04 - val_loss: 0.0108 - val_MSE: 2.5757e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0111 - train_MSE: 2.6643e-04 - val_loss: 0.0109 - val_MSE: 2.5710e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0110 - train_MSE: 2.6510e-04 - val_loss: 0.0108 - val_MSE: 2.5723e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0110 - train_MSE: 2.6471e-04 - val_loss: 0.0109 - val_MSE: 2.5565e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0110 - train_MSE: 2.6382e-04 - val_loss: 0.0109 - val_MSE: 2.5669e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0109 - train_MSE: 2.6304e-04 - val_loss: 0.0110 - val_MSE: 2.5574e-04\n",
      "epoch:1030/1500 - 耗时:0.03分/总30.73分; train_loss 0.0106 train_MSE 0.0003; val_loss 0.0110 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0109 - train_MSE: 2.6298e-04 - val_loss: 0.0110 - val_MSE: 2.5574e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0109 - train_MSE: 2.6227e-04 - val_loss: 0.0110 - val_MSE: 2.5617e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0109 - train_MSE: 2.6205e-04 - val_loss: 0.0110 - val_MSE: 2.5525e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0109 - train_MSE: 2.6112e-04 - val_loss: 0.0111 - val_MSE: 2.5647e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.6105e-04 - val_loss: 0.0112 - val_MSE: 2.5651e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.6045e-04 - val_loss: 0.0112 - val_MSE: 2.5751e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.6059e-04 - val_loss: 0.0113 - val_MSE: 2.5836e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.6014e-04 - val_loss: 0.0117 - val_MSE: 2.6320e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0108 - train_MSE: 2.6027e-04 - val_loss: 0.0114 - val_MSE: 2.5902e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5954e-04 - val_loss: 0.0119 - val_MSE: 2.6717e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0108 - train_MSE: 2.5948e-04 - val_loss: 0.0120 - val_MSE: 2.6827e-04\n",
      "epoch:1040/1500 - 耗时:0.03分/总31.02分; train_loss 0.0105 train_MSE 0.0003; val_loss 0.0116 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5946e-04 - val_loss: 0.0120 - val_MSE: 2.6825e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5957e-04 - val_loss: 0.0116 - val_MSE: 2.6240e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.6005e-04 - val_loss: 0.0119 - val_MSE: 2.6742e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5834e-04 - val_loss: 0.0123 - val_MSE: 2.7426e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5931e-04 - val_loss: 0.0117 - val_MSE: 2.6280e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5970e-04 - val_loss: 0.0117 - val_MSE: 2.6404e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5891e-04 - val_loss: 0.0122 - val_MSE: 2.7511e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0109 - train_MSE: 2.5972e-04 - val_loss: 0.0117 - val_MSE: 2.6571e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5952e-04 - val_loss: 0.0115 - val_MSE: 2.6307e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5969e-04 - val_loss: 0.0119 - val_MSE: 2.7024e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0108 - train_MSE: 2.5802e-04 - val_loss: 0.0116 - val_MSE: 2.6676e-04\n",
      "epoch:1050/1500 - 耗时:0.03分/总31.31分; train_loss 0.0107 train_MSE 0.0003; val_loss 0.0111 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5804e-04 - val_loss: 0.0116 - val_MSE: 2.6672e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0109 - train_MSE: 2.5985e-04 - val_loss: 0.0111 - val_MSE: 2.5744e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5957e-04 - val_loss: 0.0115 - val_MSE: 2.6535e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5754e-04 - val_loss: 0.0112 - val_MSE: 2.6189e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5901e-04 - val_loss: 0.0109 - val_MSE: 2.5876e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5901e-04 - val_loss: 0.0110 - val_MSE: 2.5842e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0108 - train_MSE: 2.5698e-04 - val_loss: 0.0109 - val_MSE: 2.5883e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0108 - train_MSE: 2.5733e-04 - val_loss: 0.0107 - val_MSE: 2.5992e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0108 - train_MSE: 2.5737e-04 - val_loss: 0.0107 - val_MSE: 2.5656e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0107 - train_MSE: 2.5593e-04 - val_loss: 0.0107 - val_MSE: 2.5863e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0107 - train_MSE: 2.5605e-04 - val_loss: 0.0107 - val_MSE: 2.6282e-04\n",
      "epoch:1060/1500 - 耗时:0.03分/总31.61分; train_loss 0.0106 train_MSE 0.0003; val_loss 0.0107 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0107 - train_MSE: 2.5605e-04 - val_loss: 0.0107 - val_MSE: 2.6284e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5629e-04 - val_loss: 0.0107 - val_MSE: 2.6652e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0107 - train_MSE: 2.5579e-04 - val_loss: 0.0107 - val_MSE: 2.6769e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0107 - train_MSE: 2.5554e-04 - val_loss: 0.0109 - val_MSE: 2.7840e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5596e-04 - val_loss: 0.0110 - val_MSE: 2.8072e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5561e-04 - val_loss: 0.0112 - val_MSE: 2.8677e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5571e-04 - val_loss: 0.0115 - val_MSE: 2.9573e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5599e-04 - val_loss: 0.0117 - val_MSE: 2.9950e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0109 - train_MSE: 2.5658e-04 - val_loss: 0.0118 - val_MSE: 3.0171e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0109 - train_MSE: 2.5689e-04 - val_loss: 0.0120 - val_MSE: 3.0717e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0110 - train_MSE: 2.5797e-04 - val_loss: 0.0121 - val_MSE: 3.0675e-04\n",
      "epoch:1070/1500 - 耗时:0.03分/总31.90分; train_loss 0.0111 train_MSE 0.0003; val_loss 0.0122 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0110 - train_MSE: 2.5797e-04 - val_loss: 0.0121 - val_MSE: 3.0675e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0110 - train_MSE: 2.5772e-04 - val_loss: 0.0122 - val_MSE: 3.0721e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0110 - train_MSE: 2.5829e-04 - val_loss: 0.0120 - val_MSE: 3.0107e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0110 - train_MSE: 2.5812e-04 - val_loss: 0.0117 - val_MSE: 2.9043e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0110 - train_MSE: 2.5821e-04 - val_loss: 0.0115 - val_MSE: 2.8186e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0110 - train_MSE: 2.5820e-04 - val_loss: 0.0110 - val_MSE: 2.6718e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0111 - train_MSE: 2.5927e-04 - val_loss: 0.0106 - val_MSE: 2.5378e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0111 - train_MSE: 2.5911e-04 - val_loss: 0.0104 - val_MSE: 2.4243e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0111 - train_MSE: 2.5810e-04 - val_loss: 0.0104 - val_MSE: 2.4063e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0110 - train_MSE: 2.5537e-04 - val_loss: 0.0105 - val_MSE: 2.3987e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0109 - train_MSE: 2.5387e-04 - val_loss: 0.0104 - val_MSE: 2.3970e-04\n",
      "epoch:1080/1500 - 耗时:0.03分/总32.19分; train_loss 0.0111 train_MSE 0.0003; val_loss 0.0105 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0109 - train_MSE: 2.5387e-04 - val_loss: 0.0104 - val_MSE: 2.3970e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.5148e-04 - val_loss: 0.0105 - val_MSE: 2.4010e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0107 - train_MSE: 2.4997e-04 - val_loss: 0.0105 - val_MSE: 2.3935e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0107 - train_MSE: 2.4850e-04 - val_loss: 0.0104 - val_MSE: 2.4104e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0106 - train_MSE: 2.4773e-04 - val_loss: 0.0105 - val_MSE: 2.4047e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0106 - train_MSE: 2.4675e-04 - val_loss: 0.0105 - val_MSE: 2.4077e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0105 - train_MSE: 2.4617e-04 - val_loss: 0.0106 - val_MSE: 2.4018e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0105 - train_MSE: 2.4512e-04 - val_loss: 0.0106 - val_MSE: 2.4052e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0105 - train_MSE: 2.4460e-04 - val_loss: 0.0106 - val_MSE: 2.4009e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0105 - train_MSE: 2.4395e-04 - val_loss: 0.0107 - val_MSE: 2.4105e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0104 - train_MSE: 2.4388e-04 - val_loss: 0.0107 - val_MSE: 2.4062e-04 ETA: 0s - train_loss: 0.0105 - train_MSE: 2.4570e-04 - val_loss: 0.0107 - val\n",
      "epoch:1090/1500 - 耗时:0.03分/总32.48分; train_loss 0.0102 train_MSE 0.0002; val_loss 0.0110 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4377e-04 - val_loss: 0.0107 - val_MSE: 2.4064e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4267e-04 - val_loss: 0.0110 - val_MSE: 2.4381e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4295e-04 - val_loss: 0.0110 - val_MSE: 2.4369e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4243e-04 - val_loss: 0.0109 - val_MSE: 2.4322e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4241e-04 - val_loss: 0.0114 - val_MSE: 2.5041e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4208e-04 - val_loss: 0.0114 - val_MSE: 2.4947e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4282e-04 - val_loss: 0.0111 - val_MSE: 2.4549e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4170e-04 - val_loss: 0.0121 - val_MSE: 2.6194e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4234e-04 - val_loss: 0.0116 - val_MSE: 2.5341e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4291e-04 - val_loss: 0.0113 - val_MSE: 2.4852e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0104 - train_MSE: 2.4114e-04 - val_loss: 0.0121 - val_MSE: 2.6324e-04\n",
      "epoch:1100/1500 - 耗时:0.03分/总32.77分; train_loss 0.0103 train_MSE 0.0002; val_loss 0.0116 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4116e-04 - val_loss: 0.0121 - val_MSE: 2.6319e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0105 - train_MSE: 2.4276e-04 - val_loss: 0.0116 - val_MSE: 2.5167e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4243e-04 - val_loss: 0.0114 - val_MSE: 2.5108e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4139e-04 - val_loss: 0.0118 - val_MSE: 2.5851e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4170e-04 - val_loss: 0.0114 - val_MSE: 2.5011e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4257e-04 - val_loss: 0.0112 - val_MSE: 2.4633e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4213e-04 - val_loss: 0.0115 - val_MSE: 2.5390e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4118e-04 - val_loss: 0.0111 - val_MSE: 2.4915e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4253e-04 - val_loss: 0.0108 - val_MSE: 2.4240e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4186e-04 - val_loss: 0.0111 - val_MSE: 2.4813e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0104 - train_MSE: 2.4075e-04 - val_loss: 0.0108 - val_MSE: 2.4520e-04\n",
      "epoch:1110/1500 - 耗时:0.03分/总33.06分; train_loss 0.0103 train_MSE 0.0002; val_loss 0.0105 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4077e-04 - val_loss: 0.0108 - val_MSE: 2.4519e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4134e-04 - val_loss: 0.0106 - val_MSE: 2.4189e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4115e-04 - val_loss: 0.0107 - val_MSE: 2.4322e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0103 - train_MSE: 2.4016e-04 - val_loss: 0.0105 - val_MSE: 2.4319e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4133e-04 - val_loss: 0.0103 - val_MSE: 2.4363e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0103 - train_MSE: 2.3989e-04 - val_loss: 0.0103 - val_MSE: 2.4352e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0103 - train_MSE: 2.3918e-04 - val_loss: 0.0103 - val_MSE: 2.4744e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.3970e-04 - val_loss: 0.0103 - val_MSE: 2.5171e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0103 - train_MSE: 2.3934e-04 - val_loss: 0.0104 - val_MSE: 2.5365e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0103 - train_MSE: 2.3888e-04 - val_loss: 0.0105 - val_MSE: 2.6032e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0104 - train_MSE: 2.3950e-04 - val_loss: 0.0107 - val_MSE: 2.6771e-04\n",
      "epoch:1120/1500 - 耗时:0.03分/总33.35分; train_loss 0.0103 train_MSE 0.0002; val_loss 0.0109 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.3953e-04 - val_loss: 0.0107 - val_MSE: 2.6773e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.3918e-04 - val_loss: 0.0109 - val_MSE: 2.7284e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.3926e-04 - val_loss: 0.0113 - val_MSE: 2.8314e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.4003e-04 - val_loss: 0.0113 - val_MSE: 2.8296e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0105 - train_MSE: 2.4036e-04 - val_loss: 0.0115 - val_MSE: 2.8790e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0105 - train_MSE: 2.4093e-04 - val_loss: 0.0116 - val_MSE: 2.8974e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0106 - train_MSE: 2.4151e-04 - val_loss: 0.0117 - val_MSE: 2.9064e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0106 - train_MSE: 2.4187e-04 - val_loss: 0.0117 - val_MSE: 2.8976e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0106 - train_MSE: 2.4287e-04 - val_loss: 0.0115 - val_MSE: 2.8108e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0106 - train_MSE: 2.4251e-04 - val_loss: 0.0112 - val_MSE: 2.6990e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0107 - train_MSE: 2.4312e-04 - val_loss: 0.0109 - val_MSE: 2.6067e-04\n",
      "epoch:1130/1500 - 耗时:0.03分/总33.64分; train_loss 0.0111 train_MSE 0.0002; val_loss 0.0106 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0107 - train_MSE: 2.4326e-04 - val_loss: 0.0109 - val_MSE: 2.6061e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0107 - train_MSE: 2.4398e-04 - val_loss: 0.0106 - val_MSE: 2.4708e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0108 - train_MSE: 2.4419e-04 - val_loss: 0.0105 - val_MSE: 2.4236e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0107 - train_MSE: 2.4243e-04 - val_loss: 0.0104 - val_MSE: 2.3592e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0106 - train_MSE: 2.4094e-04 - val_loss: 0.0102 - val_MSE: 2.3290e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0105 - train_MSE: 2.3866e-04 - val_loss: 0.0101 - val_MSE: 2.2862e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0105 - train_MSE: 2.3746e-04 - val_loss: 0.0100 - val_MSE: 2.2795e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.3587e-04 - val_loss: 0.0100 - val_MSE: 2.2647e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.3481e-04 - val_loss: 0.0100 - val_MSE: 2.2629e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0103 - train_MSE: 2.3336e-04 - val_loss: 0.0101 - val_MSE: 2.2577e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0103 - train_MSE: 2.3235e-04 - val_loss: 0.0101 - val_MSE: 2.2633e-04\n",
      "epoch:1140/1500 - 耗时:0.03分/总33.94分; train_loss 0.0103 train_MSE 0.0002; val_loss 0.0101 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0103 - train_MSE: 2.3231e-04 - val_loss: 0.0101 - val_MSE: 2.2633e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0102 - train_MSE: 2.3103e-04 - val_loss: 0.0101 - val_MSE: 2.2719e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0102 - train_MSE: 2.3056e-04 - val_loss: 0.0101 - val_MSE: 2.2683e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.2961e-04 - val_loss: 0.0101 - val_MSE: 2.2648e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.2907e-04 - val_loss: 0.0102 - val_MSE: 2.2627e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.2844e-04 - val_loss: 0.0102 - val_MSE: 2.2664e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2824e-04 - val_loss: 0.0103 - val_MSE: 2.2683e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2754e-04 - val_loss: 0.0104 - val_MSE: 2.2812e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2765e-04 - val_loss: 0.0106 - val_MSE: 2.3023e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2686e-04 - val_loss: 0.0107 - val_MSE: 2.3146e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0100 - train_MSE: 2.2697e-04 - val_loss: 0.0106 - val_MSE: 2.3008e-04\n",
      "epoch:1150/1500 - 耗时:0.03分/总34.23分; train_loss 0.0098 train_MSE 0.0002; val_loss 0.0110 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2693e-04 - val_loss: 0.0106 - val_MSE: 2.3010e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2663e-04 - val_loss: 0.0110 - val_MSE: 2.3525e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2651e-04 - val_loss: 0.0111 - val_MSE: 2.3746e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2633e-04 - val_loss: 0.0108 - val_MSE: 2.3294e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2729e-04 - val_loss: 0.0112 - val_MSE: 2.4006e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2554e-04 - val_loss: 0.0118 - val_MSE: 2.4909e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2679e-04 - val_loss: 0.0110 - val_MSE: 2.3483e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2721e-04 - val_loss: 0.0113 - val_MSE: 2.4068e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2592e-04 - val_loss: 0.0118 - val_MSE: 2.5096e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.2734e-04 - val_loss: 0.0112 - val_MSE: 2.3861e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0100 - train_MSE: 2.2711e-04 - val_loss: 0.0110 - val_MSE: 2.3731e-04\n",
      "epoch:1160/1500 - 耗时:0.03分/总34.52分; train_loss 0.0102 train_MSE 0.0002; val_loss 0.0115 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2732e-04 - val_loss: 0.0110 - val_MSE: 2.3735e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2675e-04 - val_loss: 0.0115 - val_MSE: 2.4589e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2595e-04 - val_loss: 0.0111 - val_MSE: 2.3890e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.2781e-04 - val_loss: 0.0107 - val_MSE: 2.3098e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2748e-04 - val_loss: 0.0110 - val_MSE: 2.3907e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2603e-04 - val_loss: 0.0107 - val_MSE: 2.3492e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2694e-04 - val_loss: 0.0104 - val_MSE: 2.2923e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2729e-04 - val_loss: 0.0106 - val_MSE: 2.3129e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2626e-04 - val_loss: 0.0104 - val_MSE: 2.3133e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2583e-04 - val_loss: 0.0101 - val_MSE: 2.2946e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0100 - train_MSE: 2.2594e-04 - val_loss: 0.0102 - val_MSE: 2.2768e-04\n",
      "epoch:1170/1500 - 耗时:0.03分/总34.80分; train_loss 0.0101 train_MSE 0.0002; val_loss 0.0101 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2618e-04 - val_loss: 0.0102 - val_MSE: 2.2769e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0100 - train_MSE: 2.2523e-04 - val_loss: 0.0101 - val_MSE: 2.3066e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0100 - train_MSE: 2.2495e-04 - val_loss: 0.0100 - val_MSE: 2.3110e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2500e-04 - val_loss: 0.0100 - val_MSE: 2.3109e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0099 - train_MSE: 2.2443e-04 - val_loss: 0.0100 - val_MSE: 2.3362e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2452e-04 - val_loss: 0.0101 - val_MSE: 2.4196e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2435e-04 - val_loss: 0.0102 - val_MSE: 2.4341e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0099 - train_MSE: 2.2382e-04 - val_loss: 0.0103 - val_MSE: 2.4788e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2442e-04 - val_loss: 0.0105 - val_MSE: 2.5489e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2434e-04 - val_loss: 0.0107 - val_MSE: 2.6217e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0100 - train_MSE: 2.2486e-04 - val_loss: 0.0109 - val_MSE: 2.6605e-04\n",
      "epoch:1180/1500 - 耗时:0.03分/总35.10分; train_loss 0.0102 train_MSE 0.0002; val_loss 0.0113 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2493e-04 - val_loss: 0.0109 - val_MSE: 2.6609e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.2494e-04 - val_loss: 0.0113 - val_MSE: 2.7635e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.2614e-04 - val_loss: 0.0112 - val_MSE: 2.7384e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0102 - train_MSE: 2.2618e-04 - val_loss: 0.0114 - val_MSE: 2.7764e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0102 - train_MSE: 2.2758e-04 - val_loss: 0.0113 - val_MSE: 2.7402e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0103 - train_MSE: 2.2749e-04 - val_loss: 0.0114 - val_MSE: 2.7263e-04\n",
      "117/117 [==============================] - 3s 25ms/step - train_loss: 0.0103 - train_MSE: 2.2863e-04 - val_loss: 0.0111 - val_MSE: 2.6310e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0103 - train_MSE: 2.2843e-04 - val_loss: 0.0109 - val_MSE: 2.5196e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.2908e-04 - val_loss: 0.0106 - val_MSE: 2.4153e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.2907e-04 - val_loss: 0.0103 - val_MSE: 2.3308e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0104 - train_MSE: 2.2949e-04 - val_loss: 0.0101 - val_MSE: 2.2601e-04\n",
      "epoch:1190/1500 - 耗时:0.03分/总35.41分; train_loss 0.0109 train_MSE 0.0002; val_loss 0.0101 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0104 - train_MSE: 2.2952e-04 - val_loss: 0.0101 - val_MSE: 2.2600e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0103 - train_MSE: 2.2739e-04 - val_loss: 0.0101 - val_MSE: 2.2325e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0102 - train_MSE: 2.2527e-04 - val_loss: 0.0098 - val_MSE: 2.1793e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0101 - train_MSE: 2.2375e-04 - val_loss: 0.0097 - val_MSE: 2.1707e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.2261e-04 - val_loss: 0.0097 - val_MSE: 2.1533e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.2148e-04 - val_loss: 0.0097 - val_MSE: 2.1396e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.2000e-04 - val_loss: 0.0097 - val_MSE: 2.1294e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0099 - train_MSE: 2.1877e-04 - val_loss: 0.0097 - val_MSE: 2.1378e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0099 - train_MSE: 2.1740e-04 - val_loss: 0.0097 - val_MSE: 2.1339e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0098 - train_MSE: 2.1666e-04 - val_loss: 0.0097 - val_MSE: 2.1431e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0098 - train_MSE: 2.1585e-04 - val_loss: 0.0098 - val_MSE: 2.1359e-04\n",
      "epoch:1200/1500 - 耗时:0.03分/总35.71分; train_loss 0.0097 train_MSE 0.0002; val_loss 0.0098 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0098 - train_MSE: 2.1583e-04 - val_loss: 0.0098 - val_MSE: 2.1359e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1513e-04 - val_loss: 0.0098 - val_MSE: 2.1424e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1444e-04 - val_loss: 0.0098 - val_MSE: 2.1352e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1408e-04 - val_loss: 0.0100 - val_MSE: 2.1474e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1410e-04 - val_loss: 0.0099 - val_MSE: 2.1373e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1342e-04 - val_loss: 0.0100 - val_MSE: 2.1546e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1292e-04 - val_loss: 0.0105 - val_MSE: 2.2101e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1298e-04 - val_loss: 0.0101 - val_MSE: 2.1538e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1290e-04 - val_loss: 0.0102 - val_MSE: 2.1647e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1232e-04 - val_loss: 0.0110 - val_MSE: 2.2787e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0096 - train_MSE: 2.1269e-04 - val_loss: 0.0106 - val_MSE: 2.2084e-04\n",
      "epoch:1210/1500 - 耗时:0.03分/总36.00分; train_loss 0.0096 train_MSE 0.0002; val_loss 0.0103 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1272e-04 - val_loss: 0.0106 - val_MSE: 2.2083e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1332e-04 - val_loss: 0.0103 - val_MSE: 2.1815e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1193e-04 - val_loss: 0.0115 - val_MSE: 2.3775e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1282e-04 - val_loss: 0.0108 - val_MSE: 2.2467e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1322e-04 - val_loss: 0.0106 - val_MSE: 2.2164e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1203e-04 - val_loss: 0.0114 - val_MSE: 2.3677e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1219e-04 - val_loss: 0.0111 - val_MSE: 2.2894e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1346e-04 - val_loss: 0.0106 - val_MSE: 2.2158e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1254e-04 - val_loss: 0.0112 - val_MSE: 2.3284e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1159e-04 - val_loss: 0.0109 - val_MSE: 2.2665e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0097 - train_MSE: 2.1306e-04 - val_loss: 0.0103 - val_MSE: 2.1698e-04\n",
      "epoch:1220/1500 - 耗时:0.03分/总36.28分; train_loss 0.0098 train_MSE 0.0002; val_loss 0.0109 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1328e-04 - val_loss: 0.0103 - val_MSE: 2.1703e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.1299e-04 - val_loss: 0.0109 - val_MSE: 2.2782e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1148e-04 - val_loss: 0.0105 - val_MSE: 2.2175e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1259e-04 - val_loss: 0.0100 - val_MSE: 2.1420e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1268e-04 - val_loss: 0.0104 - val_MSE: 2.1963e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1134e-04 - val_loss: 0.0101 - val_MSE: 2.1778e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1196e-04 - val_loss: 0.0098 - val_MSE: 2.1316e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1219e-04 - val_loss: 0.0100 - val_MSE: 2.1510e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0096 - train_MSE: 2.1077e-04 - val_loss: 0.0099 - val_MSE: 2.1622e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0096 - train_MSE: 2.1086e-04 - val_loss: 0.0095 - val_MSE: 2.1441e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0096 - train_MSE: 2.1200e-04 - val_loss: 0.0095 - val_MSE: 2.1355e-04\n",
      "epoch:1230/1500 - 耗时:0.03分/总36.58分; train_loss 0.0098 train_MSE 0.0002; val_loss 0.0096 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1203e-04 - val_loss: 0.0095 - val_MSE: 2.1357e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1049e-04 - val_loss: 0.0096 - val_MSE: 2.1800e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1026e-04 - val_loss: 0.0096 - val_MSE: 2.2179e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1137e-04 - val_loss: 0.0096 - val_MSE: 2.2625e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1052e-04 - val_loss: 0.0096 - val_MSE: 2.2366e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0095 - train_MSE: 2.0995e-04 - val_loss: 0.0100 - val_MSE: 2.3516e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1053e-04 - val_loss: 0.0102 - val_MSE: 2.4451e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.1104e-04 - val_loss: 0.0101 - val_MSE: 2.4004e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0096 - train_MSE: 2.1052e-04 - val_loss: 0.0108 - val_MSE: 2.5899e-04\n",
      "117/117 [==============================] - 2s 13ms/step - train_loss: 0.0097 - train_MSE: 2.1128e-04 - val_loss: 0.0110 - val_MSE: 2.6379e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0097 - train_MSE: 2.1201e-04 - val_loss: 0.0110 - val_MSE: 2.6370e-04\n",
      "epoch:1240/1500 - 耗时:0.03分/总36.87分; train_loss 0.0099 train_MSE 0.0002; val_loss 0.0113 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 13ms/step - train_loss: 0.0097 - train_MSE: 2.1211e-04 - val_loss: 0.0110 - val_MSE: 2.6372e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0098 - train_MSE: 2.1262e-04 - val_loss: 0.0113 - val_MSE: 2.6874e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0098 - train_MSE: 2.1369e-04 - val_loss: 0.0113 - val_MSE: 2.6851e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0099 - train_MSE: 2.1495e-04 - val_loss: 0.0112 - val_MSE: 2.6420e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0100 - train_MSE: 2.1538e-04 - val_loss: 0.0110 - val_MSE: 2.5443e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.1705e-04 - val_loss: 0.0106 - val_MSE: 2.4202e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.1691e-04 - val_loss: 0.0102 - val_MSE: 2.2664e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.1723e-04 - val_loss: 0.0100 - val_MSE: 2.2006e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0101 - train_MSE: 2.1705e-04 - val_loss: 0.0098 - val_MSE: 2.1236e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0100 - train_MSE: 2.1543e-04 - val_loss: 0.0097 - val_MSE: 2.1002e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0099 - train_MSE: 2.1385e-04 - val_loss: 0.0095 - val_MSE: 2.0385e-04\n",
      "epoch:1250/1500 - 耗时:0.03分/总37.17分; train_loss 0.0105 train_MSE 0.0002; val_loss 0.0094 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0099 - train_MSE: 2.1389e-04 - val_loss: 0.0095 - val_MSE: 2.0384e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0099 - train_MSE: 2.1249e-04 - val_loss: 0.0094 - val_MSE: 2.0208e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0098 - train_MSE: 2.1020e-04 - val_loss: 0.0094 - val_MSE: 2.0092e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.0881e-04 - val_loss: 0.0094 - val_MSE: 2.0220e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.0793e-04 - val_loss: 0.0094 - val_MSE: 2.0268e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.0669e-04 - val_loss: 0.0094 - val_MSE: 2.0207e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0095 - train_MSE: 2.0479e-04 - val_loss: 0.0094 - val_MSE: 2.0217e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0095 - train_MSE: 2.0362e-04 - val_loss: 0.0094 - val_MSE: 2.0232e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0094 - train_MSE: 2.0326e-04 - val_loss: 0.0094 - val_MSE: 2.0270e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0094 - train_MSE: 2.0281e-04 - val_loss: 0.0095 - val_MSE: 2.0268e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0094 - train_MSE: 2.0187e-04 - val_loss: 0.0095 - val_MSE: 2.0210e-04\n",
      "epoch:1260/1500 - 耗时:0.03分/总37.47分; train_loss 0.0093 train_MSE 0.0002; val_loss 0.0096 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0094 - train_MSE: 2.0187e-04 - val_loss: 0.0095 - val_MSE: 2.0210e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0141e-04 - val_loss: 0.0096 - val_MSE: 2.0218e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0093 - train_MSE: 2.0130e-04 - val_loss: 0.0096 - val_MSE: 2.0203e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0126e-04 - val_loss: 0.0096 - val_MSE: 2.0235e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0032e-04 - val_loss: 0.0103 - val_MSE: 2.1021e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0065e-04 - val_loss: 0.0098 - val_MSE: 2.0383e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0061e-04 - val_loss: 0.0098 - val_MSE: 2.0441e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9991e-04 - val_loss: 0.0108 - val_MSE: 2.1816e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0038e-04 - val_loss: 0.0102 - val_MSE: 2.0844e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0104e-04 - val_loss: 0.0099 - val_MSE: 2.0571e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0093 - train_MSE: 1.9955e-04 - val_loss: 0.0112 - val_MSE: 2.2602e-04\n",
      "epoch:1270/1500 - 耗时:0.03分/总37.76分; train_loss 0.0092 train_MSE 0.0002; val_loss 0.0105 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9958e-04 - val_loss: 0.0112 - val_MSE: 2.2597e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0029e-04 - val_loss: 0.0105 - val_MSE: 2.1324e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0093 - train_MSE: 2.0061e-04 - val_loss: 0.0102 - val_MSE: 2.0831e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9938e-04 - val_loss: 0.0111 - val_MSE: 2.2351e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9996e-04 - val_loss: 0.0107 - val_MSE: 2.1632e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0070e-04 - val_loss: 0.0103 - val_MSE: 2.0966e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0033e-04 - val_loss: 0.0109 - val_MSE: 2.2228e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9888e-04 - val_loss: 0.0106 - val_MSE: 2.1667e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0094 - train_MSE: 2.0123e-04 - val_loss: 0.0100 - val_MSE: 2.0592e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0086e-04 - val_loss: 0.0106 - val_MSE: 2.1585e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0093 - train_MSE: 1.9916e-04 - val_loss: 0.0103 - val_MSE: 2.1291e-04\n",
      "epoch:1280/1500 - 耗时:0.03分/总38.05分; train_loss 0.0093 train_MSE 0.0002; val_loss 0.0098 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9922e-04 - val_loss: 0.0103 - val_MSE: 2.1288e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0007e-04 - val_loss: 0.0098 - val_MSE: 2.0476e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0091e-04 - val_loss: 0.0099 - val_MSE: 2.0521e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9983e-04 - val_loss: 0.0101 - val_MSE: 2.0915e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9895e-04 - val_loss: 0.0096 - val_MSE: 2.0423e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 2.0030e-04 - val_loss: 0.0094 - val_MSE: 2.0123e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0093 - train_MSE: 1.9959e-04 - val_loss: 0.0096 - val_MSE: 2.0439e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0092 - train_MSE: 1.9795e-04 - val_loss: 0.0094 - val_MSE: 2.0293e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9951e-04 - val_loss: 0.0091 - val_MSE: 2.0308e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9957e-04 - val_loss: 0.0093 - val_MSE: 2.0108e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0092 - train_MSE: 1.9792e-04 - val_loss: 0.0092 - val_MSE: 2.0580e-04\n",
      "epoch:1290/1500 - 耗时:0.03分/总38.35分; train_loss 0.0092 train_MSE 0.0002; val_loss 0.0093 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0092 - train_MSE: 1.9794e-04 - val_loss: 0.0092 - val_MSE: 2.0583e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0092 - train_MSE: 1.9820e-04 - val_loss: 0.0093 - val_MSE: 2.1262e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9926e-04 - val_loss: 0.0094 - val_MSE: 2.1431e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0092 - train_MSE: 1.9791e-04 - val_loss: 0.0094 - val_MSE: 2.1642e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0092 - train_MSE: 1.9797e-04 - val_loss: 0.0100 - val_MSE: 2.3283e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9920e-04 - val_loss: 0.0102 - val_MSE: 2.3870e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9863e-04 - val_loss: 0.0103 - val_MSE: 2.4212e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9919e-04 - val_loss: 0.0109 - val_MSE: 2.5697e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0094 - train_MSE: 2.0011e-04 - val_loss: 0.0111 - val_MSE: 2.6078e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0095 - train_MSE: 2.0130e-04 - val_loss: 0.0111 - val_MSE: 2.5946e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0096 - train_MSE: 2.0213e-04 - val_loss: 0.0114 - val_MSE: 2.6656e-04\n",
      "epoch:1300/1500 - 耗时:0.03分/总38.64分; train_loss 0.0099 train_MSE 0.0002; val_loss 0.0111 val_MSE 0.0003\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0096 - train_MSE: 2.0216e-04 - val_loss: 0.0114 - val_MSE: 2.6651e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.0477e-04 - val_loss: 0.0111 - val_MSE: 2.5432e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0098 - train_MSE: 2.0551e-04 - val_loss: 0.0108 - val_MSE: 2.4452e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0099 - train_MSE: 2.0747e-04 - val_loss: 0.0103 - val_MSE: 2.2811e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0099 - train_MSE: 2.0757e-04 - val_loss: 0.0099 - val_MSE: 2.1224e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0099 - train_MSE: 2.0708e-04 - val_loss: 0.0096 - val_MSE: 2.0195e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0099 - train_MSE: 2.0679e-04 - val_loss: 0.0092 - val_MSE: 1.9481e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0098 - train_MSE: 2.0553e-04 - val_loss: 0.0092 - val_MSE: 1.9118e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0097 - train_MSE: 2.0336e-04 - val_loss: 0.0092 - val_MSE: 1.9033e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0096 - train_MSE: 2.0083e-04 - val_loss: 0.0091 - val_MSE: 1.9052e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0095 - train_MSE: 1.9858e-04 - val_loss: 0.0091 - val_MSE: 1.9046e-04\n",
      "epoch:1310/1500 - 耗时:0.03分/总38.94分; train_loss 0.0099 train_MSE 0.0002; val_loss 0.0091 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0095 - train_MSE: 1.9864e-04 - val_loss: 0.0091 - val_MSE: 1.9046e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0094 - train_MSE: 1.9687e-04 - val_loss: 0.0091 - val_MSE: 1.9186e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9551e-04 - val_loss: 0.0091 - val_MSE: 1.9148e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0093 - train_MSE: 1.9439e-04 - val_loss: 0.0091 - val_MSE: 1.9183e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0092 - train_MSE: 1.9318e-04 - val_loss: 0.0091 - val_MSE: 1.9150e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0092 - train_MSE: 1.9266e-04 - val_loss: 0.0090 - val_MSE: 1.9327e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0091 - train_MSE: 1.9201e-04 - val_loss: 0.0090 - val_MSE: 1.9150e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0091 - train_MSE: 1.9114e-04 - val_loss: 0.0091 - val_MSE: 1.9188e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.9111e-04 - val_loss: 0.0091 - val_MSE: 1.9037e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.9013e-04 - val_loss: 0.0091 - val_MSE: 1.9132e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0090 - train_MSE: 1.9009e-04 - val_loss: 0.0092 - val_MSE: 1.9045e-04\n",
      "epoch:1320/1500 - 耗时:0.03分/总39.25分; train_loss 0.0089 train_MSE 0.0002; val_loss 0.0091 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.9009e-04 - val_loss: 0.0092 - val_MSE: 1.9045e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8964e-04 - val_loss: 0.0091 - val_MSE: 1.9053e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8963e-04 - val_loss: 0.0093 - val_MSE: 1.9180e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8980e-04 - val_loss: 0.0097 - val_MSE: 1.9586e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8951e-04 - val_loss: 0.0092 - val_MSE: 1.9053e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8938e-04 - val_loss: 0.0099 - val_MSE: 1.9830e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8895e-04 - val_loss: 0.0103 - val_MSE: 2.0284e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8942e-04 - val_loss: 0.0094 - val_MSE: 1.9195e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8943e-04 - val_loss: 0.0100 - val_MSE: 1.9950e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8857e-04 - val_loss: 0.0109 - val_MSE: 2.1384e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0090 - train_MSE: 1.8921e-04 - val_loss: 0.0099 - val_MSE: 1.9772e-04\n",
      "epoch:1330/1500 - 耗时:0.03分/总39.54分; train_loss 0.0090 train_MSE 0.0002; val_loss 0.0098 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8922e-04 - val_loss: 0.0099 - val_MSE: 1.9772e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8988e-04 - val_loss: 0.0098 - val_MSE: 1.9673e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8862e-04 - val_loss: 0.0109 - val_MSE: 2.1559e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8898e-04 - val_loss: 0.0103 - val_MSE: 2.0349e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8949e-04 - val_loss: 0.0098 - val_MSE: 1.9659e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8903e-04 - val_loss: 0.0104 - val_MSE: 2.0647e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.8758e-04 - val_loss: 0.0104 - val_MSE: 2.0637e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8961e-04 - val_loss: 0.0096 - val_MSE: 1.9332e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8954e-04 - val_loss: 0.0102 - val_MSE: 2.0219e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.8766e-04 - val_loss: 0.0102 - val_MSE: 2.0341e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0090 - train_MSE: 1.8908e-04 - val_loss: 0.0095 - val_MSE: 1.9258e-04\n",
      "epoch:1340/1500 - 耗时:0.03分/总39.83分; train_loss 0.0091 train_MSE 0.0002; val_loss 0.0096 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8918e-04 - val_loss: 0.0095 - val_MSE: 1.9259e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8923e-04 - val_loss: 0.0096 - val_MSE: 1.9472e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8856e-04 - val_loss: 0.0098 - val_MSE: 1.9866e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0089 - train_MSE: 1.8735e-04 - val_loss: 0.0094 - val_MSE: 1.9376e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8923e-04 - val_loss: 0.0090 - val_MSE: 1.8936e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8859e-04 - val_loss: 0.0093 - val_MSE: 1.9255e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0089 - train_MSE: 1.8674e-04 - val_loss: 0.0091 - val_MSE: 1.9227e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8789e-04 - val_loss: 0.0088 - val_MSE: 1.9316e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8902e-04 - val_loss: 0.0089 - val_MSE: 1.9064e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.8666e-04 - val_loss: 0.0089 - val_MSE: 1.9552e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0089 - train_MSE: 1.8684e-04 - val_loss: 0.0090 - val_MSE: 2.0040e-04\n",
      "epoch:1350/1500 - 耗时:0.03分/总40.13分; train_loss 0.0089 train_MSE 0.0002; val_loss 0.0090 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.8688e-04 - val_loss: 0.0090 - val_MSE: 2.0041e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8843e-04 - val_loss: 0.0090 - val_MSE: 2.0333e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.8643e-04 - val_loss: 0.0091 - val_MSE: 2.0507e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.8710e-04 - val_loss: 0.0097 - val_MSE: 2.2020e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8795e-04 - val_loss: 0.0097 - val_MSE: 2.2172e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.8710e-04 - val_loss: 0.0099 - val_MSE: 2.2503e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8765e-04 - val_loss: 0.0106 - val_MSE: 2.4152e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0091 - train_MSE: 1.8888e-04 - val_loss: 0.0105 - val_MSE: 2.4007e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0091 - train_MSE: 1.8894e-04 - val_loss: 0.0108 - val_MSE: 2.4749e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0092 - train_MSE: 1.9029e-04 - val_loss: 0.0109 - val_MSE: 2.4884e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0093 - train_MSE: 1.9132e-04 - val_loss: 0.0108 - val_MSE: 2.4517e-04\n",
      "epoch:1360/1500 - 耗时:0.03分/总40.42分; train_loss 0.0097 train_MSE 0.0002; val_loss 0.0107 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9142e-04 - val_loss: 0.0108 - val_MSE: 2.4515e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0094 - train_MSE: 1.9378e-04 - val_loss: 0.0107 - val_MSE: 2.4022e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0095 - train_MSE: 1.9529e-04 - val_loss: 0.0104 - val_MSE: 2.2690e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0095 - train_MSE: 1.9559e-04 - val_loss: 0.0100 - val_MSE: 2.1431e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0095 - train_MSE: 1.9548e-04 - val_loss: 0.0096 - val_MSE: 2.0229e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0095 - train_MSE: 1.9526e-04 - val_loss: 0.0091 - val_MSE: 1.8898e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0095 - train_MSE: 1.9453e-04 - val_loss: 0.0090 - val_MSE: 1.8601e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0094 - train_MSE: 1.9305e-04 - val_loss: 0.0088 - val_MSE: 1.8128e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0094 - train_MSE: 1.9226e-04 - val_loss: 0.0088 - val_MSE: 1.8021e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.9006e-04 - val_loss: 0.0089 - val_MSE: 1.8037e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0092 - train_MSE: 1.8832e-04 - val_loss: 0.0088 - val_MSE: 1.8080e-04\n",
      "epoch:1370/1500 - 耗时:0.03分/总40.71分; train_loss 0.0097 train_MSE 0.0002; val_loss 0.0089 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0092 - train_MSE: 1.8843e-04 - val_loss: 0.0088 - val_MSE: 1.8081e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0091 - train_MSE: 1.8617e-04 - val_loss: 0.0089 - val_MSE: 1.8120e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8485e-04 - val_loss: 0.0088 - val_MSE: 1.8186e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8412e-04 - val_loss: 0.0088 - val_MSE: 1.8218e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.8336e-04 - val_loss: 0.0089 - val_MSE: 1.8167e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.8227e-04 - val_loss: 0.0088 - val_MSE: 1.8169e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.8119e-04 - val_loss: 0.0089 - val_MSE: 1.8189e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.8121e-04 - val_loss: 0.0089 - val_MSE: 1.8136e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.8044e-04 - val_loss: 0.0089 - val_MSE: 1.8110e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7980e-04 - val_loss: 0.0091 - val_MSE: 1.8213e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0087 - train_MSE: 1.7985e-04 - val_loss: 0.0091 - val_MSE: 1.8214e-04\n",
      "epoch:1380/1500 - 耗时:0.03分/总41.00分; train_loss 0.0086 train_MSE 0.0002; val_loss 0.0091 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7987e-04 - val_loss: 0.0091 - val_MSE: 1.8214e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7941e-04 - val_loss: 0.0091 - val_MSE: 1.8262e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7936e-04 - val_loss: 0.0092 - val_MSE: 1.8398e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0086 - train_MSE: 1.7886e-04 - val_loss: 0.0096 - val_MSE: 1.8767e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0086 - train_MSE: 1.7904e-04 - val_loss: 0.0095 - val_MSE: 1.8719e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7906e-04 - val_loss: 0.0095 - val_MSE: 1.8689e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7946e-04 - val_loss: 0.0102 - val_MSE: 1.9799e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7898e-04 - val_loss: 0.0107 - val_MSE: 2.0490e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7973e-04 - val_loss: 0.0097 - val_MSE: 1.8995e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7949e-04 - val_loss: 0.0104 - val_MSE: 2.0168e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0087 - train_MSE: 1.7848e-04 - val_loss: 0.0110 - val_MSE: 2.1181e-04\n",
      "epoch:1390/1500 - 耗时:0.03分/总41.29分; train_loss 0.0087 train_MSE 0.0002; val_loss 0.0101 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7861e-04 - val_loss: 0.0110 - val_MSE: 2.1175e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7997e-04 - val_loss: 0.0101 - val_MSE: 1.9546e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.8043e-04 - val_loss: 0.0103 - val_MSE: 1.9985e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7912e-04 - val_loss: 0.0108 - val_MSE: 2.1081e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.8065e-04 - val_loss: 0.0102 - val_MSE: 1.9687e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.8095e-04 - val_loss: 0.0100 - val_MSE: 1.9543e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7986e-04 - val_loss: 0.0103 - val_MSE: 2.0235e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7904e-04 - val_loss: 0.0099 - val_MSE: 1.9479e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.8059e-04 - val_loss: 0.0096 - val_MSE: 1.8903e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.8046e-04 - val_loss: 0.0099 - val_MSE: 1.9505e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0087 - train_MSE: 1.7874e-04 - val_loss: 0.0094 - val_MSE: 1.9022e-04\n",
      "epoch:1400/1500 - 耗时:0.03分/总41.58分; train_loss 0.0087 train_MSE 0.0002; val_loss 0.0092 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7881e-04 - val_loss: 0.0094 - val_MSE: 1.9019e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7927e-04 - val_loss: 0.0092 - val_MSE: 1.8437e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7988e-04 - val_loss: 0.0093 - val_MSE: 1.8626e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7951e-04 - val_loss: 0.0092 - val_MSE: 1.8709e-04\n",
      "117/117 [==============================] - 2s 16ms/step - train_loss: 0.0087 - train_MSE: 1.7812e-04 - val_loss: 0.0089 - val_MSE: 1.8410e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7920e-04 - val_loss: 0.0088 - val_MSE: 1.8205e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0087 - train_MSE: 1.7863e-04 - val_loss: 0.0088 - val_MSE: 1.8327e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0086 - train_MSE: 1.7817e-04 - val_loss: 0.0087 - val_MSE: 1.8488e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7786e-04 - val_loss: 0.0087 - val_MSE: 1.8659e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7886e-04 - val_loss: 0.0087 - val_MSE: 1.8808e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0087 - train_MSE: 1.7762e-04 - val_loss: 0.0089 - val_MSE: 1.9555e-04\n",
      "epoch:1410/1500 - 耗时:0.03分/总41.88分; train_loss 0.0088 train_MSE 0.0002; val_loss 0.0092 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7781e-04 - val_loss: 0.0089 - val_MSE: 1.9558e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7769e-04 - val_loss: 0.0092 - val_MSE: 2.0395e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7865e-04 - val_loss: 0.0094 - val_MSE: 2.1101e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7843e-04 - val_loss: 0.0097 - val_MSE: 2.1796e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.7895e-04 - val_loss: 0.0105 - val_MSE: 2.3671e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0088 - train_MSE: 1.8024e-04 - val_loss: 0.0106 - val_MSE: 2.3968e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.8108e-04 - val_loss: 0.0107 - val_MSE: 2.4073e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.8288e-04 - val_loss: 0.0108 - val_MSE: 2.4184e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0092 - train_MSE: 1.8505e-04 - val_loss: 0.0107 - val_MSE: 2.3524e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.8744e-04 - val_loss: 0.0103 - val_MSE: 2.2165e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0094 - train_MSE: 1.8730e-04 - val_loss: 0.0101 - val_MSE: 2.1300e-04\n",
      "epoch:1420/1500 - 耗时:0.03分/总42.17分; train_loss 0.0101 train_MSE 0.0002; val_loss 0.0096 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0094 - train_MSE: 1.8736e-04 - val_loss: 0.0101 - val_MSE: 2.1295e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0094 - train_MSE: 1.8779e-04 - val_loss: 0.0096 - val_MSE: 2.0057e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0093 - train_MSE: 1.8706e-04 - val_loss: 0.0093 - val_MSE: 1.8917e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0092 - train_MSE: 1.8567e-04 - val_loss: 0.0090 - val_MSE: 1.8263e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0092 - train_MSE: 1.8491e-04 - val_loss: 0.0088 - val_MSE: 1.7891e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0092 - train_MSE: 1.8432e-04 - val_loss: 0.0087 - val_MSE: 1.7532e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0091 - train_MSE: 1.8252e-04 - val_loss: 0.0086 - val_MSE: 1.7199e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0090 - train_MSE: 1.8112e-04 - val_loss: 0.0085 - val_MSE: 1.7254e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0089 - train_MSE: 1.7882e-04 - val_loss: 0.0086 - val_MSE: 1.7247e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0088 - train_MSE: 1.7661e-04 - val_loss: 0.0085 - val_MSE: 1.7350e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0087 - train_MSE: 1.7531e-04 - val_loss: 0.0085 - val_MSE: 1.7411e-04\n",
      "epoch:1430/1500 - 耗时:0.03分/总42.49分; train_loss 0.0090 train_MSE 0.0002; val_loss 0.0085 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7533e-04 - val_loss: 0.0085 - val_MSE: 1.7411e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7447e-04 - val_loss: 0.0085 - val_MSE: 1.7486e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0086 - train_MSE: 1.7423e-04 - val_loss: 0.0085 - val_MSE: 1.7501e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0085 - train_MSE: 1.7281e-04 - val_loss: 0.0085 - val_MSE: 1.7286e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0085 - train_MSE: 1.7170e-04 - val_loss: 0.0085 - val_MSE: 1.7282e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0085 - train_MSE: 1.7226e-04 - val_loss: 0.0085 - val_MSE: 1.7279e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0085 - train_MSE: 1.7140e-04 - val_loss: 0.0084 - val_MSE: 1.7210e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7093e-04 - val_loss: 0.0087 - val_MSE: 1.7252e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0085 - train_MSE: 1.7155e-04 - val_loss: 0.0086 - val_MSE: 1.7129e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0085 - train_MSE: 1.7112e-04 - val_loss: 0.0084 - val_MSE: 1.7082e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0084 - train_MSE: 1.7038e-04 - val_loss: 0.0092 - val_MSE: 1.7764e-04\n",
      "epoch:1440/1500 - 耗时:0.03分/总42.80分; train_loss 0.0084 train_MSE 0.0002; val_loss 0.0088 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7042e-04 - val_loss: 0.0092 - val_MSE: 1.7762e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7053e-04 - val_loss: 0.0088 - val_MSE: 1.7232e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0084 - train_MSE: 1.7071e-04 - val_loss: 0.0085 - val_MSE: 1.7125e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7011e-04 - val_loss: 0.0096 - val_MSE: 1.8328e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7018e-04 - val_loss: 0.0091 - val_MSE: 1.7520e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7051e-04 - val_loss: 0.0087 - val_MSE: 1.7274e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6979e-04 - val_loss: 0.0098 - val_MSE: 1.8504e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6988e-04 - val_loss: 0.0094 - val_MSE: 1.7997e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7029e-04 - val_loss: 0.0090 - val_MSE: 1.7474e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0084 - train_MSE: 1.6991e-04 - val_loss: 0.0098 - val_MSE: 1.8503e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0084 - train_MSE: 1.6941e-04 - val_loss: 0.0101 - val_MSE: 1.9005e-04\n",
      "epoch:1450/1500 - 耗时:0.03分/总43.09分; train_loss 0.0085 train_MSE 0.0002; val_loss 0.0091 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0084 - train_MSE: 1.6947e-04 - val_loss: 0.0101 - val_MSE: 1.8999e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7057e-04 - val_loss: 0.0091 - val_MSE: 1.7523e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0084 - train_MSE: 1.7039e-04 - val_loss: 0.0096 - val_MSE: 1.8279e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0084 - train_MSE: 1.6896e-04 - val_loss: 0.0100 - val_MSE: 1.8891e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0084 - train_MSE: 1.6961e-04 - val_loss: 0.0094 - val_MSE: 1.7909e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0085 - train_MSE: 1.7098e-04 - val_loss: 0.0092 - val_MSE: 1.7641e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6991e-04 - val_loss: 0.0100 - val_MSE: 1.8995e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0085 - train_MSE: 1.6978e-04 - val_loss: 0.0093 - val_MSE: 1.7980e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6976e-04 - val_loss: 0.0089 - val_MSE: 1.7385e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7052e-04 - val_loss: 0.0093 - val_MSE: 1.7883e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0084 - train_MSE: 1.6848e-04 - val_loss: 0.0093 - val_MSE: 1.8036e-04\n",
      "epoch:1460/1500 - 耗时:0.03分/总43.39分; train_loss 0.0084 train_MSE 0.0002; val_loss 0.0086 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0084 - train_MSE: 1.6856e-04 - val_loss: 0.0093 - val_MSE: 1.8032e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0085 - train_MSE: 1.7010e-04 - val_loss: 0.0086 - val_MSE: 1.7141e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.7014e-04 - val_loss: 0.0088 - val_MSE: 1.7333e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6873e-04 - val_loss: 0.0090 - val_MSE: 1.7634e-04\n",
      "117/117 [==============================] - 2s 17ms/step - train_loss: 0.0084 - train_MSE: 1.6857e-04 - val_loss: 0.0085 - val_MSE: 1.7317e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6967e-04 - val_loss: 0.0083 - val_MSE: 1.7170e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6928e-04 - val_loss: 0.0085 - val_MSE: 1.7374e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0083 - train_MSE: 1.6774e-04 - val_loss: 0.0084 - val_MSE: 1.7537e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6870e-04 - val_loss: 0.0085 - val_MSE: 1.8334e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6946e-04 - val_loss: 0.0083 - val_MSE: 1.7737e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0083 - train_MSE: 1.6766e-04 - val_loss: 0.0083 - val_MSE: 1.7890e-04\n",
      "epoch:1470/1500 - 耗时:0.03分/总43.68分; train_loss 0.0083 train_MSE 0.0002; val_loss 0.0090 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0083 - train_MSE: 1.6772e-04 - val_loss: 0.0083 - val_MSE: 1.7897e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6825e-04 - val_loss: 0.0090 - val_MSE: 1.9687e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0085 - train_MSE: 1.6929e-04 - val_loss: 0.0090 - val_MSE: 1.9605e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0083 - train_MSE: 1.6800e-04 - val_loss: 0.0090 - val_MSE: 1.9662e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0084 - train_MSE: 1.6847e-04 - val_loss: 0.0099 - val_MSE: 2.1670e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0085 - train_MSE: 1.6927e-04 - val_loss: 0.0098 - val_MSE: 2.1449e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6945e-04 - val_loss: 0.0099 - val_MSE: 2.1675e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0085 - train_MSE: 1.7005e-04 - val_loss: 0.0106 - val_MSE: 2.3216e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0086 - train_MSE: 1.7134e-04 - val_loss: 0.0104 - val_MSE: 2.2549e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0087 - train_MSE: 1.7284e-04 - val_loss: 0.0104 - val_MSE: 2.2386e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0088 - train_MSE: 1.7418e-04 - val_loss: 0.0101 - val_MSE: 2.1546e-04\n",
      "epoch:1480/1500 - 耗时:0.03分/总43.98分; train_loss 0.0093 train_MSE 0.0002; val_loss 0.0099 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0088 - train_MSE: 1.7427e-04 - val_loss: 0.0101 - val_MSE: 2.1543e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.7695e-04 - val_loss: 0.0099 - val_MSE: 2.0857e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.7672e-04 - val_loss: 0.0099 - val_MSE: 2.0453e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0090 - train_MSE: 1.7715e-04 - val_loss: 0.0095 - val_MSE: 1.9344e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0089 - train_MSE: 1.7578e-04 - val_loss: 0.0091 - val_MSE: 1.8245e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0089 - train_MSE: 1.7556e-04 - val_loss: 0.0088 - val_MSE: 1.7535e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.7565e-04 - val_loss: 0.0084 - val_MSE: 1.6805e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.7597e-04 - val_loss: 0.0083 - val_MSE: 1.6475e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0089 - train_MSE: 1.7482e-04 - val_loss: 0.0084 - val_MSE: 1.6313e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0088 - train_MSE: 1.7252e-04 - val_loss: 0.0083 - val_MSE: 1.6324e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0086 - train_MSE: 1.7000e-04 - val_loss: 0.0084 - val_MSE: 1.6356e-04\n",
      "epoch:1490/1500 - 耗时:0.03分/总44.27分; train_loss 0.0092 train_MSE 0.0002; val_loss 0.0083 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0087 - train_MSE: 1.7009e-04 - val_loss: 0.0084 - val_MSE: 1.6356e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0086 - train_MSE: 1.6846e-04 - val_loss: 0.0083 - val_MSE: 1.6434e-04\n",
      "117/117 [==============================] - 2s 15ms/step - train_loss: 0.0085 - train_MSE: 1.6741e-04 - val_loss: 0.0083 - val_MSE: 1.6501e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6647e-04 - val_loss: 0.0084 - val_MSE: 1.6481e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0084 - train_MSE: 1.6523e-04 - val_loss: 0.0084 - val_MSE: 1.6468e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0083 - train_MSE: 1.6443e-04 - val_loss: 0.0084 - val_MSE: 1.6483e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0083 - train_MSE: 1.6402e-04 - val_loss: 0.0084 - val_MSE: 1.6434e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0082 - train_MSE: 1.6315e-04 - val_loss: 0.0085 - val_MSE: 1.6489e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0082 - train_MSE: 1.6309e-04 - val_loss: 0.0085 - val_MSE: 1.6485e-04\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0082 - train_MSE: 1.6281e-04 - val_loss: 0.0085 - val_MSE: 1.6516e-04\n",
      "117/117 [==============================] - ETA: 0s - train_loss: 0.0082 - train_MSE: 1.6249e-04 - val_loss: 0.0090 - val_MSE: 1.6994e-04\n",
      "epoch:1500/1500 - 耗时:0.03分/总44.56分; train_loss 0.0082 train_MSE 0.0002; val_loss 0.0088 val_MSE 0.0002\n",
      "117/117 [==============================] - 2s 14ms/step - train_loss: 0.0082 - train_MSE: 1.6252e-04 - val_loss: 0.0090 - val_MSE: 1.6992e-04\n",
      "\n",
      "epoch:1500/1500 - 共耗时:44.56分,正常结束\n"
     ]
    }
   ],
   "source": [
    "# 4) epoch循环训练:\n",
    "EPOCHS = 1500\n",
    "train_loss_results = []\n",
    "logs = {}  # 字典\n",
    "wait = 0\n",
    "best = np.infty  # 先设置一个无穷大的数字;\n",
    "patience = 80\n",
    "\n",
    "train_start = time.time()\n",
    "callbacks.on_train_begin(logs=logs)\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    callbacks.on_epoch_begin(epoch, logs=logs)\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_MSE.reset_states()\n",
    "\n",
    "    for batch, batch_data in enumerate(dataset_all): #以全部的数据来做训练\n",
    "        callbacks.on_batch_begin(batch, logs=logs)\n",
    "        callbacks.on_train_batch_begin(batch, logs=logs)\n",
    "        train_dict = train_step(batch_data)\n",
    "        logs[\"train_loss\"] = train_dict[\"train_loss\"]\n",
    "        logs[\"train_MSE\"] = train_dict[\"train_MSE\"]\n",
    "\n",
    "        # if batch % 10 == 0:  # 每n次batch,打印\n",
    "        #     print(\n",
    "        #         \"Epoch {} Batch {} train_loss {:.4f} train_MSE {:.4f} \".format(\n",
    "        #             epoch + 1, batch, train_loss.result(), train_MSE.result()\n",
    "        #         )\n",
    "        #     )\n",
    "        callbacks.on_train_batch_end(batch, logs=logs)\n",
    "        callbacks.on_batch_end(batch, logs=logs)\n",
    "    # End epoch 每个epoch\n",
    "    train_loss_results.append(train_loss.result())\n",
    "\n",
    "    val_loss.reset_states()\n",
    "    val_MSE.reset_states()\n",
    "    for batch_data in dataset_val:\n",
    "        callbacks.on_batch_begin(batch, logs=logs)\n",
    "        callbacks.on_test_batch_begin(batch, logs=logs)\n",
    "        test_step(batch_data)\n",
    "        callbacks.on_test_batch_end(batch, logs=logs)\n",
    "        callbacks.on_batch_end(batch, logs=logs)\n",
    "\n",
    "    logs[\"val_loss\"] = val_loss.result()\n",
    "    logs[\"val_MSE\"] = val_MSE.result()\n",
    "    # --------------------\n",
    "    # The early stopping strategy: stop the training if `val_loss` does not\n",
    "    # decrease over a certain number of epochs.\n",
    "    wait += 1\n",
    "    if (\n",
    "        val_loss.result() < best\n",
    "    ):  # 当loss变小,在改进时,计数器恢复为0,存储模型,实现总是存储最佳模型; 当n次loss不再变小,即触发\n",
    "        best = val_loss.result()\n",
    "        wait = 0\n",
    "\n",
    "        ckpt_save_path = ckpt_manager.save()  # 存weight\n",
    "        # print(\"Saving checkpoint for epoch {} at {}\".format(epoch + 1, ckpt_save_path))\n",
    "    if wait >= patience:\n",
    "        print(\n",
    "            \"\\nepoch:{}/{} - 共耗时:{:.2f}分,历{}次训练未见val_loss减少,故提前中止\".format(\n",
    "                epoch + 1, EPOCHS, (time.time() - train_start) / 60, patience\n",
    "            )\n",
    "        )\n",
    "        break\n",
    "    # --------------------\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:  # 每n次epoch,打印\n",
    "\n",
    "        print(\n",
    "            \"\\nepoch:{}/{} - 耗时:{:.2f}分/总{:.2f}分; train_loss {:.4f} train_MSE {:.4f}; val_loss {:.4f} val_MSE {:.4f}\".format(\n",
    "                epoch + 1,\n",
    "                EPOCHS,\n",
    "                (time.time() - epoch_start) / 60,\n",
    "                (time.time() - train_start) / 60,\n",
    "                train_loss.result(),\n",
    "                train_MSE.result(),\n",
    "                val_loss.result(),\n",
    "                val_MSE.result(),\n",
    "            )\n",
    "        )\n",
    "    # print(\"Time taken for 1 epoch: {} mins\\n\".format((time.time() - start) / 60))\n",
    "    callbacks.on_epoch_end(epoch, logs=logs)\n",
    "callbacks.on_train_end(logs=logs)\n",
    "print(\n",
    "    \"\\nepoch:{}/{} - 共耗时:{:.2f}分,正常结束\".format(\n",
    "        epoch + 1, EPOCHS, (time.time() - train_start) / 60\n",
    "    )\n",
    ")\n",
    "\n",
    "# 在Docker上运行时,用于JupyterLab上自动关闭租用连接:\n",
    "# import os\n",
    "# 若释放前要保存环境并命名为 SnapName\n",
    "# os.system(\"export $(cat /proc/1/environ |tr '\\\\0' '\\\\n' | grep MATCLOUD_CANCELTOKEN)&&/public/script/matncli node cancel -url https://matpool.com/api/public/node -save -name snapName\")\n",
    "# 若释放前不需要保存环境\n",
    "# os.system(\"export $(cat /proc/1/environ |tr '\\\\0' '\\\\n' | grep MATCLOUD_CANCELTOKEN)&&/public/script/matncli node cancel -url https://matpool.com/api/public/node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40319ac7-f285-4704-8d3b-af815f7ba67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLinear = LTSF_DLinear(\n",
    "#     seq_len=L_seq,\n",
    "#     pred_len=L_pred,\n",
    "#     channels=14,\n",
    "#     kernel_size=25,\n",
    "#     individual=False,\n",
    "# )\n",
    "# DLinear(iter(dataset_train).next()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e484efed-0435-4465-a3d5-5b9487d4e971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最近存储的checkpoint: ./checkpoint\\CusomModel_F20_230207-672\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Failed to restore from checkpoint or SavedModel at ./checkpoint/BTC_F20_221202-161: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoint/BTC_F20_221202-161",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:96\u001b[0m, in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoint/BTC_F20_221202-161",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:2335\u001b[0m, in \u001b[0;36mCheckpoint.restore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2335\u001b[0m   status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:2220\u001b[0m, in \u001b[0;36mCheckpoint.read\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2219\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;129;01mor\u001b[39;00m checkpoint_options\u001b[38;5;241m.\u001b[39mCheckpointOptions()\n\u001b[1;32m-> 2220\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2221\u001b[0m _checkpoint_read_durations\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m   2222\u001b[0m     _get_duration_microseconds(start_time, time\u001b[38;5;241m.\u001b[39mtime()))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:1338\u001b[0m, in \u001b[0;36mTrackableSaver.restore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m InitializationOnlyStatus(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_view, ops\u001b[38;5;241m.\u001b[39muid())\n\u001b[1;32m-> 1338\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43mpy_checkpoint_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNewCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m graph_building \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:100\u001b[0m, in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 100\u001b[0m   \u001b[43merror_translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:35\u001b[0m, in \u001b[0;36merror_translator\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m---> 35\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoint/BTC_F20_221202-161",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m saved_ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_manager\u001b[38;5;241m.\u001b[39mlatest_checkpoint  \u001b[38;5;66;03m# 提取checkpoint目录中存储的最新的checkpoint\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最近存储的checkpoint: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(saved_ckpt_path))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mckpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./checkpoint/BTC_F20_221202-161\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpect_partial()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:2337\u001b[0m, in \u001b[0;36mCheckpoint.restore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2335\u001b[0m   status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(save_path, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2337\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m   2338\u001b[0m       \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2339\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to restore from checkpoint or SavedModel at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2340\u001b[0m           orig_save_path, e\u001b[38;5;241m.\u001b[39mmessage))\n\u001b[0;32m   2341\u001b[0m \u001b[38;5;66;03m# Create the save counter now so it gets initialized with other variables\u001b[39;00m\n\u001b[0;32m   2342\u001b[0m \u001b[38;5;66;03m# when graph building. Creating it earlier would lead to errors when using,\u001b[39;00m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;66;03m# say, train.Saver() to save the model before initializing it.\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_create_save_counter()\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to restore from checkpoint or SavedModel at ./checkpoint/BTC_F20_221202-161: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoint/BTC_F20_221202-161"
     ]
    }
   ],
   "source": [
    "saved_ckpt_path = ckpt_manager.latest_checkpoint  # 提取checkpoint目录中存储的最新的checkpoint\n",
    "print(\"最近存储的checkpoint: {}\".format(saved_ckpt_path))\n",
    "ckpt.restore(\"./checkpoint/BTC_F20_221202-161\").expect_partial()\n",
    "# ckpt.restore(saved_ckpt_path).assert_consumed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e453ea-f084-445b-aedc-c7aaa513a006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training=False,val_loss:0.0088,val_MSE:0.0002\n",
      "y_hat.shape:(704, 7, 1)\n",
      "y_true.shape:(3976, 1)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 703 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#用验证集评估模型,并获得验证集的预测值,以及y_Scaler缩放之前的值:\n",
    "Modelevaluation(dataset_val)\n",
    "#获取向前创建的dataset_predict数据的预测;dataset_preict包含5*Batch_size组数据,预测出(5*Batch_size,7,1)个数据来\n",
    "y_hat = np.zeros((Batch_size,L_pred,out_features))\n",
    "# print(y_hat.shape)\n",
    "for data_hat in dataset_predict:\n",
    "    y_hat_ = DLinear(data_hat)\n",
    "    # print(y_hat_.shape)\n",
    "    y_hat_inverse = y_Scaler.inverse_transform(y_hat_[:,:,0])\n",
    "    y_hat = np.concatenate([y_hat,np.expand_dims(y_hat_inverse,-1)],axis=0)\n",
    "y_hat = y_hat[Batch_size:] #初始是Batch_size个0;抛去;\n",
    "\n",
    "# y_hat_end = y_hat_.shape[0]\n",
    "print('y_hat.shape:{}'.format(y_hat.shape))\n",
    "\n",
    "# 真实值:\n",
    "y_true = y_Scaler.inverse_transform(data[:,-1:])\n",
    "print('y_true.shape:{}'.format(y_true.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bba06-b553-4afa-a284-0a22b49c531f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9237e3-fdb8-4886-870d-91154a4bbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly.io.templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c12694c-470f-4311-8944-122cb509e720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "真实值",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2022-02-25T20:00:00+08:00",
          "2022-02-26T08:00:00+08:00",
          "2022-02-26T20:00:00+08:00",
          "2022-02-27T08:00:00+08:00",
          "2022-02-27T20:00:00+08:00",
          "2022-02-28T08:00:00+08:00",
          "2022-02-28T20:00:00+08:00",
          "2022-03-01T08:00:00+08:00",
          "2022-03-01T20:00:00+08:00",
          "2022-03-02T08:00:00+08:00",
          "2022-03-02T20:00:00+08:00",
          "2022-03-03T08:00:00+08:00",
          "2022-03-03T20:00:00+08:00",
          "2022-03-04T08:00:00+08:00",
          "2022-03-04T20:00:00+08:00",
          "2022-03-05T08:00:00+08:00",
          "2022-03-05T20:00:00+08:00",
          "2022-03-06T08:00:00+08:00",
          "2022-03-06T20:00:00+08:00",
          "2022-03-07T08:00:00+08:00",
          "2022-03-07T20:00:00+08:00",
          "2022-03-08T08:00:00+08:00",
          "2022-03-08T20:00:00+08:00",
          "2022-03-09T08:00:00+08:00",
          "2022-03-09T20:00:00+08:00",
          "2022-03-10T08:00:00+08:00",
          "2022-03-10T20:00:00+08:00",
          "2022-03-11T08:00:00+08:00",
          "2022-03-11T20:00:00+08:00",
          "2022-03-12T08:00:00+08:00",
          "2022-03-12T20:00:00+08:00",
          "2022-03-13T08:00:00+08:00",
          "2022-03-13T20:00:00+08:00",
          "2022-03-14T08:00:00+08:00",
          "2022-03-14T20:00:00+08:00",
          "2022-03-15T08:00:00+08:00",
          "2022-03-15T20:00:00+08:00",
          "2022-03-16T08:00:00+08:00",
          "2022-03-16T20:00:00+08:00",
          "2022-03-17T08:00:00+08:00",
          "2022-03-17T20:00:00+08:00",
          "2022-03-18T08:00:00+08:00",
          "2022-03-18T20:00:00+08:00",
          "2022-03-19T08:00:00+08:00",
          "2022-03-19T20:00:00+08:00",
          "2022-03-20T08:00:00+08:00",
          "2022-03-20T20:00:00+08:00",
          "2022-03-21T08:00:00+08:00",
          "2022-03-21T20:00:00+08:00",
          "2022-03-22T08:00:00+08:00",
          "2022-03-22T20:00:00+08:00",
          "2022-03-23T08:00:00+08:00",
          "2022-03-23T20:00:00+08:00",
          "2022-03-24T08:00:00+08:00",
          "2022-03-24T20:00:00+08:00",
          "2022-03-25T08:00:00+08:00",
          "2022-03-25T20:00:00+08:00",
          "2022-03-26T08:00:00+08:00",
          "2022-03-26T20:00:00+08:00",
          "2022-03-27T08:00:00+08:00",
          "2022-03-27T20:00:00+08:00",
          "2022-03-28T08:00:00+08:00",
          "2022-03-28T20:00:00+08:00",
          "2022-03-29T08:00:00+08:00",
          "2022-03-29T20:00:00+08:00",
          "2022-03-30T08:00:00+08:00",
          "2022-03-30T20:00:00+08:00",
          "2022-03-31T08:00:00+08:00",
          "2022-03-31T20:00:00+08:00",
          "2022-04-01T08:00:00+08:00",
          "2022-04-01T20:00:00+08:00",
          "2022-04-02T08:00:00+08:00",
          "2022-04-02T20:00:00+08:00",
          "2022-04-03T08:00:00+08:00",
          "2022-04-03T20:00:00+08:00",
          "2022-04-04T08:00:00+08:00",
          "2022-04-04T20:00:00+08:00",
          "2022-04-05T08:00:00+08:00",
          "2022-04-05T20:00:00+08:00",
          "2022-04-06T08:00:00+08:00",
          "2022-04-06T20:00:00+08:00",
          "2022-04-07T08:00:00+08:00",
          "2022-04-07T20:00:00+08:00",
          "2022-04-08T08:00:00+08:00",
          "2022-04-08T20:00:00+08:00",
          "2022-04-09T08:00:00+08:00",
          "2022-04-09T20:00:00+08:00",
          "2022-04-10T08:00:00+08:00",
          "2022-04-10T20:00:00+08:00",
          "2022-04-11T08:00:00+08:00",
          "2022-04-11T20:00:00+08:00",
          "2022-04-12T08:00:00+08:00",
          "2022-04-12T20:00:00+08:00",
          "2022-04-13T08:00:00+08:00",
          "2022-04-13T20:00:00+08:00",
          "2022-04-14T08:00:00+08:00",
          "2022-04-14T20:00:00+08:00",
          "2022-04-15T08:00:00+08:00",
          "2022-04-15T20:00:00+08:00",
          "2022-04-16T08:00:00+08:00",
          "2022-04-16T20:00:00+08:00",
          "2022-04-17T08:00:00+08:00",
          "2022-04-17T20:00:00+08:00",
          "2022-04-18T08:00:00+08:00",
          "2022-04-18T20:00:00+08:00",
          "2022-04-19T08:00:00+08:00",
          "2022-04-19T20:00:00+08:00",
          "2022-04-20T08:00:00+08:00",
          "2022-04-20T20:00:00+08:00",
          "2022-04-21T08:00:00+08:00",
          "2022-04-21T20:00:00+08:00",
          "2022-04-22T08:00:00+08:00",
          "2022-04-22T20:00:00+08:00",
          "2022-04-23T08:00:00+08:00",
          "2022-04-23T20:00:00+08:00",
          "2022-04-24T08:00:00+08:00",
          "2022-04-24T20:00:00+08:00",
          "2022-04-25T08:00:00+08:00",
          "2022-04-25T20:00:00+08:00",
          "2022-04-26T08:00:00+08:00",
          "2022-04-26T20:00:00+08:00",
          "2022-04-27T08:00:00+08:00",
          "2022-04-27T20:00:00+08:00",
          "2022-04-28T08:00:00+08:00",
          "2022-04-28T20:00:00+08:00",
          "2022-04-29T08:00:00+08:00",
          "2022-04-29T20:00:00+08:00",
          "2022-04-30T08:00:00+08:00",
          "2022-04-30T20:00:00+08:00",
          "2022-05-01T08:00:00+08:00",
          "2022-05-01T20:00:00+08:00",
          "2022-05-02T08:00:00+08:00",
          "2022-05-02T20:00:00+08:00",
          "2022-05-03T08:00:00+08:00",
          "2022-05-03T20:00:00+08:00",
          "2022-05-04T08:00:00+08:00",
          "2022-05-04T20:00:00+08:00",
          "2022-05-05T08:00:00+08:00",
          "2022-05-05T20:00:00+08:00",
          "2022-05-06T08:00:00+08:00",
          "2022-05-06T20:00:00+08:00",
          "2022-05-07T08:00:00+08:00",
          "2022-05-07T20:00:00+08:00",
          "2022-05-08T08:00:00+08:00",
          "2022-05-08T20:00:00+08:00",
          "2022-05-09T08:00:00+08:00",
          "2022-05-09T20:00:00+08:00",
          "2022-05-10T08:00:00+08:00",
          "2022-05-10T20:00:00+08:00",
          "2022-05-11T08:00:00+08:00",
          "2022-05-11T20:00:00+08:00",
          "2022-05-12T08:00:00+08:00",
          "2022-05-12T20:00:00+08:00",
          "2022-05-13T08:00:00+08:00",
          "2022-05-13T20:00:00+08:00",
          "2022-05-14T08:00:00+08:00",
          "2022-05-14T20:00:00+08:00",
          "2022-05-15T08:00:00+08:00",
          "2022-05-15T20:00:00+08:00",
          "2022-05-16T08:00:00+08:00",
          "2022-05-16T20:00:00+08:00",
          "2022-05-17T08:00:00+08:00",
          "2022-05-17T20:00:00+08:00",
          "2022-05-18T08:00:00+08:00",
          "2022-05-18T20:00:00+08:00",
          "2022-05-19T08:00:00+08:00",
          "2022-05-19T20:00:00+08:00",
          "2022-05-20T08:00:00+08:00",
          "2022-05-20T20:00:00+08:00",
          "2022-05-21T08:00:00+08:00",
          "2022-05-21T20:00:00+08:00",
          "2022-05-22T08:00:00+08:00",
          "2022-05-22T20:00:00+08:00",
          "2022-05-23T08:00:00+08:00",
          "2022-05-23T20:00:00+08:00",
          "2022-05-24T08:00:00+08:00",
          "2022-05-24T20:00:00+08:00",
          "2022-05-25T08:00:00+08:00",
          "2022-05-25T20:00:00+08:00",
          "2022-05-26T08:00:00+08:00",
          "2022-05-26T20:00:00+08:00",
          "2022-05-27T08:00:00+08:00",
          "2022-05-27T20:00:00+08:00",
          "2022-05-28T08:00:00+08:00",
          "2022-05-28T20:00:00+08:00",
          "2022-05-29T08:00:00+08:00",
          "2022-05-29T20:00:00+08:00",
          "2022-05-30T08:00:00+08:00",
          "2022-05-30T20:00:00+08:00",
          "2022-05-31T08:00:00+08:00",
          "2022-05-31T20:00:00+08:00",
          "2022-06-01T08:00:00+08:00",
          "2022-06-01T20:00:00+08:00",
          "2022-06-02T08:00:00+08:00",
          "2022-06-02T20:00:00+08:00",
          "2022-06-03T08:00:00+08:00",
          "2022-06-03T20:00:00+08:00",
          "2022-06-04T08:00:00+08:00",
          "2022-06-04T20:00:00+08:00",
          "2022-06-05T08:00:00+08:00",
          "2022-06-05T20:00:00+08:00",
          "2022-06-06T08:00:00+08:00",
          "2022-06-06T20:00:00+08:00",
          "2022-06-07T08:00:00+08:00",
          "2022-06-07T20:00:00+08:00",
          "2022-06-08T08:00:00+08:00",
          "2022-06-08T20:00:00+08:00",
          "2022-06-09T08:00:00+08:00",
          "2022-06-09T20:00:00+08:00",
          "2022-06-10T08:00:00+08:00",
          "2022-06-10T20:00:00+08:00",
          "2022-06-11T08:00:00+08:00",
          "2022-06-11T20:00:00+08:00",
          "2022-06-12T08:00:00+08:00",
          "2022-06-12T20:00:00+08:00",
          "2022-06-13T08:00:00+08:00",
          "2022-06-13T20:00:00+08:00",
          "2022-06-14T08:00:00+08:00",
          "2022-06-14T20:00:00+08:00",
          "2022-06-15T08:00:00+08:00",
          "2022-06-15T20:00:00+08:00",
          "2022-06-16T08:00:00+08:00",
          "2022-06-16T20:00:00+08:00",
          "2022-06-17T08:00:00+08:00",
          "2022-06-17T20:00:00+08:00",
          "2022-06-18T08:00:00+08:00",
          "2022-06-18T20:00:00+08:00",
          "2022-06-19T08:00:00+08:00",
          "2022-06-19T20:00:00+08:00",
          "2022-06-20T08:00:00+08:00",
          "2022-06-20T20:00:00+08:00",
          "2022-06-21T08:00:00+08:00",
          "2022-06-21T20:00:00+08:00",
          "2022-06-22T08:00:00+08:00",
          "2022-06-22T20:00:00+08:00",
          "2022-06-23T08:00:00+08:00",
          "2022-06-23T20:00:00+08:00",
          "2022-06-24T08:00:00+08:00",
          "2022-06-24T20:00:00+08:00",
          "2022-06-25T08:00:00+08:00",
          "2022-06-25T20:00:00+08:00",
          "2022-06-26T08:00:00+08:00",
          "2022-06-26T20:00:00+08:00",
          "2022-06-27T08:00:00+08:00",
          "2022-06-27T20:00:00+08:00",
          "2022-06-28T08:00:00+08:00",
          "2022-06-28T20:00:00+08:00",
          "2022-06-29T08:00:00+08:00",
          "2022-06-29T20:00:00+08:00",
          "2022-06-30T08:00:00+08:00",
          "2022-06-30T20:00:00+08:00",
          "2022-07-01T08:00:00+08:00",
          "2022-07-01T20:00:00+08:00",
          "2022-07-02T08:00:00+08:00",
          "2022-07-02T20:00:00+08:00",
          "2022-07-03T08:00:00+08:00",
          "2022-07-03T20:00:00+08:00",
          "2022-07-04T08:00:00+08:00",
          "2022-07-04T20:00:00+08:00",
          "2022-07-05T08:00:00+08:00",
          "2022-07-05T20:00:00+08:00",
          "2022-07-06T08:00:00+08:00",
          "2022-07-06T20:00:00+08:00",
          "2022-07-07T08:00:00+08:00",
          "2022-07-07T20:00:00+08:00",
          "2022-07-08T08:00:00+08:00",
          "2022-07-08T20:00:00+08:00",
          "2022-07-09T08:00:00+08:00",
          "2022-07-09T20:00:00+08:00",
          "2022-07-10T08:00:00+08:00",
          "2022-07-10T20:00:00+08:00",
          "2022-07-11T08:00:00+08:00",
          "2022-07-11T20:00:00+08:00",
          "2022-07-12T08:00:00+08:00",
          "2022-07-12T20:00:00+08:00",
          "2022-07-13T08:00:00+08:00",
          "2022-07-13T20:00:00+08:00",
          "2022-07-14T08:00:00+08:00",
          "2022-07-14T20:00:00+08:00",
          "2022-07-15T08:00:00+08:00",
          "2022-07-15T20:00:00+08:00",
          "2022-07-16T08:00:00+08:00",
          "2022-07-16T20:00:00+08:00",
          "2022-07-17T08:00:00+08:00",
          "2022-07-17T20:00:00+08:00",
          "2022-07-18T08:00:00+08:00",
          "2022-07-18T20:00:00+08:00",
          "2022-07-19T08:00:00+08:00",
          "2022-07-19T20:00:00+08:00",
          "2022-07-20T08:00:00+08:00",
          "2022-07-20T20:00:00+08:00",
          "2022-07-21T08:00:00+08:00",
          "2022-07-21T20:00:00+08:00",
          "2022-07-22T08:00:00+08:00",
          "2022-07-22T20:00:00+08:00",
          "2022-07-23T08:00:00+08:00",
          "2022-07-23T20:00:00+08:00",
          "2022-07-24T08:00:00+08:00",
          "2022-07-24T20:00:00+08:00",
          "2022-07-25T08:00:00+08:00",
          "2022-07-25T20:00:00+08:00",
          "2022-07-26T08:00:00+08:00",
          "2022-07-26T20:00:00+08:00",
          "2022-07-27T08:00:00+08:00",
          "2022-07-27T20:00:00+08:00",
          "2022-07-28T08:00:00+08:00",
          "2022-07-28T20:00:00+08:00",
          "2022-07-29T08:00:00+08:00",
          "2022-07-29T20:00:00+08:00",
          "2022-07-30T08:00:00+08:00",
          "2022-07-30T20:00:00+08:00",
          "2022-07-31T08:00:00+08:00",
          "2022-07-31T20:00:00+08:00",
          "2022-08-01T08:00:00+08:00",
          "2022-08-01T20:00:00+08:00",
          "2022-08-02T08:00:00+08:00",
          "2022-08-02T20:00:00+08:00",
          "2022-08-03T08:00:00+08:00",
          "2022-08-03T20:00:00+08:00",
          "2022-08-04T08:00:00+08:00",
          "2022-08-04T20:00:00+08:00",
          "2022-08-05T08:00:00+08:00",
          "2022-08-05T20:00:00+08:00",
          "2022-08-06T08:00:00+08:00",
          "2022-08-06T20:00:00+08:00",
          "2022-08-07T08:00:00+08:00",
          "2022-08-07T20:00:00+08:00",
          "2022-08-08T08:00:00+08:00",
          "2022-08-08T20:00:00+08:00",
          "2022-08-09T08:00:00+08:00",
          "2022-08-09T20:00:00+08:00",
          "2022-08-10T08:00:00+08:00",
          "2022-08-10T20:00:00+08:00",
          "2022-08-11T08:00:00+08:00",
          "2022-08-11T20:00:00+08:00",
          "2022-08-12T08:00:00+08:00",
          "2022-08-12T20:00:00+08:00",
          "2022-08-13T08:00:00+08:00",
          "2022-08-13T20:00:00+08:00",
          "2022-08-14T08:00:00+08:00",
          "2022-08-14T20:00:00+08:00",
          "2022-08-15T08:00:00+08:00",
          "2022-08-15T20:00:00+08:00",
          "2022-08-16T08:00:00+08:00",
          "2022-08-16T20:00:00+08:00",
          "2022-08-17T08:00:00+08:00",
          "2022-08-17T20:00:00+08:00",
          "2022-08-18T08:00:00+08:00",
          "2022-08-18T20:00:00+08:00",
          "2022-08-19T08:00:00+08:00",
          "2022-08-19T20:00:00+08:00",
          "2022-08-20T08:00:00+08:00",
          "2022-08-20T20:00:00+08:00",
          "2022-08-21T08:00:00+08:00",
          "2022-08-21T20:00:00+08:00",
          "2022-08-22T08:00:00+08:00",
          "2022-08-22T20:00:00+08:00",
          "2022-08-23T08:00:00+08:00",
          "2022-08-23T20:00:00+08:00",
          "2022-08-24T08:00:00+08:00",
          "2022-08-24T20:00:00+08:00",
          "2022-08-25T08:00:00+08:00",
          "2022-08-25T20:00:00+08:00",
          "2022-08-26T08:00:00+08:00",
          "2022-08-26T20:00:00+08:00",
          "2022-08-27T08:00:00+08:00",
          "2022-08-27T20:00:00+08:00",
          "2022-08-28T08:00:00+08:00",
          "2022-08-28T20:00:00+08:00",
          "2022-08-29T08:00:00+08:00",
          "2022-08-29T20:00:00+08:00",
          "2022-08-30T08:00:00+08:00",
          "2022-08-30T20:00:00+08:00",
          "2022-08-31T08:00:00+08:00",
          "2022-08-31T20:00:00+08:00",
          "2022-09-01T08:00:00+08:00",
          "2022-09-01T20:00:00+08:00",
          "2022-09-02T08:00:00+08:00",
          "2022-09-02T20:00:00+08:00",
          "2022-09-03T08:00:00+08:00",
          "2022-09-03T20:00:00+08:00",
          "2022-09-04T08:00:00+08:00",
          "2022-09-04T20:00:00+08:00",
          "2022-09-05T08:00:00+08:00",
          "2022-09-05T20:00:00+08:00",
          "2022-09-06T08:00:00+08:00",
          "2022-09-06T20:00:00+08:00",
          "2022-09-07T08:00:00+08:00",
          "2022-09-07T20:00:00+08:00",
          "2022-09-08T08:00:00+08:00",
          "2022-09-08T20:00:00+08:00",
          "2022-09-09T08:00:00+08:00",
          "2022-09-09T20:00:00+08:00",
          "2022-09-10T08:00:00+08:00",
          "2022-09-10T20:00:00+08:00",
          "2022-09-11T08:00:00+08:00",
          "2022-09-11T20:00:00+08:00",
          "2022-09-12T08:00:00+08:00",
          "2022-09-12T20:00:00+08:00",
          "2022-09-13T08:00:00+08:00",
          "2022-09-13T20:00:00+08:00",
          "2022-09-14T08:00:00+08:00",
          "2022-09-14T20:00:00+08:00",
          "2022-09-15T08:00:00+08:00",
          "2022-09-15T20:00:00+08:00",
          "2022-09-16T08:00:00+08:00",
          "2022-09-16T20:00:00+08:00",
          "2022-09-17T08:00:00+08:00",
          "2022-09-17T20:00:00+08:00",
          "2022-09-18T08:00:00+08:00",
          "2022-09-18T20:00:00+08:00",
          "2022-09-19T08:00:00+08:00",
          "2022-09-19T20:00:00+08:00",
          "2022-09-20T08:00:00+08:00",
          "2022-09-20T20:00:00+08:00",
          "2022-09-21T08:00:00+08:00",
          "2022-09-21T20:00:00+08:00",
          "2022-09-22T08:00:00+08:00",
          "2022-09-22T20:00:00+08:00",
          "2022-09-23T08:00:00+08:00",
          "2022-09-23T20:00:00+08:00",
          "2022-09-24T08:00:00+08:00",
          "2022-09-24T20:00:00+08:00",
          "2022-09-25T08:00:00+08:00",
          "2022-09-25T20:00:00+08:00",
          "2022-09-26T08:00:00+08:00",
          "2022-09-26T20:00:00+08:00",
          "2022-09-27T08:00:00+08:00",
          "2022-09-27T20:00:00+08:00",
          "2022-09-28T08:00:00+08:00",
          "2022-09-28T20:00:00+08:00",
          "2022-09-29T08:00:00+08:00",
          "2022-09-29T20:00:00+08:00",
          "2022-09-30T08:00:00+08:00",
          "2022-09-30T20:00:00+08:00",
          "2022-10-01T08:00:00+08:00",
          "2022-10-01T20:00:00+08:00",
          "2022-10-02T08:00:00+08:00",
          "2022-10-02T20:00:00+08:00",
          "2022-10-03T08:00:00+08:00",
          "2022-10-03T20:00:00+08:00",
          "2022-10-04T08:00:00+08:00",
          "2022-10-04T20:00:00+08:00",
          "2022-10-05T08:00:00+08:00",
          "2022-10-05T20:00:00+08:00",
          "2022-10-06T08:00:00+08:00",
          "2022-10-06T20:00:00+08:00",
          "2022-10-07T08:00:00+08:00",
          "2022-10-07T20:00:00+08:00",
          "2022-10-08T08:00:00+08:00",
          "2022-10-08T20:00:00+08:00",
          "2022-10-09T08:00:00+08:00",
          "2022-10-09T20:00:00+08:00",
          "2022-10-10T08:00:00+08:00",
          "2022-10-10T20:00:00+08:00",
          "2022-10-11T08:00:00+08:00",
          "2022-10-11T20:00:00+08:00",
          "2022-10-12T08:00:00+08:00",
          "2022-10-12T20:00:00+08:00",
          "2022-10-13T08:00:00+08:00",
          "2022-10-13T20:00:00+08:00",
          "2022-10-14T08:00:00+08:00",
          "2022-10-14T20:00:00+08:00",
          "2022-10-15T08:00:00+08:00",
          "2022-10-15T20:00:00+08:00",
          "2022-10-16T08:00:00+08:00",
          "2022-10-16T20:00:00+08:00",
          "2022-10-17T08:00:00+08:00",
          "2022-10-17T20:00:00+08:00",
          "2022-10-18T08:00:00+08:00",
          "2022-10-18T20:00:00+08:00",
          "2022-10-19T08:00:00+08:00",
          "2022-10-19T20:00:00+08:00",
          "2022-10-20T08:00:00+08:00",
          "2022-10-20T20:00:00+08:00",
          "2022-10-21T08:00:00+08:00",
          "2022-10-21T20:00:00+08:00",
          "2022-10-22T08:00:00+08:00",
          "2022-10-22T20:00:00+08:00",
          "2022-10-23T08:00:00+08:00",
          "2022-10-23T20:00:00+08:00",
          "2022-10-24T08:00:00+08:00",
          "2022-10-24T20:00:00+08:00",
          "2022-10-25T08:00:00+08:00",
          "2022-10-25T20:00:00+08:00",
          "2022-10-26T08:00:00+08:00",
          "2022-10-26T20:00:00+08:00",
          "2022-10-27T08:00:00+08:00",
          "2022-10-27T20:00:00+08:00",
          "2022-10-28T08:00:00+08:00",
          "2022-10-28T20:00:00+08:00",
          "2022-10-29T08:00:00+08:00",
          "2022-10-29T20:00:00+08:00",
          "2022-10-30T08:00:00+08:00",
          "2022-10-30T20:00:00+08:00",
          "2022-10-31T08:00:00+08:00",
          "2022-10-31T20:00:00+08:00",
          "2022-11-01T08:00:00+08:00",
          "2022-11-01T20:00:00+08:00",
          "2022-11-02T08:00:00+08:00",
          "2022-11-02T20:00:00+08:00",
          "2022-11-03T08:00:00+08:00",
          "2022-11-03T20:00:00+08:00",
          "2022-11-04T08:00:00+08:00",
          "2022-11-04T20:00:00+08:00",
          "2022-11-05T08:00:00+08:00",
          "2022-11-05T20:00:00+08:00",
          "2022-11-06T08:00:00+08:00",
          "2022-11-06T20:00:00+08:00",
          "2022-11-07T08:00:00+08:00",
          "2022-11-07T20:00:00+08:00",
          "2022-11-08T08:00:00+08:00",
          "2022-11-08T20:00:00+08:00",
          "2022-11-09T08:00:00+08:00",
          "2022-11-09T20:00:00+08:00",
          "2022-11-10T08:00:00+08:00",
          "2022-11-10T20:00:00+08:00",
          "2022-11-11T08:00:00+08:00",
          "2022-11-11T20:00:00+08:00",
          "2022-11-12T08:00:00+08:00",
          "2022-11-12T20:00:00+08:00",
          "2022-11-13T08:00:00+08:00",
          "2022-11-13T20:00:00+08:00",
          "2022-11-14T08:00:00+08:00",
          "2022-11-14T20:00:00+08:00",
          "2022-11-15T08:00:00+08:00",
          "2022-11-15T20:00:00+08:00",
          "2022-11-16T08:00:00+08:00",
          "2022-11-16T20:00:00+08:00",
          "2022-11-17T08:00:00+08:00",
          "2022-11-17T20:00:00+08:00",
          "2022-11-18T08:00:00+08:00",
          "2022-11-18T20:00:00+08:00",
          "2022-11-19T08:00:00+08:00",
          "2022-11-19T20:00:00+08:00",
          "2022-11-20T08:00:00+08:00",
          "2022-11-20T20:00:00+08:00",
          "2022-11-21T08:00:00+08:00",
          "2022-11-21T20:00:00+08:00",
          "2022-11-22T08:00:00+08:00",
          "2022-11-22T20:00:00+08:00",
          "2022-11-23T08:00:00+08:00",
          "2022-11-23T20:00:00+08:00",
          "2022-11-24T08:00:00+08:00",
          "2022-11-24T20:00:00+08:00",
          "2022-11-25T08:00:00+08:00",
          "2022-11-25T20:00:00+08:00",
          "2022-11-26T08:00:00+08:00",
          "2022-11-26T20:00:00+08:00",
          "2022-11-27T08:00:00+08:00",
          "2022-11-27T20:00:00+08:00",
          "2022-11-28T08:00:00+08:00",
          "2022-11-28T20:00:00+08:00",
          "2022-11-29T08:00:00+08:00",
          "2022-11-29T20:00:00+08:00",
          "2022-11-30T08:00:00+08:00",
          "2022-11-30T20:00:00+08:00",
          "2022-12-01T08:00:00+08:00",
          "2022-12-01T20:00:00+08:00",
          "2022-12-02T08:00:00+08:00",
          "2022-12-02T20:00:00+08:00",
          "2022-12-03T08:00:00+08:00",
          "2022-12-03T20:00:00+08:00",
          "2022-12-04T08:00:00+08:00",
          "2022-12-04T20:00:00+08:00",
          "2022-12-05T08:00:00+08:00",
          "2022-12-05T20:00:00+08:00",
          "2022-12-06T08:00:00+08:00",
          "2022-12-06T20:00:00+08:00",
          "2022-12-07T08:00:00+08:00",
          "2022-12-07T20:00:00+08:00",
          "2022-12-08T08:00:00+08:00",
          "2022-12-08T20:00:00+08:00",
          "2022-12-09T08:00:00+08:00",
          "2022-12-09T20:00:00+08:00",
          "2022-12-10T08:00:00+08:00",
          "2022-12-10T20:00:00+08:00",
          "2022-12-11T08:00:00+08:00",
          "2022-12-11T20:00:00+08:00",
          "2022-12-12T08:00:00+08:00",
          "2022-12-12T20:00:00+08:00",
          "2022-12-13T08:00:00+08:00",
          "2022-12-13T20:00:00+08:00",
          "2022-12-14T08:00:00+08:00",
          "2022-12-14T20:00:00+08:00",
          "2022-12-15T08:00:00+08:00",
          "2022-12-15T20:00:00+08:00",
          "2022-12-16T08:00:00+08:00",
          "2022-12-16T20:00:00+08:00",
          "2022-12-17T08:00:00+08:00",
          "2022-12-17T20:00:00+08:00",
          "2022-12-18T08:00:00+08:00",
          "2022-12-18T20:00:00+08:00",
          "2022-12-19T08:00:00+08:00",
          "2022-12-19T20:00:00+08:00",
          "2022-12-20T08:00:00+08:00",
          "2022-12-20T20:00:00+08:00",
          "2022-12-21T08:00:00+08:00",
          "2022-12-21T20:00:00+08:00",
          "2022-12-22T08:00:00+08:00",
          "2022-12-22T20:00:00+08:00",
          "2022-12-23T08:00:00+08:00",
          "2022-12-23T20:00:00+08:00",
          "2022-12-24T08:00:00+08:00",
          "2022-12-24T20:00:00+08:00",
          "2022-12-25T08:00:00+08:00",
          "2022-12-25T20:00:00+08:00",
          "2022-12-26T08:00:00+08:00",
          "2022-12-26T20:00:00+08:00",
          "2022-12-27T08:00:00+08:00",
          "2022-12-27T20:00:00+08:00",
          "2022-12-28T08:00:00+08:00",
          "2022-12-28T20:00:00+08:00",
          "2022-12-29T08:00:00+08:00",
          "2022-12-29T20:00:00+08:00",
          "2022-12-30T08:00:00+08:00",
          "2022-12-30T20:00:00+08:00",
          "2022-12-31T08:00:00+08:00",
          "2022-12-31T20:00:00+08:00",
          "2023-01-01T08:00:00+08:00",
          "2023-01-01T20:00:00+08:00",
          "2023-01-02T08:00:00+08:00",
          "2023-01-02T20:00:00+08:00",
          "2023-01-03T08:00:00+08:00",
          "2023-01-03T20:00:00+08:00",
          "2023-01-04T08:00:00+08:00",
          "2023-01-04T20:00:00+08:00",
          "2023-01-05T08:00:00+08:00",
          "2023-01-05T20:00:00+08:00",
          "2023-01-06T08:00:00+08:00",
          "2023-01-06T20:00:00+08:00",
          "2023-01-07T08:00:00+08:00",
          "2023-01-07T20:00:00+08:00",
          "2023-01-08T08:00:00+08:00",
          "2023-01-08T20:00:00+08:00",
          "2023-01-09T08:00:00+08:00",
          "2023-01-09T20:00:00+08:00",
          "2023-01-10T08:00:00+08:00",
          "2023-01-10T20:00:00+08:00",
          "2023-01-11T08:00:00+08:00",
          "2023-01-11T20:00:00+08:00",
          "2023-01-12T08:00:00+08:00",
          "2023-01-12T20:00:00+08:00",
          "2023-01-13T08:00:00+08:00",
          "2023-01-13T20:00:00+08:00",
          "2023-01-14T08:00:00+08:00",
          "2023-01-14T20:00:00+08:00",
          "2023-01-15T08:00:00+08:00",
          "2023-01-15T20:00:00+08:00",
          "2023-01-16T08:00:00+08:00",
          "2023-01-16T20:00:00+08:00",
          "2023-01-17T08:00:00+08:00",
          "2023-01-17T20:00:00+08:00",
          "2023-01-18T08:00:00+08:00",
          "2023-01-18T20:00:00+08:00",
          "2023-01-19T08:00:00+08:00",
          "2023-01-19T20:00:00+08:00",
          "2023-01-20T08:00:00+08:00",
          "2023-01-20T20:00:00+08:00",
          "2023-01-21T08:00:00+08:00",
          "2023-01-21T20:00:00+08:00",
          "2023-01-22T08:00:00+08:00",
          "2023-01-22T20:00:00+08:00",
          "2023-01-23T08:00:00+08:00",
          "2023-01-23T20:00:00+08:00",
          "2023-01-24T08:00:00+08:00",
          "2023-01-24T20:00:00+08:00",
          "2023-01-25T08:00:00+08:00",
          "2023-01-25T20:00:00+08:00",
          "2023-01-26T08:00:00+08:00",
          "2023-01-26T20:00:00+08:00",
          "2023-01-27T08:00:00+08:00",
          "2023-01-27T20:00:00+08:00",
          "2023-01-28T08:00:00+08:00",
          "2023-01-28T20:00:00+08:00",
          "2023-01-29T08:00:00+08:00",
          "2023-01-29T20:00:00+08:00",
          "2023-01-30T08:00:00+08:00",
          "2023-01-30T20:00:00+08:00",
          "2023-01-31T08:00:00+08:00",
          "2023-01-31T20:00:00+08:00",
          "2023-02-01T08:00:00+08:00",
          "2023-02-01T20:00:00+08:00",
          "2023-02-02T08:00:00+08:00",
          "2023-02-02T20:00:00+08:00",
          "2023-02-03T08:00:00+08:00",
          "2023-02-03T20:00:00+08:00",
          "2023-02-04T08:00:00+08:00",
          "2023-02-04T20:00:00+08:00",
          "2023-02-05T08:00:00+08:00",
          "2023-02-05T20:00:00+08:00",
          "2023-02-06T08:00:00+08:00",
          "2023-02-06T20:00:00+08:00",
          "2023-02-07T08:00:00+08:00",
          "2023-02-07T20:00:00+08:00",
          "2023-02-08T08:00:00+08:00",
          "2023-02-08T20:00:00+08:00",
          "2023-02-09T08:00:00+08:00",
          "2023-02-09T20:00:00+08:00",
          "2023-02-10T08:00:00+08:00",
          "2023-02-10T20:00:00+08:00",
          "2023-02-11T08:00:00+08:00",
          "2023-02-11T20:00:00+08:00",
          "2023-02-12T08:00:00+08:00"
         ],
         "xhoverformat": "%y/%m/%d_%H:00",
         "y": [
          39219.171875,
          38928.2109375,
          39116.71875,
          39479.80078125,
          37699.0703125,
          38333.6484375,
          43160,
          43609.9609375,
          44421.19921875,
          44103.28125,
          43892.98046875,
          43382.23046875,
          42454,
          41662.0703125,
          39148.66015625,
          39129.58984375,
          39397.9609375,
          38352.48046875,
          38420.80859375,
          38337.05078125,
          37988,
          38983.05078125,
          38730.62890625,
          42151.66015625,
          41941.7109375,
          39076.37890625,
          39422,
          39893.6796875,
          38729.5703125,
          39079.16015625,
          38807.359375,
          38741.12109375,
          37777.33984375,
          38897.640625,
          39671.37109375,
          38645.01171875,
          39280.328125,
          40521.6015625,
          41114,
          40748.51171875,
          40917.8984375,
          40390.41015625,
          41757.51171875,
          41721.78125,
          42201.12890625,
          41586.859375,
          41262.109375,
          41244.28125,
          41002.25,
          42983,
          42364.12890625,
          42039.78125,
          42882.76171875,
          42968.421875,
          43991.4609375,
          44585.28125,
          44313.16015625,
          44334.48828125,
          44511.26953125,
          44569.5,
          46827.76171875,
          47252.5390625,
          47122.2109375,
          47896.1015625,
          47434.80078125,
          47319.91015625,
          47067.98828125,
          47152.01171875,
          45510.33984375,
          45064.26171875,
          46283.48828125,
          46542.83984375,
          45811,
          46252.58984375,
          46407.3515625,
          46160.08984375,
          46580.51171875,
          46683.37109375,
          45497.55078125,
          44819.19140625,
          43170.46875,
          43766.73828125,
          43444.19140625,
          43298.7890625,
          42252.01171875,
          42445.1015625,
          42753.96875,
          42680.359375,
          42158.8515625,
          41067.62890625,
          39530.44921875,
          40378,
          40074.94140625,
          39722.640625,
          41147.7890625,
          40919.98828125,
          39942.37890625,
          40220,
          40551.8984375,
          40416.94921875,
          40378.7109375,
          40464.76953125,
          39678.12109375,
          38998.5390625,
          40801.12890625,
          40687.30078125,
          41493.1796875,
          42090,
          41358.19140625,
          42440,
          40480.01171875,
          40585.5390625,
          39709.1796875,
          39602.9296875,
          39441.6015625,
          39609.109375,
          39450.12890625,
          38832.2890625,
          40426.078125,
          40467.03125,
          38112.6484375,
          39017.19140625,
          39235.71875,
          39679.30859375,
          39742.0703125,
          38749.5390625,
          38596.109375,
          38580.01171875,
          37630.80078125,
          37942.78125,
          38468.3515625,
          38528.76953125,
          38525.16015625,
          38570.01171875,
          37728.94921875,
          39002.30078125,
          39690,
          39492.828125,
          36552.96875,
          35780.83984375,
          36013.76953125,
          36055.859375,
          35472.390625,
          34786.23828125,
          34038.3984375,
          33122.30859375,
          30076.310546875,
          31622.240234375,
          31017.099609375,
          31533.150390625,
          29103.939453125,
          28472.98046875,
          29029.75,
          30668.080078125,
          29287.05078125,
          29074.240234375,
          30086.740234375,
          30241.4609375,
          31328.890625,
          29950.94921875,
          29874.009765625,
          30319.470703125,
          30444.9296875,
          29833.580078125,
          28715.3203125,
          29500.19921875,
          30319.23046875,
          30414.0703125,
          29201.009765625,
          29288,
          29445.060546875,
          29897.51953125,
          30293.939453125,
          30397.109375,
          29109.150390625,
          29295.740234375,
          29654.580078125,
          29409.009765625,
          29542.150390625,
          28998.400390625,
          29201.349609375,
          28912.9609375,
          28629.80078125,
          28828.01953125,
          29031.330078125,
          29213.849609375,
          29468.099609375,
          30665.369140625,
          31734.220703125,
          31767,
          31801.0390625,
          31609.16015625,
          29805.830078125,
          30173.669921875,
          30452.619140625,
          29758.189453125,
          29700.2109375,
          29681.689453125,
          29864.0390625,
          29718.689453125,
          29919.2109375,
          31396.7109375,
          31373.099609375,
          29521.5,
          31125.330078125,
          30410.849609375,
          30204.76953125,
          30299.470703125,
          30109.9296875,
          30020.560546875,
          29091.880859375,
          28734.009765625,
          28424.69921875,
          27457.390625,
          26574.529296875,
          23729.4296875,
          22487.41015625,
          21994.560546875,
          22136.41015625,
          21177.029296875,
          22583.720703125,
          21044.55078125,
          20401.310546875,
          20972.0390625,
          20468.810546875,
          19243.98046875,
          18970.7890625,
          19692.5,
          20574,
          20801.7890625,
          20573.890625,
          20962.419921875,
          20723.51953125,
          20506.30078125,
          19987.990234375,
          20638.7890625,
          21110.130859375,
          21169.529296875,
          21237.689453125,
          21340.220703125,
          21491.189453125,
          21708.599609375,
          21038.0703125,
          21304.55078125,
          20742.560546875,
          20998.130859375,
          20281.2890625,
          20104.80078125,
          20123.009765625,
          19101.359375,
          19942.2109375,
          19191.029296875,
          19279.80078125,
          19195.2109375,
          19252.810546875,
          19089.80078125,
          19315.830078125,
          19806.490234375,
          20236.7109375,
          19520.390625,
          20175.830078125,
          20103.4296875,
          20564.509765625,
          20507.830078125,
          21624.98046875,
          21583.98046875,
          21594.75,
          21447.2890625,
          21591.830078125,
          21301.83984375,
          20862.470703125,
          20473.060546875,
          19963.609375,
          19773.900390625,
          19328.75,
          19843.890625,
          20234.869140625,
          19738.130859375,
          20588.83984375,
          20769.740234375,
          20830.0390625,
          20616.689453125,
          21195.599609375,
          21456.7890625,
          20798.16015625,
          22133.310546875,
          22432.580078125,
          21974.490234375,
          23396.619140625,
          23728.55078125,
          23223.30078125,
          22606.0390625,
          23152.189453125,
          23610.580078125,
          22684.830078125,
          22227.529296875,
          22451.0703125,
          22657.630859375,
          22579.6796875,
          21941.25,
          21310.900390625,
          21090.220703125,
          21254.669921875,
          21200.23046875,
          22952.44921875,
          23114.51953125,
          23842.9296875,
          23720.560546875,
          23773.75,
          23956.380859375,
          23643.509765625,
          23801.0703125,
          23293.3203125,
          23227.7890625,
          23268.009765625,
          22882.609375,
          22987.7890625,
          23402.830078125,
          22818.369140625,
          22885.009765625,
          22622.98046875,
          23405.130859375,
          23312.419921875,
          23157.419921875,
          22954.2109375,
          23038.48046875,
          23174.390625,
          24166.119140625,
          23810,
          23263.919921875,
          23149.94921875,
          23123.94921875,
          23954.05078125,
          24559.369140625,
          23934.390625,
          23672.990234375,
          24403.6796875,
          24435.91015625,
          24441.380859375,
          24564.490234375,
          24305.240234375,
          24049.48046875,
          24094.8203125,
          24038.029296875,
          23854.740234375,
          23746.650390625,
          23342.66015625,
          23534.4296875,
          23191.19921875,
          21467.91015625,
          20834.390625,
          21233.66015625,
          21140.0703125,
          21524.390625,
          21515.609375,
          21248.7109375,
          21399.830078125,
          21456.33984375,
          21529.119140625,
          21438.919921875,
          21368.080078125,
          21720.310546875,
          21559.0390625,
          21189.76953125,
          20241.05078125,
          20211.2109375,
          20037.599609375,
          20034.970703125,
          19555.609375,
          19825.08984375,
          20285.73046875,
          20403.80078125,
          19811.66015625,
          20314.779296875,
          20050.01953125,
          20074.009765625,
          20131.4609375,
          20090.810546875,
          19951.859375,
          19798.759765625,
          19831.900390625,
          19850.7890625,
          20000.30078125,
          19701.94921875,
          19796.83984375,
          19918.330078125,
          18790.609375,
          18739.58984375,
          19292.83984375,
          19311.150390625,
          19319.76953125,
          20937.720703125,
          21360.109375,
          21285.109375,
          21648.33984375,
          21613.029296875,
          21826.869140625,
          22312.75,
          22395.740234375,
          22522.740234375,
          20173.5703125,
          20225.349609375,
          20226.7109375,
          20148.349609375,
          19701.880859375,
          19867.8203125,
          19803.30078125,
          19810.220703125,
          20113.619140625,
          19922.919921875,
          19416.1796875,
          18684.869140625,
          19537.01953125,
          19219.490234375,
          18875,
          19165.9296875,
          18461.359375,
          19229.810546875,
          19401.630859375,
          18862.720703125,
          19289.91015625,
          19051.630859375,
          18920.5,
          19117.939453125,
          18807.380859375,
          18876.619140625,
          19227.8203125,
          20229.259765625,
          19079.130859375,
          18955.4296875,
          19412.8203125,
          19463.0390625,
          19591.509765625,
          19436.2890625,
          19422.609375,
          19312.0390625,
          19310.94921875,
          19192.4296875,
          19056.80078125,
          19245.41015625,
          19629.080078125,
          19939,
          20337.8203125,
          20027.4296875,
          20158.259765625,
          20245.220703125,
          19960.669921875,
          19998.900390625,
          19530.08984375,
          19534.2109375,
          19417.9609375,
          19468.349609375,
          19439.01953125,
          19331.619140625,
          19131.869140625,
          19153.6796875,
          19060,
          19114.619140625,
          19155.529296875,
          18753.19921875,
          19375.130859375,
          19596.25,
          19176.9296875,
          19167.330078125,
          19069.390625,
          19144.689453125,
          19262.98046875,
          19457.580078125,
          19549.859375,
          19563.58984375,
          19327.439453125,
          19200.83984375,
          19123.970703125,
          19208.08984375,
          19041.919921875,
          18945.650390625,
          19164.369140625,
          19178.66015625,
          19204.349609375,
          19151.779296875,
          19570.400390625,
          19423.630859375,
          19329.720703125,
          19302.130859375,
          20080.0703125,
          20607.810546875,
          20771.58984375,
          20622.83984375,
          20295.109375,
          20173.740234375,
          20591.83984375,
          20698.890625,
          20809.669921875,
          20769.83984375,
          20627.48046875,
          20730.5390625,
          20490.740234375,
          20522.7890625,
          20483.619140625,
          20431.330078125,
          20151.83984375,
          20130.640625,
          20207.8203125,
          20558.4609375,
          21148.51953125,
          21404.630859375,
          21299.369140625,
          21255.080078125,
          20905.580078125,
          20733.4609375,
          20591.130859375,
          19699.0390625,
          18547.23046875,
          17818.080078125,
          15922.8095703125,
          16397.5703125,
          17601.150390625,
          17350.69921875,
          17070.310546875,
          16866.919921875,
          16812.080078125,
          16659.23046875,
          16329.849609375,
          16749.80078125,
          16619.4609375,
          16781.619140625,
          16900.5703125,
          16707.900390625,
          16662.759765625,
          16595.080078125,
          16692.560546875,
          16749.880859375,
          16700.44921875,
          16676.259765625,
          16700.6796875,
          16525.380859375,
          16280.23046875,
          16084.419921875,
          15781.2900390625,
          15747.8798828125,
          16226.9404296875,
          16585.76953125,
          16603.109375,
          16572.109375,
          16598.94921875,
          16531.640625,
          16522.140625,
          16580.310546875,
          16458.5703125,
          16550.91015625,
          16428.779296875,
          16213.2900390625,
          16212.91015625,
          16497.640625,
          16442.529296875,
          16879.3203125,
          17163.640625,
          17102.470703125,
          16977.369140625,
          16996.919921875,
          17092.740234375,
          16943.4296875,
          16885.19921875,
          16948.640625,
          17105.69921875,
          17310.509765625,
          16966.349609375,
          16983.900390625,
          17088.9609375,
          16793.2890625,
          16836.640625,
          16851.01953125,
          17224.099609375,
          17241.439453125,
          17128.560546875,
          17168.609375,
          17127.490234375,
          17167.4296875,
          17085.05078125,
          16988.619140625,
          17209.830078125,
          17444.630859375,
          17774.69921875,
          17824.9296875,
          17803.150390625,
          17720.330078125,
          17356.33984375,
          17027.08984375,
          16632.119140625,
          16708.220703125,
          16776.51953125,
          16711.349609375,
          16738.2109375,
          16734.4609375,
          16438.880859375,
          16814.25,
          16895.560546875,
          16878.470703125,
          16824.669921875,
          16834.80078125,
          16821.4296875,
          16844.01953125,
          16778.5,
          16824.41015625,
          16836.119140625,
          16821.509765625,
          16832.109375,
          16864.0390625,
          16919.390625,
          16832.400390625,
          16706.359375,
          16678.98046875,
          16547.310546875,
          16598.69921875,
          16633.470703125,
          16496.26953125,
          16607.48046875,
          16567.150390625,
          16542.400390625,
          16556.66015625,
          16616.75,
          16735.109375,
          16672.869140625,
          16721.029296875,
          16675.1796875,
          16835.349609375,
          16850.359375,
          16833.599609375,
          16831.849609375,
          16738.220703125,
          16950.650390625,
          16918.30078125,
          16943.5703125,
          16927.419921875,
          17127.830078125,
          17238.9296875,
          17178.259765625,
          17252.890625,
          17440.66015625,
          17437.75,
          17943.259765625,
          18200.80078125,
          18846.619140625,
          18920.94921875,
          19930.009765625,
          20721.73046875,
          20954.919921875,
          20722.23046875,
          20871.5,
          20817.560546875,
          21185.650390625,
          21219.75,
          21134.810546875,
          21204.669921875,
          20677.470703125,
          20743.720703125,
          21071.58984375,
          20963.509765625,
          22667.2109375,
          22905.650390625,
          22783.55078125,
          22783.609375,
          22707.880859375,
          22904.580078125,
          22916.44921875,
          22917.66015625,
          22632.890625,
          22598.470703125,
          23060.939453125,
          22992.939453125,
          23009.650390625,
          22967.470703125,
          23074.16015625,
          22981.509765625,
          23022.599609375,
          23432.169921875,
          23742.30078125,
          23077.470703125,
          22826.150390625,
          22865.4296875,
          23125.130859375,
          23077.51953125,
          23732.66015625,
          23820.490234375,
          23488.939453125,
          23534.130859375,
          23431.900390625,
          23363.759765625,
          23326.83984375,
          23356.330078125,
          22932.91015625,
          22878.23046875,
          22762.51953125,
          22977.240234375,
          23240.4609375,
          23159.0703125,
          22963,
          22685.7890625,
          21796.349609375,
          21733.51953125,
          21625.189453125,
          21697.439453125,
          21862.55078125,
          21814.009765625
         ],
         "yhoverformat": "$000,.0f"
        },
        {
         "mode": "markers",
         "name": "验证集预测值",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2022-02-26T08:00:00+08:00",
          "2022-02-26T20:00:00+08:00",
          "2022-02-27T08:00:00+08:00",
          "2022-02-27T20:00:00+08:00",
          "2022-02-28T08:00:00+08:00",
          "2022-02-28T20:00:00+08:00",
          "2022-03-01T08:00:00+08:00",
          "2022-03-01T20:00:00+08:00",
          "2022-03-02T08:00:00+08:00",
          "2022-03-02T20:00:00+08:00",
          "2022-03-03T08:00:00+08:00",
          "2022-03-03T20:00:00+08:00",
          "2022-03-04T08:00:00+08:00",
          "2022-03-04T20:00:00+08:00",
          "2022-03-05T08:00:00+08:00",
          "2022-03-05T20:00:00+08:00",
          "2022-03-06T08:00:00+08:00",
          "2022-03-06T20:00:00+08:00",
          "2022-03-07T08:00:00+08:00",
          "2022-03-07T20:00:00+08:00",
          "2022-03-08T08:00:00+08:00",
          "2022-03-08T20:00:00+08:00",
          "2022-03-09T08:00:00+08:00",
          "2022-03-09T20:00:00+08:00",
          "2022-03-10T08:00:00+08:00",
          "2022-03-10T20:00:00+08:00",
          "2022-03-11T08:00:00+08:00",
          "2022-03-11T20:00:00+08:00",
          "2022-03-12T08:00:00+08:00",
          "2022-03-12T20:00:00+08:00",
          "2022-03-13T08:00:00+08:00",
          "2022-03-13T20:00:00+08:00",
          "2022-03-14T08:00:00+08:00",
          "2022-03-14T20:00:00+08:00",
          "2022-03-15T08:00:00+08:00",
          "2022-03-15T20:00:00+08:00",
          "2022-03-16T08:00:00+08:00",
          "2022-03-16T20:00:00+08:00",
          "2022-03-17T08:00:00+08:00",
          "2022-03-17T20:00:00+08:00",
          "2022-03-18T08:00:00+08:00",
          "2022-03-18T20:00:00+08:00",
          "2022-03-19T08:00:00+08:00",
          "2022-03-19T20:00:00+08:00",
          "2022-03-20T08:00:00+08:00",
          "2022-03-20T20:00:00+08:00",
          "2022-03-21T08:00:00+08:00",
          "2022-03-21T20:00:00+08:00",
          "2022-03-22T08:00:00+08:00",
          "2022-03-22T20:00:00+08:00",
          "2022-03-23T08:00:00+08:00",
          "2022-03-23T20:00:00+08:00",
          "2022-03-24T08:00:00+08:00",
          "2022-03-24T20:00:00+08:00",
          "2022-03-25T08:00:00+08:00",
          "2022-03-25T20:00:00+08:00",
          "2022-03-26T08:00:00+08:00",
          "2022-03-26T20:00:00+08:00",
          "2022-03-27T08:00:00+08:00",
          "2022-03-27T20:00:00+08:00",
          "2022-03-28T08:00:00+08:00",
          "2022-03-28T20:00:00+08:00",
          "2022-03-29T08:00:00+08:00",
          "2022-03-29T20:00:00+08:00",
          "2022-03-30T08:00:00+08:00",
          "2022-03-30T20:00:00+08:00",
          "2022-03-31T08:00:00+08:00",
          "2022-03-31T20:00:00+08:00",
          "2022-04-01T08:00:00+08:00",
          "2022-04-01T20:00:00+08:00",
          "2022-04-02T08:00:00+08:00",
          "2022-04-02T20:00:00+08:00",
          "2022-04-03T08:00:00+08:00",
          "2022-04-03T20:00:00+08:00",
          "2022-04-04T08:00:00+08:00",
          "2022-04-04T20:00:00+08:00",
          "2022-04-05T08:00:00+08:00",
          "2022-04-05T20:00:00+08:00",
          "2022-04-06T08:00:00+08:00",
          "2022-04-06T20:00:00+08:00",
          "2022-04-07T08:00:00+08:00",
          "2022-04-07T20:00:00+08:00",
          "2022-04-08T08:00:00+08:00",
          "2022-04-08T20:00:00+08:00",
          "2022-04-09T08:00:00+08:00",
          "2022-04-09T20:00:00+08:00",
          "2022-04-10T08:00:00+08:00",
          "2022-04-10T20:00:00+08:00",
          "2022-04-11T08:00:00+08:00",
          "2022-04-11T20:00:00+08:00",
          "2022-04-12T08:00:00+08:00",
          "2022-04-12T20:00:00+08:00",
          "2022-04-13T08:00:00+08:00",
          "2022-04-13T20:00:00+08:00",
          "2022-04-14T08:00:00+08:00",
          "2022-04-14T20:00:00+08:00",
          "2022-04-15T08:00:00+08:00",
          "2022-04-15T20:00:00+08:00",
          "2022-04-16T08:00:00+08:00",
          "2022-04-16T20:00:00+08:00",
          "2022-04-17T08:00:00+08:00",
          "2022-04-17T20:00:00+08:00",
          "2022-04-18T08:00:00+08:00",
          "2022-04-18T20:00:00+08:00",
          "2022-04-19T08:00:00+08:00",
          "2022-04-19T20:00:00+08:00",
          "2022-04-20T08:00:00+08:00",
          "2022-04-20T20:00:00+08:00",
          "2022-04-21T08:00:00+08:00",
          "2022-04-21T20:00:00+08:00",
          "2022-04-22T08:00:00+08:00",
          "2022-04-22T20:00:00+08:00",
          "2022-04-23T08:00:00+08:00",
          "2022-04-23T20:00:00+08:00",
          "2022-04-24T08:00:00+08:00",
          "2022-04-24T20:00:00+08:00",
          "2022-04-25T08:00:00+08:00",
          "2022-04-25T20:00:00+08:00",
          "2022-04-26T08:00:00+08:00",
          "2022-04-26T20:00:00+08:00",
          "2022-04-27T08:00:00+08:00",
          "2022-04-27T20:00:00+08:00",
          "2022-04-28T08:00:00+08:00",
          "2022-04-28T20:00:00+08:00",
          "2022-04-29T08:00:00+08:00",
          "2022-04-29T20:00:00+08:00",
          "2022-04-30T08:00:00+08:00",
          "2022-04-30T20:00:00+08:00",
          "2022-05-01T08:00:00+08:00",
          "2022-05-01T20:00:00+08:00",
          "2022-05-02T08:00:00+08:00",
          "2022-05-02T20:00:00+08:00",
          "2022-05-03T08:00:00+08:00",
          "2022-05-03T20:00:00+08:00",
          "2022-05-04T08:00:00+08:00",
          "2022-05-04T20:00:00+08:00",
          "2022-05-05T08:00:00+08:00",
          "2022-05-05T20:00:00+08:00",
          "2022-05-06T08:00:00+08:00",
          "2022-05-06T20:00:00+08:00",
          "2022-05-07T08:00:00+08:00",
          "2022-05-07T20:00:00+08:00",
          "2022-05-08T08:00:00+08:00",
          "2022-05-08T20:00:00+08:00",
          "2022-05-09T08:00:00+08:00",
          "2022-05-09T20:00:00+08:00",
          "2022-05-10T08:00:00+08:00",
          "2022-05-10T20:00:00+08:00",
          "2022-05-11T08:00:00+08:00",
          "2022-05-11T20:00:00+08:00",
          "2022-05-12T08:00:00+08:00",
          "2022-05-12T20:00:00+08:00",
          "2022-05-13T08:00:00+08:00",
          "2022-05-13T20:00:00+08:00",
          "2022-05-14T08:00:00+08:00",
          "2022-05-14T20:00:00+08:00",
          "2022-05-15T08:00:00+08:00",
          "2022-05-15T20:00:00+08:00",
          "2022-05-16T08:00:00+08:00",
          "2022-05-16T20:00:00+08:00",
          "2022-05-17T08:00:00+08:00",
          "2022-05-17T20:00:00+08:00",
          "2022-05-18T08:00:00+08:00",
          "2022-05-18T20:00:00+08:00",
          "2022-05-19T08:00:00+08:00",
          "2022-05-19T20:00:00+08:00",
          "2022-05-20T08:00:00+08:00",
          "2022-05-20T20:00:00+08:00",
          "2022-05-21T08:00:00+08:00",
          "2022-05-21T20:00:00+08:00",
          "2022-05-22T08:00:00+08:00",
          "2022-05-22T20:00:00+08:00",
          "2022-05-23T08:00:00+08:00",
          "2022-05-23T20:00:00+08:00",
          "2022-05-24T08:00:00+08:00",
          "2022-05-24T20:00:00+08:00",
          "2022-05-25T08:00:00+08:00",
          "2022-05-25T20:00:00+08:00",
          "2022-05-26T08:00:00+08:00",
          "2022-05-26T20:00:00+08:00",
          "2022-05-27T08:00:00+08:00",
          "2022-05-27T20:00:00+08:00",
          "2022-05-28T08:00:00+08:00",
          "2022-05-28T20:00:00+08:00",
          "2022-05-29T08:00:00+08:00",
          "2022-05-29T20:00:00+08:00",
          "2022-05-30T08:00:00+08:00",
          "2022-05-30T20:00:00+08:00",
          "2022-05-31T08:00:00+08:00",
          "2022-05-31T20:00:00+08:00",
          "2022-06-01T08:00:00+08:00",
          "2022-06-01T20:00:00+08:00",
          "2022-06-02T08:00:00+08:00",
          "2022-06-02T20:00:00+08:00",
          "2022-06-03T08:00:00+08:00",
          "2022-06-03T20:00:00+08:00",
          "2022-06-04T08:00:00+08:00",
          "2022-06-04T20:00:00+08:00",
          "2022-06-05T08:00:00+08:00",
          "2022-06-05T20:00:00+08:00",
          "2022-06-06T08:00:00+08:00",
          "2022-06-06T20:00:00+08:00",
          "2022-06-07T08:00:00+08:00",
          "2022-06-07T20:00:00+08:00",
          "2022-06-08T08:00:00+08:00",
          "2022-06-08T20:00:00+08:00",
          "2022-06-09T08:00:00+08:00",
          "2022-06-09T20:00:00+08:00",
          "2022-06-10T08:00:00+08:00",
          "2022-06-10T20:00:00+08:00",
          "2022-06-11T08:00:00+08:00",
          "2022-06-11T20:00:00+08:00",
          "2022-06-12T08:00:00+08:00",
          "2022-06-12T20:00:00+08:00",
          "2022-06-13T08:00:00+08:00",
          "2022-06-13T20:00:00+08:00",
          "2022-06-14T08:00:00+08:00",
          "2022-06-14T20:00:00+08:00",
          "2022-06-15T08:00:00+08:00",
          "2022-06-15T20:00:00+08:00",
          "2022-06-16T08:00:00+08:00",
          "2022-06-16T20:00:00+08:00",
          "2022-06-17T08:00:00+08:00",
          "2022-06-17T20:00:00+08:00",
          "2022-06-18T08:00:00+08:00",
          "2022-06-18T20:00:00+08:00",
          "2022-06-19T08:00:00+08:00",
          "2022-06-19T20:00:00+08:00",
          "2022-06-20T08:00:00+08:00",
          "2022-06-20T20:00:00+08:00",
          "2022-06-21T08:00:00+08:00",
          "2022-06-21T20:00:00+08:00",
          "2022-06-22T08:00:00+08:00",
          "2022-06-22T20:00:00+08:00",
          "2022-06-23T08:00:00+08:00",
          "2022-06-23T20:00:00+08:00",
          "2022-06-24T08:00:00+08:00",
          "2022-06-24T20:00:00+08:00",
          "2022-06-25T08:00:00+08:00",
          "2022-06-25T20:00:00+08:00",
          "2022-06-26T08:00:00+08:00",
          "2022-06-26T20:00:00+08:00",
          "2022-06-27T08:00:00+08:00",
          "2022-06-27T20:00:00+08:00",
          "2022-06-28T08:00:00+08:00",
          "2022-06-28T20:00:00+08:00",
          "2022-06-29T08:00:00+08:00",
          "2022-06-29T20:00:00+08:00",
          "2022-06-30T08:00:00+08:00",
          "2022-06-30T20:00:00+08:00",
          "2022-07-01T08:00:00+08:00",
          "2022-07-01T20:00:00+08:00",
          "2022-07-02T08:00:00+08:00",
          "2022-07-02T20:00:00+08:00",
          "2022-07-03T08:00:00+08:00",
          "2022-07-03T20:00:00+08:00",
          "2022-07-04T08:00:00+08:00",
          "2022-07-04T20:00:00+08:00",
          "2022-07-05T08:00:00+08:00",
          "2022-07-05T20:00:00+08:00",
          "2022-07-06T08:00:00+08:00",
          "2022-07-06T20:00:00+08:00",
          "2022-07-07T08:00:00+08:00",
          "2022-07-07T20:00:00+08:00",
          "2022-07-08T08:00:00+08:00",
          "2022-07-08T20:00:00+08:00",
          "2022-07-09T08:00:00+08:00",
          "2022-07-09T20:00:00+08:00",
          "2022-07-10T08:00:00+08:00",
          "2022-07-10T20:00:00+08:00",
          "2022-07-11T08:00:00+08:00",
          "2022-07-11T20:00:00+08:00",
          "2022-07-12T08:00:00+08:00",
          "2022-07-12T20:00:00+08:00",
          "2022-07-13T08:00:00+08:00",
          "2022-07-13T20:00:00+08:00",
          "2022-07-14T08:00:00+08:00",
          "2022-07-14T20:00:00+08:00",
          "2022-07-15T08:00:00+08:00",
          "2022-07-15T20:00:00+08:00",
          "2022-07-16T08:00:00+08:00",
          "2022-07-16T20:00:00+08:00",
          "2022-07-17T08:00:00+08:00",
          "2022-07-17T20:00:00+08:00",
          "2022-07-18T08:00:00+08:00",
          "2022-07-18T20:00:00+08:00",
          "2022-07-19T08:00:00+08:00",
          "2022-07-19T20:00:00+08:00",
          "2022-07-20T08:00:00+08:00",
          "2022-07-20T20:00:00+08:00",
          "2022-07-21T08:00:00+08:00",
          "2022-07-21T20:00:00+08:00",
          "2022-07-22T08:00:00+08:00",
          "2022-07-22T20:00:00+08:00",
          "2022-07-23T08:00:00+08:00",
          "2022-07-23T20:00:00+08:00",
          "2022-07-24T08:00:00+08:00",
          "2022-07-24T20:00:00+08:00",
          "2022-07-25T08:00:00+08:00",
          "2022-07-25T20:00:00+08:00",
          "2022-07-26T08:00:00+08:00",
          "2022-07-26T20:00:00+08:00",
          "2022-07-27T08:00:00+08:00",
          "2022-07-27T20:00:00+08:00",
          "2022-07-28T08:00:00+08:00",
          "2022-07-28T20:00:00+08:00",
          "2022-07-29T08:00:00+08:00",
          "2022-07-29T20:00:00+08:00",
          "2022-07-30T08:00:00+08:00",
          "2022-07-30T20:00:00+08:00",
          "2022-07-31T08:00:00+08:00",
          "2022-07-31T20:00:00+08:00",
          "2022-08-01T08:00:00+08:00",
          "2022-08-01T20:00:00+08:00",
          "2022-08-02T08:00:00+08:00",
          "2022-08-02T20:00:00+08:00",
          "2022-08-03T08:00:00+08:00",
          "2022-08-03T20:00:00+08:00",
          "2022-08-04T08:00:00+08:00",
          "2022-08-04T20:00:00+08:00",
          "2022-08-05T08:00:00+08:00",
          "2022-08-05T20:00:00+08:00",
          "2022-08-06T08:00:00+08:00",
          "2022-08-06T20:00:00+08:00",
          "2022-08-07T08:00:00+08:00",
          "2022-08-07T20:00:00+08:00",
          "2022-08-08T08:00:00+08:00",
          "2022-08-08T20:00:00+08:00",
          "2022-08-09T08:00:00+08:00",
          "2022-08-09T20:00:00+08:00",
          "2022-08-10T08:00:00+08:00",
          "2022-08-10T20:00:00+08:00",
          "2022-08-11T08:00:00+08:00",
          "2022-08-11T20:00:00+08:00",
          "2022-08-12T08:00:00+08:00",
          "2022-08-12T20:00:00+08:00",
          "2022-08-13T08:00:00+08:00",
          "2022-08-13T20:00:00+08:00",
          "2022-08-14T08:00:00+08:00",
          "2022-08-14T20:00:00+08:00",
          "2022-08-15T08:00:00+08:00",
          "2022-08-15T20:00:00+08:00",
          "2022-08-16T08:00:00+08:00",
          "2022-08-16T20:00:00+08:00",
          "2022-08-17T08:00:00+08:00",
          "2022-08-17T20:00:00+08:00",
          "2022-08-18T08:00:00+08:00",
          "2022-08-18T20:00:00+08:00",
          "2022-08-19T08:00:00+08:00",
          "2022-08-19T20:00:00+08:00",
          "2022-08-20T08:00:00+08:00",
          "2022-08-20T20:00:00+08:00",
          "2022-08-21T08:00:00+08:00",
          "2022-08-21T20:00:00+08:00",
          "2022-08-22T08:00:00+08:00",
          "2022-08-22T20:00:00+08:00",
          "2022-08-23T08:00:00+08:00",
          "2022-08-23T20:00:00+08:00",
          "2022-08-24T08:00:00+08:00",
          "2022-08-24T20:00:00+08:00",
          "2022-08-25T08:00:00+08:00",
          "2022-08-25T20:00:00+08:00",
          "2022-08-26T08:00:00+08:00",
          "2022-08-26T20:00:00+08:00",
          "2022-08-27T08:00:00+08:00",
          "2022-08-27T20:00:00+08:00",
          "2022-08-28T08:00:00+08:00",
          "2022-08-28T20:00:00+08:00",
          "2022-08-29T08:00:00+08:00",
          "2022-08-29T20:00:00+08:00",
          "2022-08-30T08:00:00+08:00",
          "2022-08-30T20:00:00+08:00",
          "2022-08-31T08:00:00+08:00",
          "2022-08-31T20:00:00+08:00",
          "2022-09-01T08:00:00+08:00",
          "2022-09-01T20:00:00+08:00",
          "2022-09-02T08:00:00+08:00",
          "2022-09-02T20:00:00+08:00",
          "2022-09-03T08:00:00+08:00",
          "2022-09-03T20:00:00+08:00",
          "2022-09-04T08:00:00+08:00",
          "2022-09-04T20:00:00+08:00",
          "2022-09-05T08:00:00+08:00",
          "2022-09-05T20:00:00+08:00",
          "2022-09-06T08:00:00+08:00",
          "2022-09-06T20:00:00+08:00",
          "2022-09-07T08:00:00+08:00",
          "2022-09-07T20:00:00+08:00",
          "2022-09-08T08:00:00+08:00",
          "2022-09-08T20:00:00+08:00",
          "2022-09-09T08:00:00+08:00",
          "2022-09-09T20:00:00+08:00",
          "2022-09-10T08:00:00+08:00",
          "2022-09-10T20:00:00+08:00",
          "2022-09-11T08:00:00+08:00",
          "2022-09-11T20:00:00+08:00",
          "2022-09-12T08:00:00+08:00",
          "2022-09-12T20:00:00+08:00",
          "2022-09-13T08:00:00+08:00",
          "2022-09-13T20:00:00+08:00",
          "2022-09-14T08:00:00+08:00",
          "2022-09-14T20:00:00+08:00",
          "2022-09-15T08:00:00+08:00",
          "2022-09-15T20:00:00+08:00",
          "2022-09-16T08:00:00+08:00",
          "2022-09-16T20:00:00+08:00",
          "2022-09-17T08:00:00+08:00",
          "2022-09-17T20:00:00+08:00",
          "2022-09-18T08:00:00+08:00",
          "2022-09-18T20:00:00+08:00",
          "2022-09-19T08:00:00+08:00",
          "2022-09-19T20:00:00+08:00",
          "2022-09-20T08:00:00+08:00",
          "2022-09-20T20:00:00+08:00",
          "2022-09-21T08:00:00+08:00",
          "2022-09-21T20:00:00+08:00",
          "2022-09-22T08:00:00+08:00",
          "2022-09-22T20:00:00+08:00",
          "2022-09-23T08:00:00+08:00",
          "2022-09-23T20:00:00+08:00",
          "2022-09-24T08:00:00+08:00",
          "2022-09-24T20:00:00+08:00",
          "2022-09-25T08:00:00+08:00",
          "2022-09-25T20:00:00+08:00",
          "2022-09-26T08:00:00+08:00",
          "2022-09-26T20:00:00+08:00",
          "2022-09-27T08:00:00+08:00",
          "2022-09-27T20:00:00+08:00",
          "2022-09-28T08:00:00+08:00",
          "2022-09-28T20:00:00+08:00",
          "2022-09-29T08:00:00+08:00",
          "2022-09-29T20:00:00+08:00",
          "2022-09-30T08:00:00+08:00",
          "2022-09-30T20:00:00+08:00",
          "2022-10-01T08:00:00+08:00",
          "2022-10-01T20:00:00+08:00",
          "2022-10-02T08:00:00+08:00",
          "2022-10-02T20:00:00+08:00",
          "2022-10-03T08:00:00+08:00",
          "2022-10-03T20:00:00+08:00",
          "2022-10-04T08:00:00+08:00",
          "2022-10-04T20:00:00+08:00",
          "2022-10-05T08:00:00+08:00",
          "2022-10-05T20:00:00+08:00",
          "2022-10-06T08:00:00+08:00",
          "2022-10-06T20:00:00+08:00",
          "2022-10-07T08:00:00+08:00",
          "2022-10-07T20:00:00+08:00",
          "2022-10-08T08:00:00+08:00",
          "2022-10-08T20:00:00+08:00",
          "2022-10-09T08:00:00+08:00",
          "2022-10-09T20:00:00+08:00",
          "2022-10-10T08:00:00+08:00",
          "2022-10-10T20:00:00+08:00",
          "2022-10-11T08:00:00+08:00",
          "2022-10-11T20:00:00+08:00",
          "2022-10-12T08:00:00+08:00",
          "2022-10-12T20:00:00+08:00",
          "2022-10-13T08:00:00+08:00",
          "2022-10-13T20:00:00+08:00",
          "2022-10-14T08:00:00+08:00",
          "2022-10-14T20:00:00+08:00",
          "2022-10-15T08:00:00+08:00",
          "2022-10-15T20:00:00+08:00",
          "2022-10-16T08:00:00+08:00",
          "2022-10-16T20:00:00+08:00",
          "2022-10-17T08:00:00+08:00",
          "2022-10-17T20:00:00+08:00",
          "2022-10-18T08:00:00+08:00",
          "2022-10-18T20:00:00+08:00",
          "2022-10-19T08:00:00+08:00",
          "2022-10-19T20:00:00+08:00",
          "2022-10-20T08:00:00+08:00",
          "2022-10-20T20:00:00+08:00",
          "2022-10-21T08:00:00+08:00",
          "2022-10-21T20:00:00+08:00",
          "2022-10-22T08:00:00+08:00",
          "2022-10-22T20:00:00+08:00",
          "2022-10-23T08:00:00+08:00",
          "2022-10-23T20:00:00+08:00",
          "2022-10-24T08:00:00+08:00",
          "2022-10-24T20:00:00+08:00",
          "2022-10-25T08:00:00+08:00",
          "2022-10-25T20:00:00+08:00",
          "2022-10-26T08:00:00+08:00",
          "2022-10-26T20:00:00+08:00",
          "2022-10-27T08:00:00+08:00",
          "2022-10-27T20:00:00+08:00",
          "2022-10-28T08:00:00+08:00",
          "2022-10-28T20:00:00+08:00",
          "2022-10-29T08:00:00+08:00",
          "2022-10-29T20:00:00+08:00",
          "2022-10-30T08:00:00+08:00",
          "2022-10-30T20:00:00+08:00",
          "2022-10-31T08:00:00+08:00",
          "2022-10-31T20:00:00+08:00",
          "2022-11-01T08:00:00+08:00",
          "2022-11-01T20:00:00+08:00",
          "2022-11-02T08:00:00+08:00",
          "2022-11-02T20:00:00+08:00",
          "2022-11-03T08:00:00+08:00",
          "2022-11-03T20:00:00+08:00",
          "2022-11-04T08:00:00+08:00",
          "2022-11-04T20:00:00+08:00",
          "2022-11-05T08:00:00+08:00",
          "2022-11-05T20:00:00+08:00",
          "2022-11-06T08:00:00+08:00",
          "2022-11-06T20:00:00+08:00",
          "2022-11-07T08:00:00+08:00",
          "2022-11-07T20:00:00+08:00",
          "2022-11-08T08:00:00+08:00",
          "2022-11-08T20:00:00+08:00",
          "2022-11-09T08:00:00+08:00",
          "2022-11-09T20:00:00+08:00",
          "2022-11-10T08:00:00+08:00",
          "2022-11-10T20:00:00+08:00",
          "2022-11-11T08:00:00+08:00",
          "2022-11-11T20:00:00+08:00",
          "2022-11-12T08:00:00+08:00",
          "2022-11-12T20:00:00+08:00",
          "2022-11-13T08:00:00+08:00",
          "2022-11-13T20:00:00+08:00",
          "2022-11-14T08:00:00+08:00",
          "2022-11-14T20:00:00+08:00",
          "2022-11-15T08:00:00+08:00",
          "2022-11-15T20:00:00+08:00",
          "2022-11-16T08:00:00+08:00",
          "2022-11-16T20:00:00+08:00",
          "2022-11-17T08:00:00+08:00",
          "2022-11-17T20:00:00+08:00",
          "2022-11-18T08:00:00+08:00",
          "2022-11-18T20:00:00+08:00",
          "2022-11-19T08:00:00+08:00",
          "2022-11-19T20:00:00+08:00",
          "2022-11-20T08:00:00+08:00",
          "2022-11-20T20:00:00+08:00",
          "2022-11-21T08:00:00+08:00",
          "2022-11-21T20:00:00+08:00",
          "2022-11-22T08:00:00+08:00",
          "2022-11-22T20:00:00+08:00",
          "2022-11-23T08:00:00+08:00",
          "2022-11-23T20:00:00+08:00",
          "2022-11-24T08:00:00+08:00",
          "2022-11-24T20:00:00+08:00",
          "2022-11-25T08:00:00+08:00",
          "2022-11-25T20:00:00+08:00",
          "2022-11-26T08:00:00+08:00",
          "2022-11-26T20:00:00+08:00",
          "2022-11-27T08:00:00+08:00",
          "2022-11-27T20:00:00+08:00",
          "2022-11-28T08:00:00+08:00",
          "2022-11-28T20:00:00+08:00",
          "2022-11-29T08:00:00+08:00",
          "2022-11-29T20:00:00+08:00",
          "2022-11-30T08:00:00+08:00",
          "2022-11-30T20:00:00+08:00",
          "2022-12-01T08:00:00+08:00",
          "2022-12-01T20:00:00+08:00",
          "2022-12-02T08:00:00+08:00",
          "2022-12-02T20:00:00+08:00",
          "2022-12-03T08:00:00+08:00",
          "2022-12-03T20:00:00+08:00",
          "2022-12-04T08:00:00+08:00",
          "2022-12-04T20:00:00+08:00",
          "2022-12-05T08:00:00+08:00",
          "2022-12-05T20:00:00+08:00",
          "2022-12-06T08:00:00+08:00",
          "2022-12-06T20:00:00+08:00",
          "2022-12-07T08:00:00+08:00",
          "2022-12-07T20:00:00+08:00",
          "2022-12-08T08:00:00+08:00",
          "2022-12-08T20:00:00+08:00",
          "2022-12-09T08:00:00+08:00",
          "2022-12-09T20:00:00+08:00",
          "2022-12-10T08:00:00+08:00",
          "2022-12-10T20:00:00+08:00",
          "2022-12-11T08:00:00+08:00",
          "2022-12-11T20:00:00+08:00",
          "2022-12-12T08:00:00+08:00",
          "2022-12-12T20:00:00+08:00",
          "2022-12-13T08:00:00+08:00",
          "2022-12-13T20:00:00+08:00",
          "2022-12-14T08:00:00+08:00",
          "2022-12-14T20:00:00+08:00",
          "2022-12-15T08:00:00+08:00",
          "2022-12-15T20:00:00+08:00",
          "2022-12-16T08:00:00+08:00",
          "2022-12-16T20:00:00+08:00",
          "2022-12-17T08:00:00+08:00",
          "2022-12-17T20:00:00+08:00",
          "2022-12-18T08:00:00+08:00",
          "2022-12-18T20:00:00+08:00",
          "2022-12-19T08:00:00+08:00",
          "2022-12-19T20:00:00+08:00",
          "2022-12-20T08:00:00+08:00",
          "2022-12-20T20:00:00+08:00",
          "2022-12-21T08:00:00+08:00",
          "2022-12-21T20:00:00+08:00",
          "2022-12-22T08:00:00+08:00",
          "2022-12-22T20:00:00+08:00",
          "2022-12-23T08:00:00+08:00",
          "2022-12-23T20:00:00+08:00",
          "2022-12-24T08:00:00+08:00",
          "2022-12-24T20:00:00+08:00",
          "2022-12-25T08:00:00+08:00",
          "2022-12-25T20:00:00+08:00",
          "2022-12-26T08:00:00+08:00",
          "2022-12-26T20:00:00+08:00",
          "2022-12-27T08:00:00+08:00",
          "2022-12-27T20:00:00+08:00",
          "2022-12-28T08:00:00+08:00",
          "2022-12-28T20:00:00+08:00",
          "2022-12-29T08:00:00+08:00",
          "2022-12-29T20:00:00+08:00",
          "2022-12-30T08:00:00+08:00",
          "2022-12-30T20:00:00+08:00",
          "2022-12-31T08:00:00+08:00",
          "2022-12-31T20:00:00+08:00",
          "2023-01-01T08:00:00+08:00",
          "2023-01-01T20:00:00+08:00",
          "2023-01-02T08:00:00+08:00",
          "2023-01-02T20:00:00+08:00",
          "2023-01-03T08:00:00+08:00",
          "2023-01-03T20:00:00+08:00",
          "2023-01-04T08:00:00+08:00",
          "2023-01-04T20:00:00+08:00",
          "2023-01-05T08:00:00+08:00",
          "2023-01-05T20:00:00+08:00",
          "2023-01-06T08:00:00+08:00",
          "2023-01-06T20:00:00+08:00",
          "2023-01-07T08:00:00+08:00",
          "2023-01-07T20:00:00+08:00",
          "2023-01-08T08:00:00+08:00",
          "2023-01-08T20:00:00+08:00",
          "2023-01-09T08:00:00+08:00",
          "2023-01-09T20:00:00+08:00",
          "2023-01-10T08:00:00+08:00",
          "2023-01-10T20:00:00+08:00",
          "2023-01-11T08:00:00+08:00",
          "2023-01-11T20:00:00+08:00",
          "2023-01-12T08:00:00+08:00",
          "2023-01-12T20:00:00+08:00",
          "2023-01-13T08:00:00+08:00",
          "2023-01-13T20:00:00+08:00",
          "2023-01-14T08:00:00+08:00",
          "2023-01-14T20:00:00+08:00",
          "2023-01-15T08:00:00+08:00",
          "2023-01-15T20:00:00+08:00",
          "2023-01-16T08:00:00+08:00",
          "2023-01-16T20:00:00+08:00",
          "2023-01-17T08:00:00+08:00",
          "2023-01-17T20:00:00+08:00",
          "2023-01-18T08:00:00+08:00",
          "2023-01-18T20:00:00+08:00",
          "2023-01-19T08:00:00+08:00",
          "2023-01-19T20:00:00+08:00",
          "2023-01-20T08:00:00+08:00",
          "2023-01-20T20:00:00+08:00",
          "2023-01-21T08:00:00+08:00",
          "2023-01-21T20:00:00+08:00",
          "2023-01-22T08:00:00+08:00",
          "2023-01-22T20:00:00+08:00",
          "2023-01-23T08:00:00+08:00",
          "2023-01-23T20:00:00+08:00",
          "2023-01-24T08:00:00+08:00",
          "2023-01-24T20:00:00+08:00",
          "2023-01-25T08:00:00+08:00",
          "2023-01-25T20:00:00+08:00",
          "2023-01-26T08:00:00+08:00",
          "2023-01-26T20:00:00+08:00",
          "2023-01-27T08:00:00+08:00",
          "2023-01-27T20:00:00+08:00",
          "2023-01-28T08:00:00+08:00",
          "2023-01-28T20:00:00+08:00",
          "2023-01-29T08:00:00+08:00",
          "2023-01-29T20:00:00+08:00",
          "2023-01-30T08:00:00+08:00",
          "2023-01-30T20:00:00+08:00",
          "2023-01-31T08:00:00+08:00",
          "2023-01-31T20:00:00+08:00",
          "2023-02-01T08:00:00+08:00",
          "2023-02-01T20:00:00+08:00",
          "2023-02-02T08:00:00+08:00",
          "2023-02-02T20:00:00+08:00",
          "2023-02-03T08:00:00+08:00",
          "2023-02-03T20:00:00+08:00",
          "2023-02-04T08:00:00+08:00",
          "2023-02-04T20:00:00+08:00",
          "2023-02-05T08:00:00+08:00",
          "2023-02-05T20:00:00+08:00",
          "2023-02-06T08:00:00+08:00",
          "2023-02-06T20:00:00+08:00",
          "2023-02-07T08:00:00+08:00",
          "2023-02-07T20:00:00+08:00",
          "2023-02-08T08:00:00+08:00",
          "2023-02-08T20:00:00+08:00",
          "2023-02-09T08:00:00+08:00",
          "2023-02-09T20:00:00+08:00",
          "2023-02-10T08:00:00+08:00",
          "2023-02-10T20:00:00+08:00",
          "2023-02-11T08:00:00+08:00",
          "2023-02-11T20:00:00+08:00",
          "2023-02-12T08:00:00+08:00",
          "2023-02-12T20:00:00+08:00"
         ],
         "xhoverformat": "%y/%m/%d_%H:00",
         "y": [
          38730.08550079381,
          38453.089155197755,
          38774.791802737716,
          39064.814154565414,
          38013.52794343162,
          38247.66452658804,
          42870.165848975696,
          43404.2475244275,
          44027.07103576347,
          43921.48675500623,
          43400.62769020094,
          43373.685175387975,
          42153.654551475825,
          41357.94636968385,
          39602.34604474859,
          39096.27471593165,
          38192.56132058768,
          38206.09233031633,
          38234.91607953032,
          37991.36946938026,
          38007.3406868463,
          38998.47365700978,
          38974.183374303175,
          40213.97081441456,
          39916.53531965005,
          38975.46323049403,
          39089.72894541335,
          40092.47699600772,
          38367.82837395318,
          38800.16919220885,
          38737.541048604406,
          38399.034506076656,
          37514.12574476583,
          38597.85939432869,
          39336.27088164863,
          38240.23981868566,
          39070.403887929104,
          40219.097949155046,
          40719.53713973451,
          40413.01929200115,
          40670.27038636354,
          40142.35669255443,
          41159.229421110555,
          41902.65624850371,
          41939.90700263701,
          41127.98088411329,
          40981.49903007651,
          40913.22332828048,
          41166.804473565484,
          42784.723883270366,
          41601.04965615333,
          41836.30804097102,
          42810.09741775297,
          42714.71729162586,
          43921.23232576347,
          44076.754127895314,
          44102.64037585197,
          43857.389860773124,
          44282.31753609199,
          44252.66496434477,
          46580.087302408014,
          46665.243998962374,
          46769.83754766825,
          47617.14089590131,
          46999.197800040114,
          47051.49457439306,
          46721.68874097002,
          46488.67395947486,
          45289.96527710377,
          44706.971507225455,
          46005.73641680652,
          46273.23792566136,
          45400.23336892092,
          45804.69105516311,
          46190.922355651164,
          45915.22899617713,
          47137.48394846918,
          46212.78785057449,
          45085.82821466197,
          44494.42285981844,
          43134.6720317453,
          43317.61436726742,
          43035.21332775697,
          42744.48551302888,
          41965.592791190276,
          42332.472049274395,
          42329.22614893493,
          42385.466576550665,
          41761.87977748641,
          40635.513809806995,
          39477.54079119734,
          39650.03225282363,
          39755.33511941841,
          39727.65630179685,
          40745.473502542016,
          39687.35625173894,
          39782.177404529684,
          39837.99378340748,
          40153.31642493578,
          40437.386674478286,
          40181.21883189189,
          39923.28540456027,
          39230.57480622412,
          39112.3924229617,
          40276.99216684872,
          40701.80419251179,
          41362.572355915865,
          41833.08141557419,
          41565.11345310762,
          41785.93876088142,
          40433.71287041236,
          40017.25845987514,
          39792.99064734702,
          39336.75661020299,
          39195.73341991999,
          39481.99330294565,
          39598.07857244956,
          38466.974823870856,
          39589.13499906766,
          39907.221667369595,
          38359.09296995172,
          38997.999493421004,
          38418.028034547606,
          39348.75333449802,
          39226.17626431518,
          38036.1528710947,
          38539.548837874136,
          37581.28349988912,
          37524.80020799621,
          37252.75366766841,
          37988.07730917848,
          38516.912345245466,
          37892.52370856767,
          37921.200968217636,
          39167.49177397353,
          38698.67890926695,
          38752.151455120525,
          37859.7293211712,
          35963.961613405874,
          35546.971359463445,
          35119.59191144162,
          34791.162308922605,
          33930.54768530691,
          33255.64713396403,
          33933.30014711496,
          32351.87591379216,
          32064.02006551645,
          30503.370365363924,
          30859.563595252086,
          31050.227472793144,
          29160.907233338687,
          28833.994568804923,
          28774.66629537932,
          30173.817033689385,
          29106.23385855905,
          29477.519368529163,
          29801.827988313154,
          30251.90175379155,
          31086.125125953586,
          29951.842939334634,
          30259.376576544782,
          30125.396450300024,
          30560.343240799728,
          29540.27858174351,
          29305.430753203913,
          29425.81626240933,
          30190.144837594136,
          30011.389019611994,
          29260.33316992455,
          28959.987158822398,
          29157.156329502228,
          30201.357071723985,
          29870.41979916837,
          30132.18508509551,
          29158.449678152927,
          29120.78836774153,
          29507.74055108407,
          29102.641009252184,
          28837.830282388968,
          28999.269491909265,
          28885.986799064252,
          28380.108219673642,
          28426.32953210853,
          28849.861701580736,
          29144.49654718061,
          29056.75893580764,
          29549.584524046913,
          30169.861815461012,
          31234.62506648408,
          31642.372985433794,
          31452.44348320707,
          31360.469239443282,
          29558.34305797953,
          29850.795980073304,
          29868.154993408945,
          29142.91407439041,
          28684.831570247836,
          29166.290724816194,
          30921.314728966707,
          28493.81496125659,
          30153.645806223532,
          30809.624146383212,
          30552.766260850538,
          28907.721224377674,
          30784.271814337502,
          29639.002910417516,
          29760.807055400754,
          29678.37583573476,
          29302.46819452116,
          28555.753061914755,
          29556.39243378503,
          28417.17971684046,
          27925.624347320725,
          27201.048413823042,
          25845.03306963226,
          23962.360757892064,
          22642.39726640279,
          21626.07001872319,
          21351.693137831015,
          20943.85655414519,
          21191.51836454747,
          20156.71222936523,
          20203.029916513286,
          20428.50434045026,
          20685.990589112786,
          19122.330142920924,
          18608.095875898733,
          19337.937723723862,
          20530.563234199846,
          20603.786813769868,
          20150.285963491253,
          21039.99804050632,
          20707.863794013167,
          20171.270593536236,
          19753.00048340295,
          20471.22725079719,
          20671.017813675164,
          20599.733293334062,
          20674.654995350083,
          21064.955236228045,
          21320.066811958135,
          21578.647877362237,
          20249.744667479594,
          20949.093556058684,
          21060.926773217663,
          20632.485275856736,
          20212.470783415127,
          19479.20185078978,
          19938.440851490355,
          20075.54930092451,
          20093.895191322983,
          19271.74757072077,
          19207.500331935124,
          18768.654220540684,
          19040.93109643295,
          18799.537497375048,
          19010.592336727976,
          19494.918639013053,
          19908.61287776517,
          19495.853473730775,
          20264.37434893834,
          20004.046973731656,
          20825.718503250824,
          20382.439155050703,
          21448.549724563847,
          21459.879535843756,
          21455.75469812021,
          21043.79134921657,
          21494.91752656275,
          21574.422809936994,
          20716.098049506156,
          20267.39087746047,
          20123.738585002273,
          19729.3115789065,
          20364.312998998255,
          19483.937704194806,
          19798.597287696517,
          21196.36023013698,
          20287.265270809767,
          20399.24883252129,
          20101.77864286004,
          20365.93787666225,
          21099.946967084717,
          21532.03142860336,
          21015.94291209984,
          21830.220573624832,
          22148.873925240187,
          22122.38629907337,
          22834.24077043301,
          23444.84589563367,
          23361.13674727108,
          22673.591833560684,
          23046.56582850548,
          23232.58058988336,
          22514.92050580254,
          22445.98945595698,
          22747.700132997576,
          22627.493880758644,
          21876.42261111709,
          21795.17101794026,
          21142.48098299384,
          20815.43724885017,
          21429.93398496851,
          21201.471944923356,
          22633.073976651012,
          23092.409352064755,
          23140.095560139787,
          23192.777833345393,
          23728.482458966926,
          23758.01167108129,
          23799.2214984315,
          23137.638004954028,
          23891.047325137013,
          23568.120718739836,
          23184.51273794419,
          22617.199133898146,
          22938.01127908844,
          22507.588317624795,
          22686.96864374826,
          22997.555431871537,
          23115.58747058142,
          23309.828777475235,
          23191.82372368504,
          22832.05884692691,
          22944.0597560868,
          22848.074396761,
          23451.630675440625,
          24166.72140966841,
          23455.30447950655,
          23403.826890215532,
          23422.051348475412,
          23578.793254475946,
          23424.510831155432,
          24407.417255802982,
          24113.202603952515,
          24012.974829753104,
          24155.804082160856,
          24203.65412724827,
          24439.147666366083,
          24926.173424366967,
          24240.128101193448,
          23956.83077685054,
          24000.216745224057,
          23754.954665179634,
          23729.66208545609,
          23655.946994848917,
          23005.03603710756,
          23169.620917265627,
          22873.91245736107,
          22189.684761277884,
          20966.585566498492,
          21648.7932485937,
          20677.933663092026,
          21524.89198985195,
          21072.95626491517,
          21883.556267385713,
          21714.915939297578,
          22281.32169354559,
          21296.859781027524,
          20672.180092715957,
          20921.55159052982,
          21539.326994390103,
          21663.459552443455,
          20636.197629807928,
          20712.738427005155,
          20921.006109653295,
          20290.684645632933,
          21701.408059500092,
          21365.524836664743,
          20905.989001847614,
          21322.940705904773,
          20284.296929644224,
          20158.285064684114,
          20222.93707726506,
          19729.394461159827,
          19966.372170860413,
          19778.437625196246,
          19849.230634500196,
          19436.25920609683,
          19825.655452165283,
          19347.39593807407,
          18653.168401752675,
          19460.06568774334,
          18219.40894771919,
          18718.165435806757,
          18996.11974605169,
          18445.15707584156,
          18814.0698403735,
          19353.232390703462,
          19052.552923093754,
          19968.976215610186,
          20482.932923458455,
          20534.181140932134,
          21166.723078343864,
          21483.383400890925,
          21065.134493194535,
          21823.57071841631,
          21948.71135596939,
          22310.73332850989,
          22021.614971491697,
          21172.86022007834,
          19828.531273606186,
          19745.593122948936,
          20115.2248428411,
          19874.133860382546,
          19705.25452300576,
          19589.489217549562,
          19813.186491775738,
          19909.00608659489,
          19455.4358465228,
          20218.469145562638,
          18927.081720274513,
          19349.034308197908,
          18688.112908999894,
          18459.479321965304,
          19001.506128770594,
          18373.773289545898,
          19191.585011802727,
          19132.58441240189,
          20082.268545926516,
          19085.526567456713,
          19501.146372977906,
          19843.027957960767,
          19089.851864583645,
          19332.006823875563,
          19614.244026373635,
          19430.750427492203,
          19253.677312001957,
          19512.55906651114,
          19226.84273686774,
          19160.67571379581,
          19623.57888109099,
          19082.269102151666,
          19200.90251907171,
          19194.059914436853,
          19047.071129408818,
          19547.67030201214,
          19371.046292685252,
          19755.342388932906,
          20010.833681032876,
          20233.050639664805,
          20280.584575693032,
          20219.02811889901,
          19740.271311287852,
          19894.118120904855,
          19623.60586601068,
          18055.45821317376,
          18690.668766393082,
          18993.410652864564,
          18428.477504233746,
          19615.633749737506,
          19416.589127139447,
          18847.561980693292,
          19292.013245405524,
          19173.331641128898,
          18927.007511745374,
          18415.582567612004,
          18306.95862840148,
          18432.70449915325,
          17807.545828517246,
          18067.908862367804,
          19406.67602414309,
          18593.298502439073,
          18004.09049105575,
          18928.75382154796,
          18872.844922945522,
          17580.280762409628,
          16975.275008043973,
          16737.697847627485,
          16712.85051907877,
          17372.571089350724,
          17383.836329572812,
          18251.70411410145,
          18845.43017203804,
          17915.964489588718,
          17842.62140537437,
          18359.79799238955,
          17868.724496435654,
          18801.06696407301,
          19008.433543153038,
          18807.8315051902,
          18785.639299989234,
          19020.11126714748,
          19038.152613452345,
          19392.771080527356,
          19726.836676272374,
          20110.86870580595,
          19978.68500421463,
          19930.54776248198,
          20150.922036598156,
          20032.198027447736,
          20334.899436539687,
          19936.189538190774,
          20278.768876096965,
          20642.134312139013,
          20320.240842666986,
          20114.546364860405,
          20041.442289934712,
          20441.960177902638,
          20376.92073897476,
          21200.11691645623,
          21191.16756059154,
          21372.912922176125,
          20801.175718795716,
          20870.226273285603,
          20518.352558041588,
          21151.438048835582,
          20900.327951196185,
          20995.939376634895,
          21467.213651515765,
          22103.951743938786,
          21960.844932357115,
          22305.401879377492,
          21687.61491055163,
          20158.3698744317,
          18489.154059896555,
          17834.494125813,
          17284.660967241187,
          17511.419102357544,
          17630.651969993487,
          17590.373122372475,
          17430.024874605228,
          17332.21225071778,
          17100.413718102787,
          17265.32434479136,
          17583.235611115328,
          17621.016426171052,
          16765.045136235753,
          16663.851687410406,
          16590.701352622393,
          16723.802541483066,
          16985.114866258322,
          16593.0355481753,
          16471.640031975887,
          16696.597887450287,
          16125.169083152014,
          16378.3512371245,
          16739.993493295122,
          16229.506275120866,
          15997.765567333772,
          16837.669265089873,
          16721.832642345933,
          16644.48037006384,
          17162.46746841675,
          18282.52860236078,
          17758.06705077731,
          17400.11401862672,
          17120.62735044243,
          17003.198617436978,
          16702.71575424213,
          16396.28271625635,
          16629.91429591578,
          16627.062568153167,
          16596.62550624077,
          16574.827473616657,
          17539.494983797355,
          17178.245936456453,
          17155.380072010452,
          17257.932404291452,
          16815.10794473748,
          16923.50347587779,
          16961.345007002812,
          17433.371968393516,
          17637.945608285965,
          17408.515002373486,
          17604.15856134388,
          17498.76413877159,
          17006.78472051392,
          16770.690766933072,
          16930.02226147641,
          17194.215226428223,
          17022.43019144945,
          17058.64491741621,
          16911.331349604803,
          17116.860062904736,
          17415.543610204753,
          17639.943456089917,
          17165.031035786993,
          17710.486854886763,
          17457.498414087742,
          16902.595945603345,
          17249.42444461307,
          17534.456513792982,
          17789.745418995302,
          18438.688405093788,
          18221.045390348765,
          18422.12062815325,
          18079.895949191516,
          18140.624547199433,
          16727.99966024149,
          16685.145680284655,
          16904.46368754452,
          17149.014522205773,
          17066.629562402097,
          17423.38369312089,
          17665.203268410987,
          17067.797623925682,
          16795.264391296394,
          16797.659302918593,
          17257.476551898173,
          16734.459657265073,
          16846.258179527314,
          17130.894148636115,
          17260.86315931886,
          16743.388774439994,
          16812.063467548534,
          16978.032288587678,
          17457.12255270639,
          16652.94688861556,
          17189.390708287083,
          16618.36667778411,
          16574.21742168231,
          16721.583031838833,
          16423.74565452042,
          16378.67505616074,
          16311.465258692342,
          16622.770038428713,
          16629.078727152624,
          16124.6361309882,
          16041.060943476914,
          16311.36599273778,
          15658.79835367708,
          16085.31813925746,
          16489.97628490304,
          16305.81480925936,
          16502.475121453666,
          15974.482400379758,
          16631.435088889557,
          16828.50981235048,
          16629.176065612923,
          16323.902415426543,
          16685.275786147427,
          17008.32671592459,
          16834.110146932613,
          16878.098457263426,
          17346.322472472562,
          17156.95387107647,
          17393.190459232803,
          17119.048732640756,
          17428.685266092205,
          17563.930792320847,
          18212.72728885532,
          18852.496366007443,
          19520.2112187366,
          19229.032370350895,
          20294.558909102245,
          20586.250470962,
          20757.755055525457,
          21134.699688652738,
          20804.373431778597,
          21046.794385278856,
          20889.50507090753,
          21089.62909029306,
          21582.08267213951,
          22017.320514272975,
          21666.289114022038,
          21816.50066945838,
          21151.129649753446,
          21661.923339515575,
          22055.61018781422,
          22335.38598013801,
          22742.53252087756,
          22816.60419792345,
          22961.688618619308,
          22736.331771832396,
          22950.60359911084,
          22893.49772657087,
          23585.01520595801,
          23868.742361521643,
          23113.993432825635,
          23364.0010037464,
          23729.072272211506,
          23739.129937277616,
          22973.63137307496,
          23397.151977581587,
          22463.523871270583,
          22249.5642980628,
          22312.79189238314,
          22788.709500944395,
          22952.822145007944,
          22846.366636843682,
          22788.520606506587,
          21877.15505893716,
          22542.761232942223,
          22292.447190433588,
          22942.74905998773,
          23532.242340522025,
          23836.537787369758,
          23528.790198296385,
          23867.27361089298,
          23642.113368520928,
          22849.126808628786,
          23331.68848991577,
          23079.585732730757,
          22752.28564185006,
          22403.07572367798,
          23068.4371059116,
          23266.568096228835,
          23075.580399651535,
          23764.53816665696,
          23877.84206193887,
          23121.481748038714,
          22225.661441703123,
          22122.492311257854
         ],
         "yhoverformat": "$000,.0f"
        },
        {
         "mode": "markers+lines",
         "name": "最后第31时序预测值",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2023-02-12T20:00:00+08:00",
          "2023-02-13T08:00:00+08:00",
          "2023-02-13T20:00:00+08:00",
          "2023-02-14T08:00:00+08:00",
          "2023-02-14T20:00:00+08:00",
          "2023-02-15T08:00:00+08:00",
          "2023-02-15T20:00:00+08:00"
         ],
         "xhoverformat": "%y/%m/%d_%H:00",
         "y": [
          22122.492311257854,
          22939.701691557388,
          22164.95886486776,
          20690.308176262668,
          21516.756036566392,
          21590.94914575087,
          21630.576500310875
         ],
         "yhoverformat": "$000,.0f"
        },
        {
         "mode": "markers+lines",
         "name": "最后第15时序预测值",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2023-02-04T20:00:00+08:00",
          "2023-02-05T08:00:00+08:00",
          "2023-02-05T20:00:00+08:00",
          "2023-02-06T08:00:00+08:00",
          "2023-02-06T20:00:00+08:00",
          "2023-02-07T08:00:00+08:00",
          "2023-02-07T20:00:00+08:00"
         ],
         "xhoverformat": "%y/%m/%d_%H:00",
         "y": [
          23836.537787369758,
          21824.06608444199,
          24704.792998245328,
          23347.33781583983,
          25138.37897779511,
          24568.67720835679,
          24511.26679172321
         ],
         "yhoverformat": "$000,.0f"
        }
       ],
       "layout": {
        "autosize": true,
        "margin": {
         "b": 10,
         "l": 50,
         "pad": 0,
         "r": 15,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "rgb(0,125,125)",
          "family": "SimHei",
          "size": 20
         },
         "text": "DLinear+3.5日预测,始于:2023年02月12日08时,止于:2023年02月15日20时"
        },
        "xaxis": {
         "autorange": false,
         "range": [
          "2023-02-06 14:51:44.2523",
          "2023-02-17 22:47:08.499"
         ],
         "tickangle": -30,
         "tickformat": "%y/%m/%d_%H:",
         "title": {
          "text": "交易日期"
         },
         "type": "date"
        },
        "yaxis": {
         "autorange": false,
         "range": [
          18072.96576740087,
          27981.62282151708
         ],
         "tickformat": "$000,.0f",
         "title": {
          "text": "收盘价"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"1ec8f4af-2bd1-47c8-9b38-cda3622374ce\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1ec8f4af-2bd1-47c8-9b38-cda3622374ce\")) {                    Plotly.newPlot(                        \"1ec8f4af-2bd1-47c8-9b38-cda3622374ce\",                        [{\"mode\":\"markers\",\"name\":\"\\u771f\\u5b9e\\u503c\",\"showlegend\":true,\"x\":[\"2022-02-25T20:00:00+08:00\",\"2022-02-26T08:00:00+08:00\",\"2022-02-26T20:00:00+08:00\",\"2022-02-27T08:00:00+08:00\",\"2022-02-27T20:00:00+08:00\",\"2022-02-28T08:00:00+08:00\",\"2022-02-28T20:00:00+08:00\",\"2022-03-01T08:00:00+08:00\",\"2022-03-01T20:00:00+08:00\",\"2022-03-02T08:00:00+08:00\",\"2022-03-02T20:00:00+08:00\",\"2022-03-03T08:00:00+08:00\",\"2022-03-03T20:00:00+08:00\",\"2022-03-04T08:00:00+08:00\",\"2022-03-04T20:00:00+08:00\",\"2022-03-05T08:00:00+08:00\",\"2022-03-05T20:00:00+08:00\",\"2022-03-06T08:00:00+08:00\",\"2022-03-06T20:00:00+08:00\",\"2022-03-07T08:00:00+08:00\",\"2022-03-07T20:00:00+08:00\",\"2022-03-08T08:00:00+08:00\",\"2022-03-08T20:00:00+08:00\",\"2022-03-09T08:00:00+08:00\",\"2022-03-09T20:00:00+08:00\",\"2022-03-10T08:00:00+08:00\",\"2022-03-10T20:00:00+08:00\",\"2022-03-11T08:00:00+08:00\",\"2022-03-11T20:00:00+08:00\",\"2022-03-12T08:00:00+08:00\",\"2022-03-12T20:00:00+08:00\",\"2022-03-13T08:00:00+08:00\",\"2022-03-13T20:00:00+08:00\",\"2022-03-14T08:00:00+08:00\",\"2022-03-14T20:00:00+08:00\",\"2022-03-15T08:00:00+08:00\",\"2022-03-15T20:00:00+08:00\",\"2022-03-16T08:00:00+08:00\",\"2022-03-16T20:00:00+08:00\",\"2022-03-17T08:00:00+08:00\",\"2022-03-17T20:00:00+08:00\",\"2022-03-18T08:00:00+08:00\",\"2022-03-18T20:00:00+08:00\",\"2022-03-19T08:00:00+08:00\",\"2022-03-19T20:00:00+08:00\",\"2022-03-20T08:00:00+08:00\",\"2022-03-20T20:00:00+08:00\",\"2022-03-21T08:00:00+08:00\",\"2022-03-21T20:00:00+08:00\",\"2022-03-22T08:00:00+08:00\",\"2022-03-22T20:00:00+08:00\",\"2022-03-23T08:00:00+08:00\",\"2022-03-23T20:00:00+08:00\",\"2022-03-24T08:00:00+08:00\",\"2022-03-24T20:00:00+08:00\",\"2022-03-25T08:00:00+08:00\",\"2022-03-25T20:00:00+08:00\",\"2022-03-26T08:00:00+08:00\",\"2022-03-26T20:00:00+08:00\",\"2022-03-27T08:00:00+08:00\",\"2022-03-27T20:00:00+08:00\",\"2022-03-28T08:00:00+08:00\",\"2022-03-28T20:00:00+08:00\",\"2022-03-29T08:00:00+08:00\",\"2022-03-29T20:00:00+08:00\",\"2022-03-30T08:00:00+08:00\",\"2022-03-30T20:00:00+08:00\",\"2022-03-31T08:00:00+08:00\",\"2022-03-31T20:00:00+08:00\",\"2022-04-01T08:00:00+08:00\",\"2022-04-01T20:00:00+08:00\",\"2022-04-02T08:00:00+08:00\",\"2022-04-02T20:00:00+08:00\",\"2022-04-03T08:00:00+08:00\",\"2022-04-03T20:00:00+08:00\",\"2022-04-04T08:00:00+08:00\",\"2022-04-04T20:00:00+08:00\",\"2022-04-05T08:00:00+08:00\",\"2022-04-05T20:00:00+08:00\",\"2022-04-06T08:00:00+08:00\",\"2022-04-06T20:00:00+08:00\",\"2022-04-07T08:00:00+08:00\",\"2022-04-07T20:00:00+08:00\",\"2022-04-08T08:00:00+08:00\",\"2022-04-08T20:00:00+08:00\",\"2022-04-09T08:00:00+08:00\",\"2022-04-09T20:00:00+08:00\",\"2022-04-10T08:00:00+08:00\",\"2022-04-10T20:00:00+08:00\",\"2022-04-11T08:00:00+08:00\",\"2022-04-11T20:00:00+08:00\",\"2022-04-12T08:00:00+08:00\",\"2022-04-12T20:00:00+08:00\",\"2022-04-13T08:00:00+08:00\",\"2022-04-13T20:00:00+08:00\",\"2022-04-14T08:00:00+08:00\",\"2022-04-14T20:00:00+08:00\",\"2022-04-15T08:00:00+08:00\",\"2022-04-15T20:00:00+08:00\",\"2022-04-16T08:00:00+08:00\",\"2022-04-16T20:00:00+08:00\",\"2022-04-17T08:00:00+08:00\",\"2022-04-17T20:00:00+08:00\",\"2022-04-18T08:00:00+08:00\",\"2022-04-18T20:00:00+08:00\",\"2022-04-19T08:00:00+08:00\",\"2022-04-19T20:00:00+08:00\",\"2022-04-20T08:00:00+08:00\",\"2022-04-20T20:00:00+08:00\",\"2022-04-21T08:00:00+08:00\",\"2022-04-21T20:00:00+08:00\",\"2022-04-22T08:00:00+08:00\",\"2022-04-22T20:00:00+08:00\",\"2022-04-23T08:00:00+08:00\",\"2022-04-23T20:00:00+08:00\",\"2022-04-24T08:00:00+08:00\",\"2022-04-24T20:00:00+08:00\",\"2022-04-25T08:00:00+08:00\",\"2022-04-25T20:00:00+08:00\",\"2022-04-26T08:00:00+08:00\",\"2022-04-26T20:00:00+08:00\",\"2022-04-27T08:00:00+08:00\",\"2022-04-27T20:00:00+08:00\",\"2022-04-28T08:00:00+08:00\",\"2022-04-28T20:00:00+08:00\",\"2022-04-29T08:00:00+08:00\",\"2022-04-29T20:00:00+08:00\",\"2022-04-30T08:00:00+08:00\",\"2022-04-30T20:00:00+08:00\",\"2022-05-01T08:00:00+08:00\",\"2022-05-01T20:00:00+08:00\",\"2022-05-02T08:00:00+08:00\",\"2022-05-02T20:00:00+08:00\",\"2022-05-03T08:00:00+08:00\",\"2022-05-03T20:00:00+08:00\",\"2022-05-04T08:00:00+08:00\",\"2022-05-04T20:00:00+08:00\",\"2022-05-05T08:00:00+08:00\",\"2022-05-05T20:00:00+08:00\",\"2022-05-06T08:00:00+08:00\",\"2022-05-06T20:00:00+08:00\",\"2022-05-07T08:00:00+08:00\",\"2022-05-07T20:00:00+08:00\",\"2022-05-08T08:00:00+08:00\",\"2022-05-08T20:00:00+08:00\",\"2022-05-09T08:00:00+08:00\",\"2022-05-09T20:00:00+08:00\",\"2022-05-10T08:00:00+08:00\",\"2022-05-10T20:00:00+08:00\",\"2022-05-11T08:00:00+08:00\",\"2022-05-11T20:00:00+08:00\",\"2022-05-12T08:00:00+08:00\",\"2022-05-12T20:00:00+08:00\",\"2022-05-13T08:00:00+08:00\",\"2022-05-13T20:00:00+08:00\",\"2022-05-14T08:00:00+08:00\",\"2022-05-14T20:00:00+08:00\",\"2022-05-15T08:00:00+08:00\",\"2022-05-15T20:00:00+08:00\",\"2022-05-16T08:00:00+08:00\",\"2022-05-16T20:00:00+08:00\",\"2022-05-17T08:00:00+08:00\",\"2022-05-17T20:00:00+08:00\",\"2022-05-18T08:00:00+08:00\",\"2022-05-18T20:00:00+08:00\",\"2022-05-19T08:00:00+08:00\",\"2022-05-19T20:00:00+08:00\",\"2022-05-20T08:00:00+08:00\",\"2022-05-20T20:00:00+08:00\",\"2022-05-21T08:00:00+08:00\",\"2022-05-21T20:00:00+08:00\",\"2022-05-22T08:00:00+08:00\",\"2022-05-22T20:00:00+08:00\",\"2022-05-23T08:00:00+08:00\",\"2022-05-23T20:00:00+08:00\",\"2022-05-24T08:00:00+08:00\",\"2022-05-24T20:00:00+08:00\",\"2022-05-25T08:00:00+08:00\",\"2022-05-25T20:00:00+08:00\",\"2022-05-26T08:00:00+08:00\",\"2022-05-26T20:00:00+08:00\",\"2022-05-27T08:00:00+08:00\",\"2022-05-27T20:00:00+08:00\",\"2022-05-28T08:00:00+08:00\",\"2022-05-28T20:00:00+08:00\",\"2022-05-29T08:00:00+08:00\",\"2022-05-29T20:00:00+08:00\",\"2022-05-30T08:00:00+08:00\",\"2022-05-30T20:00:00+08:00\",\"2022-05-31T08:00:00+08:00\",\"2022-05-31T20:00:00+08:00\",\"2022-06-01T08:00:00+08:00\",\"2022-06-01T20:00:00+08:00\",\"2022-06-02T08:00:00+08:00\",\"2022-06-02T20:00:00+08:00\",\"2022-06-03T08:00:00+08:00\",\"2022-06-03T20:00:00+08:00\",\"2022-06-04T08:00:00+08:00\",\"2022-06-04T20:00:00+08:00\",\"2022-06-05T08:00:00+08:00\",\"2022-06-05T20:00:00+08:00\",\"2022-06-06T08:00:00+08:00\",\"2022-06-06T20:00:00+08:00\",\"2022-06-07T08:00:00+08:00\",\"2022-06-07T20:00:00+08:00\",\"2022-06-08T08:00:00+08:00\",\"2022-06-08T20:00:00+08:00\",\"2022-06-09T08:00:00+08:00\",\"2022-06-09T20:00:00+08:00\",\"2022-06-10T08:00:00+08:00\",\"2022-06-10T20:00:00+08:00\",\"2022-06-11T08:00:00+08:00\",\"2022-06-11T20:00:00+08:00\",\"2022-06-12T08:00:00+08:00\",\"2022-06-12T20:00:00+08:00\",\"2022-06-13T08:00:00+08:00\",\"2022-06-13T20:00:00+08:00\",\"2022-06-14T08:00:00+08:00\",\"2022-06-14T20:00:00+08:00\",\"2022-06-15T08:00:00+08:00\",\"2022-06-15T20:00:00+08:00\",\"2022-06-16T08:00:00+08:00\",\"2022-06-16T20:00:00+08:00\",\"2022-06-17T08:00:00+08:00\",\"2022-06-17T20:00:00+08:00\",\"2022-06-18T08:00:00+08:00\",\"2022-06-18T20:00:00+08:00\",\"2022-06-19T08:00:00+08:00\",\"2022-06-19T20:00:00+08:00\",\"2022-06-20T08:00:00+08:00\",\"2022-06-20T20:00:00+08:00\",\"2022-06-21T08:00:00+08:00\",\"2022-06-21T20:00:00+08:00\",\"2022-06-22T08:00:00+08:00\",\"2022-06-22T20:00:00+08:00\",\"2022-06-23T08:00:00+08:00\",\"2022-06-23T20:00:00+08:00\",\"2022-06-24T08:00:00+08:00\",\"2022-06-24T20:00:00+08:00\",\"2022-06-25T08:00:00+08:00\",\"2022-06-25T20:00:00+08:00\",\"2022-06-26T08:00:00+08:00\",\"2022-06-26T20:00:00+08:00\",\"2022-06-27T08:00:00+08:00\",\"2022-06-27T20:00:00+08:00\",\"2022-06-28T08:00:00+08:00\",\"2022-06-28T20:00:00+08:00\",\"2022-06-29T08:00:00+08:00\",\"2022-06-29T20:00:00+08:00\",\"2022-06-30T08:00:00+08:00\",\"2022-06-30T20:00:00+08:00\",\"2022-07-01T08:00:00+08:00\",\"2022-07-01T20:00:00+08:00\",\"2022-07-02T08:00:00+08:00\",\"2022-07-02T20:00:00+08:00\",\"2022-07-03T08:00:00+08:00\",\"2022-07-03T20:00:00+08:00\",\"2022-07-04T08:00:00+08:00\",\"2022-07-04T20:00:00+08:00\",\"2022-07-05T08:00:00+08:00\",\"2022-07-05T20:00:00+08:00\",\"2022-07-06T08:00:00+08:00\",\"2022-07-06T20:00:00+08:00\",\"2022-07-07T08:00:00+08:00\",\"2022-07-07T20:00:00+08:00\",\"2022-07-08T08:00:00+08:00\",\"2022-07-08T20:00:00+08:00\",\"2022-07-09T08:00:00+08:00\",\"2022-07-09T20:00:00+08:00\",\"2022-07-10T08:00:00+08:00\",\"2022-07-10T20:00:00+08:00\",\"2022-07-11T08:00:00+08:00\",\"2022-07-11T20:00:00+08:00\",\"2022-07-12T08:00:00+08:00\",\"2022-07-12T20:00:00+08:00\",\"2022-07-13T08:00:00+08:00\",\"2022-07-13T20:00:00+08:00\",\"2022-07-14T08:00:00+08:00\",\"2022-07-14T20:00:00+08:00\",\"2022-07-15T08:00:00+08:00\",\"2022-07-15T20:00:00+08:00\",\"2022-07-16T08:00:00+08:00\",\"2022-07-16T20:00:00+08:00\",\"2022-07-17T08:00:00+08:00\",\"2022-07-17T20:00:00+08:00\",\"2022-07-18T08:00:00+08:00\",\"2022-07-18T20:00:00+08:00\",\"2022-07-19T08:00:00+08:00\",\"2022-07-19T20:00:00+08:00\",\"2022-07-20T08:00:00+08:00\",\"2022-07-20T20:00:00+08:00\",\"2022-07-21T08:00:00+08:00\",\"2022-07-21T20:00:00+08:00\",\"2022-07-22T08:00:00+08:00\",\"2022-07-22T20:00:00+08:00\",\"2022-07-23T08:00:00+08:00\",\"2022-07-23T20:00:00+08:00\",\"2022-07-24T08:00:00+08:00\",\"2022-07-24T20:00:00+08:00\",\"2022-07-25T08:00:00+08:00\",\"2022-07-25T20:00:00+08:00\",\"2022-07-26T08:00:00+08:00\",\"2022-07-26T20:00:00+08:00\",\"2022-07-27T08:00:00+08:00\",\"2022-07-27T20:00:00+08:00\",\"2022-07-28T08:00:00+08:00\",\"2022-07-28T20:00:00+08:00\",\"2022-07-29T08:00:00+08:00\",\"2022-07-29T20:00:00+08:00\",\"2022-07-30T08:00:00+08:00\",\"2022-07-30T20:00:00+08:00\",\"2022-07-31T08:00:00+08:00\",\"2022-07-31T20:00:00+08:00\",\"2022-08-01T08:00:00+08:00\",\"2022-08-01T20:00:00+08:00\",\"2022-08-02T08:00:00+08:00\",\"2022-08-02T20:00:00+08:00\",\"2022-08-03T08:00:00+08:00\",\"2022-08-03T20:00:00+08:00\",\"2022-08-04T08:00:00+08:00\",\"2022-08-04T20:00:00+08:00\",\"2022-08-05T08:00:00+08:00\",\"2022-08-05T20:00:00+08:00\",\"2022-08-06T08:00:00+08:00\",\"2022-08-06T20:00:00+08:00\",\"2022-08-07T08:00:00+08:00\",\"2022-08-07T20:00:00+08:00\",\"2022-08-08T08:00:00+08:00\",\"2022-08-08T20:00:00+08:00\",\"2022-08-09T08:00:00+08:00\",\"2022-08-09T20:00:00+08:00\",\"2022-08-10T08:00:00+08:00\",\"2022-08-10T20:00:00+08:00\",\"2022-08-11T08:00:00+08:00\",\"2022-08-11T20:00:00+08:00\",\"2022-08-12T08:00:00+08:00\",\"2022-08-12T20:00:00+08:00\",\"2022-08-13T08:00:00+08:00\",\"2022-08-13T20:00:00+08:00\",\"2022-08-14T08:00:00+08:00\",\"2022-08-14T20:00:00+08:00\",\"2022-08-15T08:00:00+08:00\",\"2022-08-15T20:00:00+08:00\",\"2022-08-16T08:00:00+08:00\",\"2022-08-16T20:00:00+08:00\",\"2022-08-17T08:00:00+08:00\",\"2022-08-17T20:00:00+08:00\",\"2022-08-18T08:00:00+08:00\",\"2022-08-18T20:00:00+08:00\",\"2022-08-19T08:00:00+08:00\",\"2022-08-19T20:00:00+08:00\",\"2022-08-20T08:00:00+08:00\",\"2022-08-20T20:00:00+08:00\",\"2022-08-21T08:00:00+08:00\",\"2022-08-21T20:00:00+08:00\",\"2022-08-22T08:00:00+08:00\",\"2022-08-22T20:00:00+08:00\",\"2022-08-23T08:00:00+08:00\",\"2022-08-23T20:00:00+08:00\",\"2022-08-24T08:00:00+08:00\",\"2022-08-24T20:00:00+08:00\",\"2022-08-25T08:00:00+08:00\",\"2022-08-25T20:00:00+08:00\",\"2022-08-26T08:00:00+08:00\",\"2022-08-26T20:00:00+08:00\",\"2022-08-27T08:00:00+08:00\",\"2022-08-27T20:00:00+08:00\",\"2022-08-28T08:00:00+08:00\",\"2022-08-28T20:00:00+08:00\",\"2022-08-29T08:00:00+08:00\",\"2022-08-29T20:00:00+08:00\",\"2022-08-30T08:00:00+08:00\",\"2022-08-30T20:00:00+08:00\",\"2022-08-31T08:00:00+08:00\",\"2022-08-31T20:00:00+08:00\",\"2022-09-01T08:00:00+08:00\",\"2022-09-01T20:00:00+08:00\",\"2022-09-02T08:00:00+08:00\",\"2022-09-02T20:00:00+08:00\",\"2022-09-03T08:00:00+08:00\",\"2022-09-03T20:00:00+08:00\",\"2022-09-04T08:00:00+08:00\",\"2022-09-04T20:00:00+08:00\",\"2022-09-05T08:00:00+08:00\",\"2022-09-05T20:00:00+08:00\",\"2022-09-06T08:00:00+08:00\",\"2022-09-06T20:00:00+08:00\",\"2022-09-07T08:00:00+08:00\",\"2022-09-07T20:00:00+08:00\",\"2022-09-08T08:00:00+08:00\",\"2022-09-08T20:00:00+08:00\",\"2022-09-09T08:00:00+08:00\",\"2022-09-09T20:00:00+08:00\",\"2022-09-10T08:00:00+08:00\",\"2022-09-10T20:00:00+08:00\",\"2022-09-11T08:00:00+08:00\",\"2022-09-11T20:00:00+08:00\",\"2022-09-12T08:00:00+08:00\",\"2022-09-12T20:00:00+08:00\",\"2022-09-13T08:00:00+08:00\",\"2022-09-13T20:00:00+08:00\",\"2022-09-14T08:00:00+08:00\",\"2022-09-14T20:00:00+08:00\",\"2022-09-15T08:00:00+08:00\",\"2022-09-15T20:00:00+08:00\",\"2022-09-16T08:00:00+08:00\",\"2022-09-16T20:00:00+08:00\",\"2022-09-17T08:00:00+08:00\",\"2022-09-17T20:00:00+08:00\",\"2022-09-18T08:00:00+08:00\",\"2022-09-18T20:00:00+08:00\",\"2022-09-19T08:00:00+08:00\",\"2022-09-19T20:00:00+08:00\",\"2022-09-20T08:00:00+08:00\",\"2022-09-20T20:00:00+08:00\",\"2022-09-21T08:00:00+08:00\",\"2022-09-21T20:00:00+08:00\",\"2022-09-22T08:00:00+08:00\",\"2022-09-22T20:00:00+08:00\",\"2022-09-23T08:00:00+08:00\",\"2022-09-23T20:00:00+08:00\",\"2022-09-24T08:00:00+08:00\",\"2022-09-24T20:00:00+08:00\",\"2022-09-25T08:00:00+08:00\",\"2022-09-25T20:00:00+08:00\",\"2022-09-26T08:00:00+08:00\",\"2022-09-26T20:00:00+08:00\",\"2022-09-27T08:00:00+08:00\",\"2022-09-27T20:00:00+08:00\",\"2022-09-28T08:00:00+08:00\",\"2022-09-28T20:00:00+08:00\",\"2022-09-29T08:00:00+08:00\",\"2022-09-29T20:00:00+08:00\",\"2022-09-30T08:00:00+08:00\",\"2022-09-30T20:00:00+08:00\",\"2022-10-01T08:00:00+08:00\",\"2022-10-01T20:00:00+08:00\",\"2022-10-02T08:00:00+08:00\",\"2022-10-02T20:00:00+08:00\",\"2022-10-03T08:00:00+08:00\",\"2022-10-03T20:00:00+08:00\",\"2022-10-04T08:00:00+08:00\",\"2022-10-04T20:00:00+08:00\",\"2022-10-05T08:00:00+08:00\",\"2022-10-05T20:00:00+08:00\",\"2022-10-06T08:00:00+08:00\",\"2022-10-06T20:00:00+08:00\",\"2022-10-07T08:00:00+08:00\",\"2022-10-07T20:00:00+08:00\",\"2022-10-08T08:00:00+08:00\",\"2022-10-08T20:00:00+08:00\",\"2022-10-09T08:00:00+08:00\",\"2022-10-09T20:00:00+08:00\",\"2022-10-10T08:00:00+08:00\",\"2022-10-10T20:00:00+08:00\",\"2022-10-11T08:00:00+08:00\",\"2022-10-11T20:00:00+08:00\",\"2022-10-12T08:00:00+08:00\",\"2022-10-12T20:00:00+08:00\",\"2022-10-13T08:00:00+08:00\",\"2022-10-13T20:00:00+08:00\",\"2022-10-14T08:00:00+08:00\",\"2022-10-14T20:00:00+08:00\",\"2022-10-15T08:00:00+08:00\",\"2022-10-15T20:00:00+08:00\",\"2022-10-16T08:00:00+08:00\",\"2022-10-16T20:00:00+08:00\",\"2022-10-17T08:00:00+08:00\",\"2022-10-17T20:00:00+08:00\",\"2022-10-18T08:00:00+08:00\",\"2022-10-18T20:00:00+08:00\",\"2022-10-19T08:00:00+08:00\",\"2022-10-19T20:00:00+08:00\",\"2022-10-20T08:00:00+08:00\",\"2022-10-20T20:00:00+08:00\",\"2022-10-21T08:00:00+08:00\",\"2022-10-21T20:00:00+08:00\",\"2022-10-22T08:00:00+08:00\",\"2022-10-22T20:00:00+08:00\",\"2022-10-23T08:00:00+08:00\",\"2022-10-23T20:00:00+08:00\",\"2022-10-24T08:00:00+08:00\",\"2022-10-24T20:00:00+08:00\",\"2022-10-25T08:00:00+08:00\",\"2022-10-25T20:00:00+08:00\",\"2022-10-26T08:00:00+08:00\",\"2022-10-26T20:00:00+08:00\",\"2022-10-27T08:00:00+08:00\",\"2022-10-27T20:00:00+08:00\",\"2022-10-28T08:00:00+08:00\",\"2022-10-28T20:00:00+08:00\",\"2022-10-29T08:00:00+08:00\",\"2022-10-29T20:00:00+08:00\",\"2022-10-30T08:00:00+08:00\",\"2022-10-30T20:00:00+08:00\",\"2022-10-31T08:00:00+08:00\",\"2022-10-31T20:00:00+08:00\",\"2022-11-01T08:00:00+08:00\",\"2022-11-01T20:00:00+08:00\",\"2022-11-02T08:00:00+08:00\",\"2022-11-02T20:00:00+08:00\",\"2022-11-03T08:00:00+08:00\",\"2022-11-03T20:00:00+08:00\",\"2022-11-04T08:00:00+08:00\",\"2022-11-04T20:00:00+08:00\",\"2022-11-05T08:00:00+08:00\",\"2022-11-05T20:00:00+08:00\",\"2022-11-06T08:00:00+08:00\",\"2022-11-06T20:00:00+08:00\",\"2022-11-07T08:00:00+08:00\",\"2022-11-07T20:00:00+08:00\",\"2022-11-08T08:00:00+08:00\",\"2022-11-08T20:00:00+08:00\",\"2022-11-09T08:00:00+08:00\",\"2022-11-09T20:00:00+08:00\",\"2022-11-10T08:00:00+08:00\",\"2022-11-10T20:00:00+08:00\",\"2022-11-11T08:00:00+08:00\",\"2022-11-11T20:00:00+08:00\",\"2022-11-12T08:00:00+08:00\",\"2022-11-12T20:00:00+08:00\",\"2022-11-13T08:00:00+08:00\",\"2022-11-13T20:00:00+08:00\",\"2022-11-14T08:00:00+08:00\",\"2022-11-14T20:00:00+08:00\",\"2022-11-15T08:00:00+08:00\",\"2022-11-15T20:00:00+08:00\",\"2022-11-16T08:00:00+08:00\",\"2022-11-16T20:00:00+08:00\",\"2022-11-17T08:00:00+08:00\",\"2022-11-17T20:00:00+08:00\",\"2022-11-18T08:00:00+08:00\",\"2022-11-18T20:00:00+08:00\",\"2022-11-19T08:00:00+08:00\",\"2022-11-19T20:00:00+08:00\",\"2022-11-20T08:00:00+08:00\",\"2022-11-20T20:00:00+08:00\",\"2022-11-21T08:00:00+08:00\",\"2022-11-21T20:00:00+08:00\",\"2022-11-22T08:00:00+08:00\",\"2022-11-22T20:00:00+08:00\",\"2022-11-23T08:00:00+08:00\",\"2022-11-23T20:00:00+08:00\",\"2022-11-24T08:00:00+08:00\",\"2022-11-24T20:00:00+08:00\",\"2022-11-25T08:00:00+08:00\",\"2022-11-25T20:00:00+08:00\",\"2022-11-26T08:00:00+08:00\",\"2022-11-26T20:00:00+08:00\",\"2022-11-27T08:00:00+08:00\",\"2022-11-27T20:00:00+08:00\",\"2022-11-28T08:00:00+08:00\",\"2022-11-28T20:00:00+08:00\",\"2022-11-29T08:00:00+08:00\",\"2022-11-29T20:00:00+08:00\",\"2022-11-30T08:00:00+08:00\",\"2022-11-30T20:00:00+08:00\",\"2022-12-01T08:00:00+08:00\",\"2022-12-01T20:00:00+08:00\",\"2022-12-02T08:00:00+08:00\",\"2022-12-02T20:00:00+08:00\",\"2022-12-03T08:00:00+08:00\",\"2022-12-03T20:00:00+08:00\",\"2022-12-04T08:00:00+08:00\",\"2022-12-04T20:00:00+08:00\",\"2022-12-05T08:00:00+08:00\",\"2022-12-05T20:00:00+08:00\",\"2022-12-06T08:00:00+08:00\",\"2022-12-06T20:00:00+08:00\",\"2022-12-07T08:00:00+08:00\",\"2022-12-07T20:00:00+08:00\",\"2022-12-08T08:00:00+08:00\",\"2022-12-08T20:00:00+08:00\",\"2022-12-09T08:00:00+08:00\",\"2022-12-09T20:00:00+08:00\",\"2022-12-10T08:00:00+08:00\",\"2022-12-10T20:00:00+08:00\",\"2022-12-11T08:00:00+08:00\",\"2022-12-11T20:00:00+08:00\",\"2022-12-12T08:00:00+08:00\",\"2022-12-12T20:00:00+08:00\",\"2022-12-13T08:00:00+08:00\",\"2022-12-13T20:00:00+08:00\",\"2022-12-14T08:00:00+08:00\",\"2022-12-14T20:00:00+08:00\",\"2022-12-15T08:00:00+08:00\",\"2022-12-15T20:00:00+08:00\",\"2022-12-16T08:00:00+08:00\",\"2022-12-16T20:00:00+08:00\",\"2022-12-17T08:00:00+08:00\",\"2022-12-17T20:00:00+08:00\",\"2022-12-18T08:00:00+08:00\",\"2022-12-18T20:00:00+08:00\",\"2022-12-19T08:00:00+08:00\",\"2022-12-19T20:00:00+08:00\",\"2022-12-20T08:00:00+08:00\",\"2022-12-20T20:00:00+08:00\",\"2022-12-21T08:00:00+08:00\",\"2022-12-21T20:00:00+08:00\",\"2022-12-22T08:00:00+08:00\",\"2022-12-22T20:00:00+08:00\",\"2022-12-23T08:00:00+08:00\",\"2022-12-23T20:00:00+08:00\",\"2022-12-24T08:00:00+08:00\",\"2022-12-24T20:00:00+08:00\",\"2022-12-25T08:00:00+08:00\",\"2022-12-25T20:00:00+08:00\",\"2022-12-26T08:00:00+08:00\",\"2022-12-26T20:00:00+08:00\",\"2022-12-27T08:00:00+08:00\",\"2022-12-27T20:00:00+08:00\",\"2022-12-28T08:00:00+08:00\",\"2022-12-28T20:00:00+08:00\",\"2022-12-29T08:00:00+08:00\",\"2022-12-29T20:00:00+08:00\",\"2022-12-30T08:00:00+08:00\",\"2022-12-30T20:00:00+08:00\",\"2022-12-31T08:00:00+08:00\",\"2022-12-31T20:00:00+08:00\",\"2023-01-01T08:00:00+08:00\",\"2023-01-01T20:00:00+08:00\",\"2023-01-02T08:00:00+08:00\",\"2023-01-02T20:00:00+08:00\",\"2023-01-03T08:00:00+08:00\",\"2023-01-03T20:00:00+08:00\",\"2023-01-04T08:00:00+08:00\",\"2023-01-04T20:00:00+08:00\",\"2023-01-05T08:00:00+08:00\",\"2023-01-05T20:00:00+08:00\",\"2023-01-06T08:00:00+08:00\",\"2023-01-06T20:00:00+08:00\",\"2023-01-07T08:00:00+08:00\",\"2023-01-07T20:00:00+08:00\",\"2023-01-08T08:00:00+08:00\",\"2023-01-08T20:00:00+08:00\",\"2023-01-09T08:00:00+08:00\",\"2023-01-09T20:00:00+08:00\",\"2023-01-10T08:00:00+08:00\",\"2023-01-10T20:00:00+08:00\",\"2023-01-11T08:00:00+08:00\",\"2023-01-11T20:00:00+08:00\",\"2023-01-12T08:00:00+08:00\",\"2023-01-12T20:00:00+08:00\",\"2023-01-13T08:00:00+08:00\",\"2023-01-13T20:00:00+08:00\",\"2023-01-14T08:00:00+08:00\",\"2023-01-14T20:00:00+08:00\",\"2023-01-15T08:00:00+08:00\",\"2023-01-15T20:00:00+08:00\",\"2023-01-16T08:00:00+08:00\",\"2023-01-16T20:00:00+08:00\",\"2023-01-17T08:00:00+08:00\",\"2023-01-17T20:00:00+08:00\",\"2023-01-18T08:00:00+08:00\",\"2023-01-18T20:00:00+08:00\",\"2023-01-19T08:00:00+08:00\",\"2023-01-19T20:00:00+08:00\",\"2023-01-20T08:00:00+08:00\",\"2023-01-20T20:00:00+08:00\",\"2023-01-21T08:00:00+08:00\",\"2023-01-21T20:00:00+08:00\",\"2023-01-22T08:00:00+08:00\",\"2023-01-22T20:00:00+08:00\",\"2023-01-23T08:00:00+08:00\",\"2023-01-23T20:00:00+08:00\",\"2023-01-24T08:00:00+08:00\",\"2023-01-24T20:00:00+08:00\",\"2023-01-25T08:00:00+08:00\",\"2023-01-25T20:00:00+08:00\",\"2023-01-26T08:00:00+08:00\",\"2023-01-26T20:00:00+08:00\",\"2023-01-27T08:00:00+08:00\",\"2023-01-27T20:00:00+08:00\",\"2023-01-28T08:00:00+08:00\",\"2023-01-28T20:00:00+08:00\",\"2023-01-29T08:00:00+08:00\",\"2023-01-29T20:00:00+08:00\",\"2023-01-30T08:00:00+08:00\",\"2023-01-30T20:00:00+08:00\",\"2023-01-31T08:00:00+08:00\",\"2023-01-31T20:00:00+08:00\",\"2023-02-01T08:00:00+08:00\",\"2023-02-01T20:00:00+08:00\",\"2023-02-02T08:00:00+08:00\",\"2023-02-02T20:00:00+08:00\",\"2023-02-03T08:00:00+08:00\",\"2023-02-03T20:00:00+08:00\",\"2023-02-04T08:00:00+08:00\",\"2023-02-04T20:00:00+08:00\",\"2023-02-05T08:00:00+08:00\",\"2023-02-05T20:00:00+08:00\",\"2023-02-06T08:00:00+08:00\",\"2023-02-06T20:00:00+08:00\",\"2023-02-07T08:00:00+08:00\",\"2023-02-07T20:00:00+08:00\",\"2023-02-08T08:00:00+08:00\",\"2023-02-08T20:00:00+08:00\",\"2023-02-09T08:00:00+08:00\",\"2023-02-09T20:00:00+08:00\",\"2023-02-10T08:00:00+08:00\",\"2023-02-10T20:00:00+08:00\",\"2023-02-11T08:00:00+08:00\",\"2023-02-11T20:00:00+08:00\",\"2023-02-12T08:00:00+08:00\"],\"xhoverformat\":\"%y/%m/%d_%H:00\",\"y\":[39219.171875,38928.2109375,39116.71875,39479.80078125,37699.0703125,38333.6484375,43160.0,43609.9609375,44421.19921875,44103.28125,43892.98046875,43382.23046875,42454.0,41662.0703125,39148.66015625,39129.58984375,39397.9609375,38352.48046875,38420.80859375,38337.05078125,37988.0,38983.05078125,38730.62890625,42151.66015625,41941.7109375,39076.37890625,39422.0,39893.6796875,38729.5703125,39079.16015625,38807.359375,38741.12109375,37777.33984375,38897.640625,39671.37109375,38645.01171875,39280.328125,40521.6015625,41114.0,40748.51171875,40917.8984375,40390.41015625,41757.51171875,41721.78125,42201.12890625,41586.859375,41262.109375,41244.28125,41002.25,42983.0,42364.12890625,42039.78125,42882.76171875,42968.421875,43991.4609375,44585.28125,44313.16015625,44334.48828125,44511.26953125,44569.5,46827.76171875,47252.5390625,47122.2109375,47896.1015625,47434.80078125,47319.91015625,47067.98828125,47152.01171875,45510.33984375,45064.26171875,46283.48828125,46542.83984375,45811.0,46252.58984375,46407.3515625,46160.08984375,46580.51171875,46683.37109375,45497.55078125,44819.19140625,43170.46875,43766.73828125,43444.19140625,43298.7890625,42252.01171875,42445.1015625,42753.96875,42680.359375,42158.8515625,41067.62890625,39530.44921875,40378.0,40074.94140625,39722.640625,41147.7890625,40919.98828125,39942.37890625,40220.0,40551.8984375,40416.94921875,40378.7109375,40464.76953125,39678.12109375,38998.5390625,40801.12890625,40687.30078125,41493.1796875,42090.0,41358.19140625,42440.0,40480.01171875,40585.5390625,39709.1796875,39602.9296875,39441.6015625,39609.109375,39450.12890625,38832.2890625,40426.078125,40467.03125,38112.6484375,39017.19140625,39235.71875,39679.30859375,39742.0703125,38749.5390625,38596.109375,38580.01171875,37630.80078125,37942.78125,38468.3515625,38528.76953125,38525.16015625,38570.01171875,37728.94921875,39002.30078125,39690.0,39492.828125,36552.96875,35780.83984375,36013.76953125,36055.859375,35472.390625,34786.23828125,34038.3984375,33122.30859375,30076.310546875,31622.240234375,31017.099609375,31533.150390625,29103.939453125,28472.98046875,29029.75,30668.080078125,29287.05078125,29074.240234375,30086.740234375,30241.4609375,31328.890625,29950.94921875,29874.009765625,30319.470703125,30444.9296875,29833.580078125,28715.3203125,29500.19921875,30319.23046875,30414.0703125,29201.009765625,29288.0,29445.060546875,29897.51953125,30293.939453125,30397.109375,29109.150390625,29295.740234375,29654.580078125,29409.009765625,29542.150390625,28998.400390625,29201.349609375,28912.9609375,28629.80078125,28828.01953125,29031.330078125,29213.849609375,29468.099609375,30665.369140625,31734.220703125,31767.0,31801.0390625,31609.16015625,29805.830078125,30173.669921875,30452.619140625,29758.189453125,29700.2109375,29681.689453125,29864.0390625,29718.689453125,29919.2109375,31396.7109375,31373.099609375,29521.5,31125.330078125,30410.849609375,30204.76953125,30299.470703125,30109.9296875,30020.560546875,29091.880859375,28734.009765625,28424.69921875,27457.390625,26574.529296875,23729.4296875,22487.41015625,21994.560546875,22136.41015625,21177.029296875,22583.720703125,21044.55078125,20401.310546875,20972.0390625,20468.810546875,19243.98046875,18970.7890625,19692.5,20574.0,20801.7890625,20573.890625,20962.419921875,20723.51953125,20506.30078125,19987.990234375,20638.7890625,21110.130859375,21169.529296875,21237.689453125,21340.220703125,21491.189453125,21708.599609375,21038.0703125,21304.55078125,20742.560546875,20998.130859375,20281.2890625,20104.80078125,20123.009765625,19101.359375,19942.2109375,19191.029296875,19279.80078125,19195.2109375,19252.810546875,19089.80078125,19315.830078125,19806.490234375,20236.7109375,19520.390625,20175.830078125,20103.4296875,20564.509765625,20507.830078125,21624.98046875,21583.98046875,21594.75,21447.2890625,21591.830078125,21301.83984375,20862.470703125,20473.060546875,19963.609375,19773.900390625,19328.75,19843.890625,20234.869140625,19738.130859375,20588.83984375,20769.740234375,20830.0390625,20616.689453125,21195.599609375,21456.7890625,20798.16015625,22133.310546875,22432.580078125,21974.490234375,23396.619140625,23728.55078125,23223.30078125,22606.0390625,23152.189453125,23610.580078125,22684.830078125,22227.529296875,22451.0703125,22657.630859375,22579.6796875,21941.25,21310.900390625,21090.220703125,21254.669921875,21200.23046875,22952.44921875,23114.51953125,23842.9296875,23720.560546875,23773.75,23956.380859375,23643.509765625,23801.0703125,23293.3203125,23227.7890625,23268.009765625,22882.609375,22987.7890625,23402.830078125,22818.369140625,22885.009765625,22622.98046875,23405.130859375,23312.419921875,23157.419921875,22954.2109375,23038.48046875,23174.390625,24166.119140625,23810.0,23263.919921875,23149.94921875,23123.94921875,23954.05078125,24559.369140625,23934.390625,23672.990234375,24403.6796875,24435.91015625,24441.380859375,24564.490234375,24305.240234375,24049.48046875,24094.8203125,24038.029296875,23854.740234375,23746.650390625,23342.66015625,23534.4296875,23191.19921875,21467.91015625,20834.390625,21233.66015625,21140.0703125,21524.390625,21515.609375,21248.7109375,21399.830078125,21456.33984375,21529.119140625,21438.919921875,21368.080078125,21720.310546875,21559.0390625,21189.76953125,20241.05078125,20211.2109375,20037.599609375,20034.970703125,19555.609375,19825.08984375,20285.73046875,20403.80078125,19811.66015625,20314.779296875,20050.01953125,20074.009765625,20131.4609375,20090.810546875,19951.859375,19798.759765625,19831.900390625,19850.7890625,20000.30078125,19701.94921875,19796.83984375,19918.330078125,18790.609375,18739.58984375,19292.83984375,19311.150390625,19319.76953125,20937.720703125,21360.109375,21285.109375,21648.33984375,21613.029296875,21826.869140625,22312.75,22395.740234375,22522.740234375,20173.5703125,20225.349609375,20226.7109375,20148.349609375,19701.880859375,19867.8203125,19803.30078125,19810.220703125,20113.619140625,19922.919921875,19416.1796875,18684.869140625,19537.01953125,19219.490234375,18875.0,19165.9296875,18461.359375,19229.810546875,19401.630859375,18862.720703125,19289.91015625,19051.630859375,18920.5,19117.939453125,18807.380859375,18876.619140625,19227.8203125,20229.259765625,19079.130859375,18955.4296875,19412.8203125,19463.0390625,19591.509765625,19436.2890625,19422.609375,19312.0390625,19310.94921875,19192.4296875,19056.80078125,19245.41015625,19629.080078125,19939.0,20337.8203125,20027.4296875,20158.259765625,20245.220703125,19960.669921875,19998.900390625,19530.08984375,19534.2109375,19417.9609375,19468.349609375,19439.01953125,19331.619140625,19131.869140625,19153.6796875,19060.0,19114.619140625,19155.529296875,18753.19921875,19375.130859375,19596.25,19176.9296875,19167.330078125,19069.390625,19144.689453125,19262.98046875,19457.580078125,19549.859375,19563.58984375,19327.439453125,19200.83984375,19123.970703125,19208.08984375,19041.919921875,18945.650390625,19164.369140625,19178.66015625,19204.349609375,19151.779296875,19570.400390625,19423.630859375,19329.720703125,19302.130859375,20080.0703125,20607.810546875,20771.58984375,20622.83984375,20295.109375,20173.740234375,20591.83984375,20698.890625,20809.669921875,20769.83984375,20627.48046875,20730.5390625,20490.740234375,20522.7890625,20483.619140625,20431.330078125,20151.83984375,20130.640625,20207.8203125,20558.4609375,21148.51953125,21404.630859375,21299.369140625,21255.080078125,20905.580078125,20733.4609375,20591.130859375,19699.0390625,18547.23046875,17818.080078125,15922.8095703125,16397.5703125,17601.150390625,17350.69921875,17070.310546875,16866.919921875,16812.080078125,16659.23046875,16329.849609375,16749.80078125,16619.4609375,16781.619140625,16900.5703125,16707.900390625,16662.759765625,16595.080078125,16692.560546875,16749.880859375,16700.44921875,16676.259765625,16700.6796875,16525.380859375,16280.23046875,16084.419921875,15781.2900390625,15747.8798828125,16226.9404296875,16585.76953125,16603.109375,16572.109375,16598.94921875,16531.640625,16522.140625,16580.310546875,16458.5703125,16550.91015625,16428.779296875,16213.2900390625,16212.91015625,16497.640625,16442.529296875,16879.3203125,17163.640625,17102.470703125,16977.369140625,16996.919921875,17092.740234375,16943.4296875,16885.19921875,16948.640625,17105.69921875,17310.509765625,16966.349609375,16983.900390625,17088.9609375,16793.2890625,16836.640625,16851.01953125,17224.099609375,17241.439453125,17128.560546875,17168.609375,17127.490234375,17167.4296875,17085.05078125,16988.619140625,17209.830078125,17444.630859375,17774.69921875,17824.9296875,17803.150390625,17720.330078125,17356.33984375,17027.08984375,16632.119140625,16708.220703125,16776.51953125,16711.349609375,16738.2109375,16734.4609375,16438.880859375,16814.25,16895.560546875,16878.470703125,16824.669921875,16834.80078125,16821.4296875,16844.01953125,16778.5,16824.41015625,16836.119140625,16821.509765625,16832.109375,16864.0390625,16919.390625,16832.400390625,16706.359375,16678.98046875,16547.310546875,16598.69921875,16633.470703125,16496.26953125,16607.48046875,16567.150390625,16542.400390625,16556.66015625,16616.75,16735.109375,16672.869140625,16721.029296875,16675.1796875,16835.349609375,16850.359375,16833.599609375,16831.849609375,16738.220703125,16950.650390625,16918.30078125,16943.5703125,16927.419921875,17127.830078125,17238.9296875,17178.259765625,17252.890625,17440.66015625,17437.75,17943.259765625,18200.80078125,18846.619140625,18920.94921875,19930.009765625,20721.73046875,20954.919921875,20722.23046875,20871.5,20817.560546875,21185.650390625,21219.75,21134.810546875,21204.669921875,20677.470703125,20743.720703125,21071.58984375,20963.509765625,22667.2109375,22905.650390625,22783.55078125,22783.609375,22707.880859375,22904.580078125,22916.44921875,22917.66015625,22632.890625,22598.470703125,23060.939453125,22992.939453125,23009.650390625,22967.470703125,23074.16015625,22981.509765625,23022.599609375,23432.169921875,23742.30078125,23077.470703125,22826.150390625,22865.4296875,23125.130859375,23077.51953125,23732.66015625,23820.490234375,23488.939453125,23534.130859375,23431.900390625,23363.759765625,23326.83984375,23356.330078125,22932.91015625,22878.23046875,22762.51953125,22977.240234375,23240.4609375,23159.0703125,22963.0,22685.7890625,21796.349609375,21733.51953125,21625.189453125,21697.439453125,21862.55078125,21814.009765625],\"yhoverformat\":\"$000,.0f\",\"type\":\"scatter\"},{\"mode\":\"markers\",\"name\":\"\\u9a8c\\u8bc1\\u96c6\\u9884\\u6d4b\\u503c\",\"showlegend\":true,\"x\":[\"2022-02-26T08:00:00+08:00\",\"2022-02-26T20:00:00+08:00\",\"2022-02-27T08:00:00+08:00\",\"2022-02-27T20:00:00+08:00\",\"2022-02-28T08:00:00+08:00\",\"2022-02-28T20:00:00+08:00\",\"2022-03-01T08:00:00+08:00\",\"2022-03-01T20:00:00+08:00\",\"2022-03-02T08:00:00+08:00\",\"2022-03-02T20:00:00+08:00\",\"2022-03-03T08:00:00+08:00\",\"2022-03-03T20:00:00+08:00\",\"2022-03-04T08:00:00+08:00\",\"2022-03-04T20:00:00+08:00\",\"2022-03-05T08:00:00+08:00\",\"2022-03-05T20:00:00+08:00\",\"2022-03-06T08:00:00+08:00\",\"2022-03-06T20:00:00+08:00\",\"2022-03-07T08:00:00+08:00\",\"2022-03-07T20:00:00+08:00\",\"2022-03-08T08:00:00+08:00\",\"2022-03-08T20:00:00+08:00\",\"2022-03-09T08:00:00+08:00\",\"2022-03-09T20:00:00+08:00\",\"2022-03-10T08:00:00+08:00\",\"2022-03-10T20:00:00+08:00\",\"2022-03-11T08:00:00+08:00\",\"2022-03-11T20:00:00+08:00\",\"2022-03-12T08:00:00+08:00\",\"2022-03-12T20:00:00+08:00\",\"2022-03-13T08:00:00+08:00\",\"2022-03-13T20:00:00+08:00\",\"2022-03-14T08:00:00+08:00\",\"2022-03-14T20:00:00+08:00\",\"2022-03-15T08:00:00+08:00\",\"2022-03-15T20:00:00+08:00\",\"2022-03-16T08:00:00+08:00\",\"2022-03-16T20:00:00+08:00\",\"2022-03-17T08:00:00+08:00\",\"2022-03-17T20:00:00+08:00\",\"2022-03-18T08:00:00+08:00\",\"2022-03-18T20:00:00+08:00\",\"2022-03-19T08:00:00+08:00\",\"2022-03-19T20:00:00+08:00\",\"2022-03-20T08:00:00+08:00\",\"2022-03-20T20:00:00+08:00\",\"2022-03-21T08:00:00+08:00\",\"2022-03-21T20:00:00+08:00\",\"2022-03-22T08:00:00+08:00\",\"2022-03-22T20:00:00+08:00\",\"2022-03-23T08:00:00+08:00\",\"2022-03-23T20:00:00+08:00\",\"2022-03-24T08:00:00+08:00\",\"2022-03-24T20:00:00+08:00\",\"2022-03-25T08:00:00+08:00\",\"2022-03-25T20:00:00+08:00\",\"2022-03-26T08:00:00+08:00\",\"2022-03-26T20:00:00+08:00\",\"2022-03-27T08:00:00+08:00\",\"2022-03-27T20:00:00+08:00\",\"2022-03-28T08:00:00+08:00\",\"2022-03-28T20:00:00+08:00\",\"2022-03-29T08:00:00+08:00\",\"2022-03-29T20:00:00+08:00\",\"2022-03-30T08:00:00+08:00\",\"2022-03-30T20:00:00+08:00\",\"2022-03-31T08:00:00+08:00\",\"2022-03-31T20:00:00+08:00\",\"2022-04-01T08:00:00+08:00\",\"2022-04-01T20:00:00+08:00\",\"2022-04-02T08:00:00+08:00\",\"2022-04-02T20:00:00+08:00\",\"2022-04-03T08:00:00+08:00\",\"2022-04-03T20:00:00+08:00\",\"2022-04-04T08:00:00+08:00\",\"2022-04-04T20:00:00+08:00\",\"2022-04-05T08:00:00+08:00\",\"2022-04-05T20:00:00+08:00\",\"2022-04-06T08:00:00+08:00\",\"2022-04-06T20:00:00+08:00\",\"2022-04-07T08:00:00+08:00\",\"2022-04-07T20:00:00+08:00\",\"2022-04-08T08:00:00+08:00\",\"2022-04-08T20:00:00+08:00\",\"2022-04-09T08:00:00+08:00\",\"2022-04-09T20:00:00+08:00\",\"2022-04-10T08:00:00+08:00\",\"2022-04-10T20:00:00+08:00\",\"2022-04-11T08:00:00+08:00\",\"2022-04-11T20:00:00+08:00\",\"2022-04-12T08:00:00+08:00\",\"2022-04-12T20:00:00+08:00\",\"2022-04-13T08:00:00+08:00\",\"2022-04-13T20:00:00+08:00\",\"2022-04-14T08:00:00+08:00\",\"2022-04-14T20:00:00+08:00\",\"2022-04-15T08:00:00+08:00\",\"2022-04-15T20:00:00+08:00\",\"2022-04-16T08:00:00+08:00\",\"2022-04-16T20:00:00+08:00\",\"2022-04-17T08:00:00+08:00\",\"2022-04-17T20:00:00+08:00\",\"2022-04-18T08:00:00+08:00\",\"2022-04-18T20:00:00+08:00\",\"2022-04-19T08:00:00+08:00\",\"2022-04-19T20:00:00+08:00\",\"2022-04-20T08:00:00+08:00\",\"2022-04-20T20:00:00+08:00\",\"2022-04-21T08:00:00+08:00\",\"2022-04-21T20:00:00+08:00\",\"2022-04-22T08:00:00+08:00\",\"2022-04-22T20:00:00+08:00\",\"2022-04-23T08:00:00+08:00\",\"2022-04-23T20:00:00+08:00\",\"2022-04-24T08:00:00+08:00\",\"2022-04-24T20:00:00+08:00\",\"2022-04-25T08:00:00+08:00\",\"2022-04-25T20:00:00+08:00\",\"2022-04-26T08:00:00+08:00\",\"2022-04-26T20:00:00+08:00\",\"2022-04-27T08:00:00+08:00\",\"2022-04-27T20:00:00+08:00\",\"2022-04-28T08:00:00+08:00\",\"2022-04-28T20:00:00+08:00\",\"2022-04-29T08:00:00+08:00\",\"2022-04-29T20:00:00+08:00\",\"2022-04-30T08:00:00+08:00\",\"2022-04-30T20:00:00+08:00\",\"2022-05-01T08:00:00+08:00\",\"2022-05-01T20:00:00+08:00\",\"2022-05-02T08:00:00+08:00\",\"2022-05-02T20:00:00+08:00\",\"2022-05-03T08:00:00+08:00\",\"2022-05-03T20:00:00+08:00\",\"2022-05-04T08:00:00+08:00\",\"2022-05-04T20:00:00+08:00\",\"2022-05-05T08:00:00+08:00\",\"2022-05-05T20:00:00+08:00\",\"2022-05-06T08:00:00+08:00\",\"2022-05-06T20:00:00+08:00\",\"2022-05-07T08:00:00+08:00\",\"2022-05-07T20:00:00+08:00\",\"2022-05-08T08:00:00+08:00\",\"2022-05-08T20:00:00+08:00\",\"2022-05-09T08:00:00+08:00\",\"2022-05-09T20:00:00+08:00\",\"2022-05-10T08:00:00+08:00\",\"2022-05-10T20:00:00+08:00\",\"2022-05-11T08:00:00+08:00\",\"2022-05-11T20:00:00+08:00\",\"2022-05-12T08:00:00+08:00\",\"2022-05-12T20:00:00+08:00\",\"2022-05-13T08:00:00+08:00\",\"2022-05-13T20:00:00+08:00\",\"2022-05-14T08:00:00+08:00\",\"2022-05-14T20:00:00+08:00\",\"2022-05-15T08:00:00+08:00\",\"2022-05-15T20:00:00+08:00\",\"2022-05-16T08:00:00+08:00\",\"2022-05-16T20:00:00+08:00\",\"2022-05-17T08:00:00+08:00\",\"2022-05-17T20:00:00+08:00\",\"2022-05-18T08:00:00+08:00\",\"2022-05-18T20:00:00+08:00\",\"2022-05-19T08:00:00+08:00\",\"2022-05-19T20:00:00+08:00\",\"2022-05-20T08:00:00+08:00\",\"2022-05-20T20:00:00+08:00\",\"2022-05-21T08:00:00+08:00\",\"2022-05-21T20:00:00+08:00\",\"2022-05-22T08:00:00+08:00\",\"2022-05-22T20:00:00+08:00\",\"2022-05-23T08:00:00+08:00\",\"2022-05-23T20:00:00+08:00\",\"2022-05-24T08:00:00+08:00\",\"2022-05-24T20:00:00+08:00\",\"2022-05-25T08:00:00+08:00\",\"2022-05-25T20:00:00+08:00\",\"2022-05-26T08:00:00+08:00\",\"2022-05-26T20:00:00+08:00\",\"2022-05-27T08:00:00+08:00\",\"2022-05-27T20:00:00+08:00\",\"2022-05-28T08:00:00+08:00\",\"2022-05-28T20:00:00+08:00\",\"2022-05-29T08:00:00+08:00\",\"2022-05-29T20:00:00+08:00\",\"2022-05-30T08:00:00+08:00\",\"2022-05-30T20:00:00+08:00\",\"2022-05-31T08:00:00+08:00\",\"2022-05-31T20:00:00+08:00\",\"2022-06-01T08:00:00+08:00\",\"2022-06-01T20:00:00+08:00\",\"2022-06-02T08:00:00+08:00\",\"2022-06-02T20:00:00+08:00\",\"2022-06-03T08:00:00+08:00\",\"2022-06-03T20:00:00+08:00\",\"2022-06-04T08:00:00+08:00\",\"2022-06-04T20:00:00+08:00\",\"2022-06-05T08:00:00+08:00\",\"2022-06-05T20:00:00+08:00\",\"2022-06-06T08:00:00+08:00\",\"2022-06-06T20:00:00+08:00\",\"2022-06-07T08:00:00+08:00\",\"2022-06-07T20:00:00+08:00\",\"2022-06-08T08:00:00+08:00\",\"2022-06-08T20:00:00+08:00\",\"2022-06-09T08:00:00+08:00\",\"2022-06-09T20:00:00+08:00\",\"2022-06-10T08:00:00+08:00\",\"2022-06-10T20:00:00+08:00\",\"2022-06-11T08:00:00+08:00\",\"2022-06-11T20:00:00+08:00\",\"2022-06-12T08:00:00+08:00\",\"2022-06-12T20:00:00+08:00\",\"2022-06-13T08:00:00+08:00\",\"2022-06-13T20:00:00+08:00\",\"2022-06-14T08:00:00+08:00\",\"2022-06-14T20:00:00+08:00\",\"2022-06-15T08:00:00+08:00\",\"2022-06-15T20:00:00+08:00\",\"2022-06-16T08:00:00+08:00\",\"2022-06-16T20:00:00+08:00\",\"2022-06-17T08:00:00+08:00\",\"2022-06-17T20:00:00+08:00\",\"2022-06-18T08:00:00+08:00\",\"2022-06-18T20:00:00+08:00\",\"2022-06-19T08:00:00+08:00\",\"2022-06-19T20:00:00+08:00\",\"2022-06-20T08:00:00+08:00\",\"2022-06-20T20:00:00+08:00\",\"2022-06-21T08:00:00+08:00\",\"2022-06-21T20:00:00+08:00\",\"2022-06-22T08:00:00+08:00\",\"2022-06-22T20:00:00+08:00\",\"2022-06-23T08:00:00+08:00\",\"2022-06-23T20:00:00+08:00\",\"2022-06-24T08:00:00+08:00\",\"2022-06-24T20:00:00+08:00\",\"2022-06-25T08:00:00+08:00\",\"2022-06-25T20:00:00+08:00\",\"2022-06-26T08:00:00+08:00\",\"2022-06-26T20:00:00+08:00\",\"2022-06-27T08:00:00+08:00\",\"2022-06-27T20:00:00+08:00\",\"2022-06-28T08:00:00+08:00\",\"2022-06-28T20:00:00+08:00\",\"2022-06-29T08:00:00+08:00\",\"2022-06-29T20:00:00+08:00\",\"2022-06-30T08:00:00+08:00\",\"2022-06-30T20:00:00+08:00\",\"2022-07-01T08:00:00+08:00\",\"2022-07-01T20:00:00+08:00\",\"2022-07-02T08:00:00+08:00\",\"2022-07-02T20:00:00+08:00\",\"2022-07-03T08:00:00+08:00\",\"2022-07-03T20:00:00+08:00\",\"2022-07-04T08:00:00+08:00\",\"2022-07-04T20:00:00+08:00\",\"2022-07-05T08:00:00+08:00\",\"2022-07-05T20:00:00+08:00\",\"2022-07-06T08:00:00+08:00\",\"2022-07-06T20:00:00+08:00\",\"2022-07-07T08:00:00+08:00\",\"2022-07-07T20:00:00+08:00\",\"2022-07-08T08:00:00+08:00\",\"2022-07-08T20:00:00+08:00\",\"2022-07-09T08:00:00+08:00\",\"2022-07-09T20:00:00+08:00\",\"2022-07-10T08:00:00+08:00\",\"2022-07-10T20:00:00+08:00\",\"2022-07-11T08:00:00+08:00\",\"2022-07-11T20:00:00+08:00\",\"2022-07-12T08:00:00+08:00\",\"2022-07-12T20:00:00+08:00\",\"2022-07-13T08:00:00+08:00\",\"2022-07-13T20:00:00+08:00\",\"2022-07-14T08:00:00+08:00\",\"2022-07-14T20:00:00+08:00\",\"2022-07-15T08:00:00+08:00\",\"2022-07-15T20:00:00+08:00\",\"2022-07-16T08:00:00+08:00\",\"2022-07-16T20:00:00+08:00\",\"2022-07-17T08:00:00+08:00\",\"2022-07-17T20:00:00+08:00\",\"2022-07-18T08:00:00+08:00\",\"2022-07-18T20:00:00+08:00\",\"2022-07-19T08:00:00+08:00\",\"2022-07-19T20:00:00+08:00\",\"2022-07-20T08:00:00+08:00\",\"2022-07-20T20:00:00+08:00\",\"2022-07-21T08:00:00+08:00\",\"2022-07-21T20:00:00+08:00\",\"2022-07-22T08:00:00+08:00\",\"2022-07-22T20:00:00+08:00\",\"2022-07-23T08:00:00+08:00\",\"2022-07-23T20:00:00+08:00\",\"2022-07-24T08:00:00+08:00\",\"2022-07-24T20:00:00+08:00\",\"2022-07-25T08:00:00+08:00\",\"2022-07-25T20:00:00+08:00\",\"2022-07-26T08:00:00+08:00\",\"2022-07-26T20:00:00+08:00\",\"2022-07-27T08:00:00+08:00\",\"2022-07-27T20:00:00+08:00\",\"2022-07-28T08:00:00+08:00\",\"2022-07-28T20:00:00+08:00\",\"2022-07-29T08:00:00+08:00\",\"2022-07-29T20:00:00+08:00\",\"2022-07-30T08:00:00+08:00\",\"2022-07-30T20:00:00+08:00\",\"2022-07-31T08:00:00+08:00\",\"2022-07-31T20:00:00+08:00\",\"2022-08-01T08:00:00+08:00\",\"2022-08-01T20:00:00+08:00\",\"2022-08-02T08:00:00+08:00\",\"2022-08-02T20:00:00+08:00\",\"2022-08-03T08:00:00+08:00\",\"2022-08-03T20:00:00+08:00\",\"2022-08-04T08:00:00+08:00\",\"2022-08-04T20:00:00+08:00\",\"2022-08-05T08:00:00+08:00\",\"2022-08-05T20:00:00+08:00\",\"2022-08-06T08:00:00+08:00\",\"2022-08-06T20:00:00+08:00\",\"2022-08-07T08:00:00+08:00\",\"2022-08-07T20:00:00+08:00\",\"2022-08-08T08:00:00+08:00\",\"2022-08-08T20:00:00+08:00\",\"2022-08-09T08:00:00+08:00\",\"2022-08-09T20:00:00+08:00\",\"2022-08-10T08:00:00+08:00\",\"2022-08-10T20:00:00+08:00\",\"2022-08-11T08:00:00+08:00\",\"2022-08-11T20:00:00+08:00\",\"2022-08-12T08:00:00+08:00\",\"2022-08-12T20:00:00+08:00\",\"2022-08-13T08:00:00+08:00\",\"2022-08-13T20:00:00+08:00\",\"2022-08-14T08:00:00+08:00\",\"2022-08-14T20:00:00+08:00\",\"2022-08-15T08:00:00+08:00\",\"2022-08-15T20:00:00+08:00\",\"2022-08-16T08:00:00+08:00\",\"2022-08-16T20:00:00+08:00\",\"2022-08-17T08:00:00+08:00\",\"2022-08-17T20:00:00+08:00\",\"2022-08-18T08:00:00+08:00\",\"2022-08-18T20:00:00+08:00\",\"2022-08-19T08:00:00+08:00\",\"2022-08-19T20:00:00+08:00\",\"2022-08-20T08:00:00+08:00\",\"2022-08-20T20:00:00+08:00\",\"2022-08-21T08:00:00+08:00\",\"2022-08-21T20:00:00+08:00\",\"2022-08-22T08:00:00+08:00\",\"2022-08-22T20:00:00+08:00\",\"2022-08-23T08:00:00+08:00\",\"2022-08-23T20:00:00+08:00\",\"2022-08-24T08:00:00+08:00\",\"2022-08-24T20:00:00+08:00\",\"2022-08-25T08:00:00+08:00\",\"2022-08-25T20:00:00+08:00\",\"2022-08-26T08:00:00+08:00\",\"2022-08-26T20:00:00+08:00\",\"2022-08-27T08:00:00+08:00\",\"2022-08-27T20:00:00+08:00\",\"2022-08-28T08:00:00+08:00\",\"2022-08-28T20:00:00+08:00\",\"2022-08-29T08:00:00+08:00\",\"2022-08-29T20:00:00+08:00\",\"2022-08-30T08:00:00+08:00\",\"2022-08-30T20:00:00+08:00\",\"2022-08-31T08:00:00+08:00\",\"2022-08-31T20:00:00+08:00\",\"2022-09-01T08:00:00+08:00\",\"2022-09-01T20:00:00+08:00\",\"2022-09-02T08:00:00+08:00\",\"2022-09-02T20:00:00+08:00\",\"2022-09-03T08:00:00+08:00\",\"2022-09-03T20:00:00+08:00\",\"2022-09-04T08:00:00+08:00\",\"2022-09-04T20:00:00+08:00\",\"2022-09-05T08:00:00+08:00\",\"2022-09-05T20:00:00+08:00\",\"2022-09-06T08:00:00+08:00\",\"2022-09-06T20:00:00+08:00\",\"2022-09-07T08:00:00+08:00\",\"2022-09-07T20:00:00+08:00\",\"2022-09-08T08:00:00+08:00\",\"2022-09-08T20:00:00+08:00\",\"2022-09-09T08:00:00+08:00\",\"2022-09-09T20:00:00+08:00\",\"2022-09-10T08:00:00+08:00\",\"2022-09-10T20:00:00+08:00\",\"2022-09-11T08:00:00+08:00\",\"2022-09-11T20:00:00+08:00\",\"2022-09-12T08:00:00+08:00\",\"2022-09-12T20:00:00+08:00\",\"2022-09-13T08:00:00+08:00\",\"2022-09-13T20:00:00+08:00\",\"2022-09-14T08:00:00+08:00\",\"2022-09-14T20:00:00+08:00\",\"2022-09-15T08:00:00+08:00\",\"2022-09-15T20:00:00+08:00\",\"2022-09-16T08:00:00+08:00\",\"2022-09-16T20:00:00+08:00\",\"2022-09-17T08:00:00+08:00\",\"2022-09-17T20:00:00+08:00\",\"2022-09-18T08:00:00+08:00\",\"2022-09-18T20:00:00+08:00\",\"2022-09-19T08:00:00+08:00\",\"2022-09-19T20:00:00+08:00\",\"2022-09-20T08:00:00+08:00\",\"2022-09-20T20:00:00+08:00\",\"2022-09-21T08:00:00+08:00\",\"2022-09-21T20:00:00+08:00\",\"2022-09-22T08:00:00+08:00\",\"2022-09-22T20:00:00+08:00\",\"2022-09-23T08:00:00+08:00\",\"2022-09-23T20:00:00+08:00\",\"2022-09-24T08:00:00+08:00\",\"2022-09-24T20:00:00+08:00\",\"2022-09-25T08:00:00+08:00\",\"2022-09-25T20:00:00+08:00\",\"2022-09-26T08:00:00+08:00\",\"2022-09-26T20:00:00+08:00\",\"2022-09-27T08:00:00+08:00\",\"2022-09-27T20:00:00+08:00\",\"2022-09-28T08:00:00+08:00\",\"2022-09-28T20:00:00+08:00\",\"2022-09-29T08:00:00+08:00\",\"2022-09-29T20:00:00+08:00\",\"2022-09-30T08:00:00+08:00\",\"2022-09-30T20:00:00+08:00\",\"2022-10-01T08:00:00+08:00\",\"2022-10-01T20:00:00+08:00\",\"2022-10-02T08:00:00+08:00\",\"2022-10-02T20:00:00+08:00\",\"2022-10-03T08:00:00+08:00\",\"2022-10-03T20:00:00+08:00\",\"2022-10-04T08:00:00+08:00\",\"2022-10-04T20:00:00+08:00\",\"2022-10-05T08:00:00+08:00\",\"2022-10-05T20:00:00+08:00\",\"2022-10-06T08:00:00+08:00\",\"2022-10-06T20:00:00+08:00\",\"2022-10-07T08:00:00+08:00\",\"2022-10-07T20:00:00+08:00\",\"2022-10-08T08:00:00+08:00\",\"2022-10-08T20:00:00+08:00\",\"2022-10-09T08:00:00+08:00\",\"2022-10-09T20:00:00+08:00\",\"2022-10-10T08:00:00+08:00\",\"2022-10-10T20:00:00+08:00\",\"2022-10-11T08:00:00+08:00\",\"2022-10-11T20:00:00+08:00\",\"2022-10-12T08:00:00+08:00\",\"2022-10-12T20:00:00+08:00\",\"2022-10-13T08:00:00+08:00\",\"2022-10-13T20:00:00+08:00\",\"2022-10-14T08:00:00+08:00\",\"2022-10-14T20:00:00+08:00\",\"2022-10-15T08:00:00+08:00\",\"2022-10-15T20:00:00+08:00\",\"2022-10-16T08:00:00+08:00\",\"2022-10-16T20:00:00+08:00\",\"2022-10-17T08:00:00+08:00\",\"2022-10-17T20:00:00+08:00\",\"2022-10-18T08:00:00+08:00\",\"2022-10-18T20:00:00+08:00\",\"2022-10-19T08:00:00+08:00\",\"2022-10-19T20:00:00+08:00\",\"2022-10-20T08:00:00+08:00\",\"2022-10-20T20:00:00+08:00\",\"2022-10-21T08:00:00+08:00\",\"2022-10-21T20:00:00+08:00\",\"2022-10-22T08:00:00+08:00\",\"2022-10-22T20:00:00+08:00\",\"2022-10-23T08:00:00+08:00\",\"2022-10-23T20:00:00+08:00\",\"2022-10-24T08:00:00+08:00\",\"2022-10-24T20:00:00+08:00\",\"2022-10-25T08:00:00+08:00\",\"2022-10-25T20:00:00+08:00\",\"2022-10-26T08:00:00+08:00\",\"2022-10-26T20:00:00+08:00\",\"2022-10-27T08:00:00+08:00\",\"2022-10-27T20:00:00+08:00\",\"2022-10-28T08:00:00+08:00\",\"2022-10-28T20:00:00+08:00\",\"2022-10-29T08:00:00+08:00\",\"2022-10-29T20:00:00+08:00\",\"2022-10-30T08:00:00+08:00\",\"2022-10-30T20:00:00+08:00\",\"2022-10-31T08:00:00+08:00\",\"2022-10-31T20:00:00+08:00\",\"2022-11-01T08:00:00+08:00\",\"2022-11-01T20:00:00+08:00\",\"2022-11-02T08:00:00+08:00\",\"2022-11-02T20:00:00+08:00\",\"2022-11-03T08:00:00+08:00\",\"2022-11-03T20:00:00+08:00\",\"2022-11-04T08:00:00+08:00\",\"2022-11-04T20:00:00+08:00\",\"2022-11-05T08:00:00+08:00\",\"2022-11-05T20:00:00+08:00\",\"2022-11-06T08:00:00+08:00\",\"2022-11-06T20:00:00+08:00\",\"2022-11-07T08:00:00+08:00\",\"2022-11-07T20:00:00+08:00\",\"2022-11-08T08:00:00+08:00\",\"2022-11-08T20:00:00+08:00\",\"2022-11-09T08:00:00+08:00\",\"2022-11-09T20:00:00+08:00\",\"2022-11-10T08:00:00+08:00\",\"2022-11-10T20:00:00+08:00\",\"2022-11-11T08:00:00+08:00\",\"2022-11-11T20:00:00+08:00\",\"2022-11-12T08:00:00+08:00\",\"2022-11-12T20:00:00+08:00\",\"2022-11-13T08:00:00+08:00\",\"2022-11-13T20:00:00+08:00\",\"2022-11-14T08:00:00+08:00\",\"2022-11-14T20:00:00+08:00\",\"2022-11-15T08:00:00+08:00\",\"2022-11-15T20:00:00+08:00\",\"2022-11-16T08:00:00+08:00\",\"2022-11-16T20:00:00+08:00\",\"2022-11-17T08:00:00+08:00\",\"2022-11-17T20:00:00+08:00\",\"2022-11-18T08:00:00+08:00\",\"2022-11-18T20:00:00+08:00\",\"2022-11-19T08:00:00+08:00\",\"2022-11-19T20:00:00+08:00\",\"2022-11-20T08:00:00+08:00\",\"2022-11-20T20:00:00+08:00\",\"2022-11-21T08:00:00+08:00\",\"2022-11-21T20:00:00+08:00\",\"2022-11-22T08:00:00+08:00\",\"2022-11-22T20:00:00+08:00\",\"2022-11-23T08:00:00+08:00\",\"2022-11-23T20:00:00+08:00\",\"2022-11-24T08:00:00+08:00\",\"2022-11-24T20:00:00+08:00\",\"2022-11-25T08:00:00+08:00\",\"2022-11-25T20:00:00+08:00\",\"2022-11-26T08:00:00+08:00\",\"2022-11-26T20:00:00+08:00\",\"2022-11-27T08:00:00+08:00\",\"2022-11-27T20:00:00+08:00\",\"2022-11-28T08:00:00+08:00\",\"2022-11-28T20:00:00+08:00\",\"2022-11-29T08:00:00+08:00\",\"2022-11-29T20:00:00+08:00\",\"2022-11-30T08:00:00+08:00\",\"2022-11-30T20:00:00+08:00\",\"2022-12-01T08:00:00+08:00\",\"2022-12-01T20:00:00+08:00\",\"2022-12-02T08:00:00+08:00\",\"2022-12-02T20:00:00+08:00\",\"2022-12-03T08:00:00+08:00\",\"2022-12-03T20:00:00+08:00\",\"2022-12-04T08:00:00+08:00\",\"2022-12-04T20:00:00+08:00\",\"2022-12-05T08:00:00+08:00\",\"2022-12-05T20:00:00+08:00\",\"2022-12-06T08:00:00+08:00\",\"2022-12-06T20:00:00+08:00\",\"2022-12-07T08:00:00+08:00\",\"2022-12-07T20:00:00+08:00\",\"2022-12-08T08:00:00+08:00\",\"2022-12-08T20:00:00+08:00\",\"2022-12-09T08:00:00+08:00\",\"2022-12-09T20:00:00+08:00\",\"2022-12-10T08:00:00+08:00\",\"2022-12-10T20:00:00+08:00\",\"2022-12-11T08:00:00+08:00\",\"2022-12-11T20:00:00+08:00\",\"2022-12-12T08:00:00+08:00\",\"2022-12-12T20:00:00+08:00\",\"2022-12-13T08:00:00+08:00\",\"2022-12-13T20:00:00+08:00\",\"2022-12-14T08:00:00+08:00\",\"2022-12-14T20:00:00+08:00\",\"2022-12-15T08:00:00+08:00\",\"2022-12-15T20:00:00+08:00\",\"2022-12-16T08:00:00+08:00\",\"2022-12-16T20:00:00+08:00\",\"2022-12-17T08:00:00+08:00\",\"2022-12-17T20:00:00+08:00\",\"2022-12-18T08:00:00+08:00\",\"2022-12-18T20:00:00+08:00\",\"2022-12-19T08:00:00+08:00\",\"2022-12-19T20:00:00+08:00\",\"2022-12-20T08:00:00+08:00\",\"2022-12-20T20:00:00+08:00\",\"2022-12-21T08:00:00+08:00\",\"2022-12-21T20:00:00+08:00\",\"2022-12-22T08:00:00+08:00\",\"2022-12-22T20:00:00+08:00\",\"2022-12-23T08:00:00+08:00\",\"2022-12-23T20:00:00+08:00\",\"2022-12-24T08:00:00+08:00\",\"2022-12-24T20:00:00+08:00\",\"2022-12-25T08:00:00+08:00\",\"2022-12-25T20:00:00+08:00\",\"2022-12-26T08:00:00+08:00\",\"2022-12-26T20:00:00+08:00\",\"2022-12-27T08:00:00+08:00\",\"2022-12-27T20:00:00+08:00\",\"2022-12-28T08:00:00+08:00\",\"2022-12-28T20:00:00+08:00\",\"2022-12-29T08:00:00+08:00\",\"2022-12-29T20:00:00+08:00\",\"2022-12-30T08:00:00+08:00\",\"2022-12-30T20:00:00+08:00\",\"2022-12-31T08:00:00+08:00\",\"2022-12-31T20:00:00+08:00\",\"2023-01-01T08:00:00+08:00\",\"2023-01-01T20:00:00+08:00\",\"2023-01-02T08:00:00+08:00\",\"2023-01-02T20:00:00+08:00\",\"2023-01-03T08:00:00+08:00\",\"2023-01-03T20:00:00+08:00\",\"2023-01-04T08:00:00+08:00\",\"2023-01-04T20:00:00+08:00\",\"2023-01-05T08:00:00+08:00\",\"2023-01-05T20:00:00+08:00\",\"2023-01-06T08:00:00+08:00\",\"2023-01-06T20:00:00+08:00\",\"2023-01-07T08:00:00+08:00\",\"2023-01-07T20:00:00+08:00\",\"2023-01-08T08:00:00+08:00\",\"2023-01-08T20:00:00+08:00\",\"2023-01-09T08:00:00+08:00\",\"2023-01-09T20:00:00+08:00\",\"2023-01-10T08:00:00+08:00\",\"2023-01-10T20:00:00+08:00\",\"2023-01-11T08:00:00+08:00\",\"2023-01-11T20:00:00+08:00\",\"2023-01-12T08:00:00+08:00\",\"2023-01-12T20:00:00+08:00\",\"2023-01-13T08:00:00+08:00\",\"2023-01-13T20:00:00+08:00\",\"2023-01-14T08:00:00+08:00\",\"2023-01-14T20:00:00+08:00\",\"2023-01-15T08:00:00+08:00\",\"2023-01-15T20:00:00+08:00\",\"2023-01-16T08:00:00+08:00\",\"2023-01-16T20:00:00+08:00\",\"2023-01-17T08:00:00+08:00\",\"2023-01-17T20:00:00+08:00\",\"2023-01-18T08:00:00+08:00\",\"2023-01-18T20:00:00+08:00\",\"2023-01-19T08:00:00+08:00\",\"2023-01-19T20:00:00+08:00\",\"2023-01-20T08:00:00+08:00\",\"2023-01-20T20:00:00+08:00\",\"2023-01-21T08:00:00+08:00\",\"2023-01-21T20:00:00+08:00\",\"2023-01-22T08:00:00+08:00\",\"2023-01-22T20:00:00+08:00\",\"2023-01-23T08:00:00+08:00\",\"2023-01-23T20:00:00+08:00\",\"2023-01-24T08:00:00+08:00\",\"2023-01-24T20:00:00+08:00\",\"2023-01-25T08:00:00+08:00\",\"2023-01-25T20:00:00+08:00\",\"2023-01-26T08:00:00+08:00\",\"2023-01-26T20:00:00+08:00\",\"2023-01-27T08:00:00+08:00\",\"2023-01-27T20:00:00+08:00\",\"2023-01-28T08:00:00+08:00\",\"2023-01-28T20:00:00+08:00\",\"2023-01-29T08:00:00+08:00\",\"2023-01-29T20:00:00+08:00\",\"2023-01-30T08:00:00+08:00\",\"2023-01-30T20:00:00+08:00\",\"2023-01-31T08:00:00+08:00\",\"2023-01-31T20:00:00+08:00\",\"2023-02-01T08:00:00+08:00\",\"2023-02-01T20:00:00+08:00\",\"2023-02-02T08:00:00+08:00\",\"2023-02-02T20:00:00+08:00\",\"2023-02-03T08:00:00+08:00\",\"2023-02-03T20:00:00+08:00\",\"2023-02-04T08:00:00+08:00\",\"2023-02-04T20:00:00+08:00\",\"2023-02-05T08:00:00+08:00\",\"2023-02-05T20:00:00+08:00\",\"2023-02-06T08:00:00+08:00\",\"2023-02-06T20:00:00+08:00\",\"2023-02-07T08:00:00+08:00\",\"2023-02-07T20:00:00+08:00\",\"2023-02-08T08:00:00+08:00\",\"2023-02-08T20:00:00+08:00\",\"2023-02-09T08:00:00+08:00\",\"2023-02-09T20:00:00+08:00\",\"2023-02-10T08:00:00+08:00\",\"2023-02-10T20:00:00+08:00\",\"2023-02-11T08:00:00+08:00\",\"2023-02-11T20:00:00+08:00\",\"2023-02-12T08:00:00+08:00\",\"2023-02-12T20:00:00+08:00\"],\"xhoverformat\":\"%y/%m/%d_%H:00\",\"y\":[38730.08550079381,38453.089155197755,38774.791802737716,39064.814154565414,38013.52794343162,38247.66452658804,42870.165848975696,43404.2475244275,44027.07103576347,43921.48675500623,43400.62769020094,43373.685175387975,42153.654551475825,41357.94636968385,39602.34604474859,39096.27471593165,38192.56132058768,38206.09233031633,38234.91607953032,37991.36946938026,38007.3406868463,38998.47365700978,38974.183374303175,40213.97081441456,39916.53531965005,38975.46323049403,39089.72894541335,40092.47699600772,38367.82837395318,38800.16919220885,38737.541048604406,38399.034506076656,37514.12574476583,38597.85939432869,39336.27088164863,38240.23981868566,39070.403887929104,40219.097949155046,40719.53713973451,40413.01929200115,40670.27038636354,40142.35669255443,41159.229421110555,41902.65624850371,41939.90700263701,41127.98088411329,40981.49903007651,40913.22332828048,41166.804473565484,42784.723883270366,41601.04965615333,41836.30804097102,42810.09741775297,42714.71729162586,43921.23232576347,44076.754127895314,44102.64037585197,43857.389860773124,44282.31753609199,44252.66496434477,46580.087302408014,46665.243998962374,46769.83754766825,47617.14089590131,46999.197800040114,47051.49457439306,46721.68874097002,46488.67395947486,45289.96527710377,44706.971507225455,46005.73641680652,46273.23792566136,45400.23336892092,45804.69105516311,46190.922355651164,45915.22899617713,47137.48394846918,46212.78785057449,45085.82821466197,44494.42285981844,43134.6720317453,43317.61436726742,43035.21332775697,42744.48551302888,41965.592791190276,42332.472049274395,42329.22614893493,42385.466576550665,41761.87977748641,40635.513809806995,39477.54079119734,39650.03225282363,39755.33511941841,39727.65630179685,40745.473502542016,39687.35625173894,39782.177404529684,39837.99378340748,40153.31642493578,40437.386674478286,40181.21883189189,39923.28540456027,39230.57480622412,39112.3924229617,40276.99216684872,40701.80419251179,41362.572355915865,41833.08141557419,41565.11345310762,41785.93876088142,40433.71287041236,40017.25845987514,39792.99064734702,39336.75661020299,39195.73341991999,39481.99330294565,39598.07857244956,38466.974823870856,39589.13499906766,39907.221667369595,38359.09296995172,38997.999493421004,38418.028034547606,39348.75333449802,39226.17626431518,38036.1528710947,38539.548837874136,37581.28349988912,37524.80020799621,37252.75366766841,37988.07730917848,38516.912345245466,37892.52370856767,37921.200968217636,39167.49177397353,38698.67890926695,38752.151455120525,37859.7293211712,35963.961613405874,35546.971359463445,35119.59191144162,34791.162308922605,33930.54768530691,33255.64713396403,33933.30014711496,32351.87591379216,32064.02006551645,30503.370365363924,30859.563595252086,31050.227472793144,29160.907233338687,28833.994568804923,28774.66629537932,30173.817033689385,29106.23385855905,29477.519368529163,29801.827988313154,30251.90175379155,31086.125125953586,29951.842939334634,30259.376576544782,30125.396450300024,30560.343240799728,29540.27858174351,29305.430753203913,29425.81626240933,30190.144837594136,30011.389019611994,29260.33316992455,28959.987158822398,29157.156329502228,30201.357071723985,29870.41979916837,30132.18508509551,29158.449678152927,29120.78836774153,29507.74055108407,29102.641009252184,28837.830282388968,28999.269491909265,28885.986799064252,28380.108219673642,28426.32953210853,28849.861701580736,29144.49654718061,29056.75893580764,29549.584524046913,30169.861815461012,31234.62506648408,31642.372985433794,31452.44348320707,31360.469239443282,29558.34305797953,29850.795980073304,29868.154993408945,29142.91407439041,28684.831570247836,29166.290724816194,30921.314728966707,28493.81496125659,30153.645806223532,30809.624146383212,30552.766260850538,28907.721224377674,30784.271814337502,29639.002910417516,29760.807055400754,29678.37583573476,29302.46819452116,28555.753061914755,29556.39243378503,28417.17971684046,27925.624347320725,27201.048413823042,25845.03306963226,23962.360757892064,22642.39726640279,21626.07001872319,21351.693137831015,20943.85655414519,21191.51836454747,20156.71222936523,20203.029916513286,20428.50434045026,20685.990589112786,19122.330142920924,18608.095875898733,19337.937723723862,20530.563234199846,20603.786813769868,20150.285963491253,21039.99804050632,20707.863794013167,20171.270593536236,19753.00048340295,20471.22725079719,20671.017813675164,20599.733293334062,20674.654995350083,21064.955236228045,21320.066811958135,21578.647877362237,20249.744667479594,20949.093556058684,21060.926773217663,20632.485275856736,20212.470783415127,19479.20185078978,19938.440851490355,20075.54930092451,20093.895191322983,19271.74757072077,19207.500331935124,18768.654220540684,19040.93109643295,18799.537497375048,19010.592336727976,19494.918639013053,19908.61287776517,19495.853473730775,20264.37434893834,20004.046973731656,20825.718503250824,20382.439155050703,21448.549724563847,21459.879535843756,21455.75469812021,21043.79134921657,21494.91752656275,21574.422809936994,20716.098049506156,20267.39087746047,20123.738585002273,19729.3115789065,20364.312998998255,19483.937704194806,19798.597287696517,21196.36023013698,20287.265270809767,20399.24883252129,20101.77864286004,20365.93787666225,21099.946967084717,21532.03142860336,21015.94291209984,21830.220573624832,22148.873925240187,22122.38629907337,22834.24077043301,23444.84589563367,23361.13674727108,22673.591833560684,23046.56582850548,23232.58058988336,22514.92050580254,22445.98945595698,22747.700132997576,22627.493880758644,21876.42261111709,21795.17101794026,21142.48098299384,20815.43724885017,21429.93398496851,21201.471944923356,22633.073976651012,23092.409352064755,23140.095560139787,23192.777833345393,23728.482458966926,23758.01167108129,23799.2214984315,23137.638004954028,23891.047325137013,23568.120718739836,23184.51273794419,22617.199133898146,22938.01127908844,22507.588317624795,22686.96864374826,22997.555431871537,23115.58747058142,23309.828777475235,23191.82372368504,22832.05884692691,22944.0597560868,22848.074396761,23451.630675440625,24166.72140966841,23455.30447950655,23403.826890215532,23422.051348475412,23578.793254475946,23424.510831155432,24407.417255802982,24113.202603952515,24012.974829753104,24155.804082160856,24203.65412724827,24439.147666366083,24926.173424366967,24240.128101193448,23956.83077685054,24000.216745224057,23754.954665179634,23729.66208545609,23655.946994848917,23005.03603710756,23169.620917265627,22873.91245736107,22189.684761277884,20966.585566498492,21648.7932485937,20677.933663092026,21524.89198985195,21072.95626491517,21883.556267385713,21714.915939297578,22281.32169354559,21296.859781027524,20672.180092715957,20921.55159052982,21539.326994390103,21663.459552443455,20636.197629807928,20712.738427005155,20921.006109653295,20290.684645632933,21701.408059500092,21365.524836664743,20905.989001847614,21322.940705904773,20284.296929644224,20158.285064684114,20222.93707726506,19729.394461159827,19966.372170860413,19778.437625196246,19849.230634500196,19436.25920609683,19825.655452165283,19347.39593807407,18653.168401752675,19460.06568774334,18219.40894771919,18718.165435806757,18996.11974605169,18445.15707584156,18814.0698403735,19353.232390703462,19052.552923093754,19968.976215610186,20482.932923458455,20534.181140932134,21166.723078343864,21483.383400890925,21065.134493194535,21823.57071841631,21948.71135596939,22310.73332850989,22021.614971491697,21172.86022007834,19828.531273606186,19745.593122948936,20115.2248428411,19874.133860382546,19705.25452300576,19589.489217549562,19813.186491775738,19909.00608659489,19455.4358465228,20218.469145562638,18927.081720274513,19349.034308197908,18688.112908999894,18459.479321965304,19001.506128770594,18373.773289545898,19191.585011802727,19132.58441240189,20082.268545926516,19085.526567456713,19501.146372977906,19843.027957960767,19089.851864583645,19332.006823875563,19614.244026373635,19430.750427492203,19253.677312001957,19512.55906651114,19226.84273686774,19160.67571379581,19623.57888109099,19082.269102151666,19200.90251907171,19194.059914436853,19047.071129408818,19547.67030201214,19371.046292685252,19755.342388932906,20010.833681032876,20233.050639664805,20280.584575693032,20219.02811889901,19740.271311287852,19894.118120904855,19623.60586601068,18055.45821317376,18690.668766393082,18993.410652864564,18428.477504233746,19615.633749737506,19416.589127139447,18847.561980693292,19292.013245405524,19173.331641128898,18927.007511745374,18415.582567612004,18306.95862840148,18432.70449915325,17807.545828517246,18067.908862367804,19406.67602414309,18593.298502439073,18004.09049105575,18928.75382154796,18872.844922945522,17580.280762409628,16975.275008043973,16737.697847627485,16712.85051907877,17372.571089350724,17383.836329572812,18251.70411410145,18845.43017203804,17915.964489588718,17842.62140537437,18359.79799238955,17868.724496435654,18801.06696407301,19008.433543153038,18807.8315051902,18785.639299989234,19020.11126714748,19038.152613452345,19392.771080527356,19726.836676272374,20110.86870580595,19978.68500421463,19930.54776248198,20150.922036598156,20032.198027447736,20334.899436539687,19936.189538190774,20278.768876096965,20642.134312139013,20320.240842666986,20114.546364860405,20041.442289934712,20441.960177902638,20376.92073897476,21200.11691645623,21191.16756059154,21372.912922176125,20801.175718795716,20870.226273285603,20518.352558041588,21151.438048835582,20900.327951196185,20995.939376634895,21467.213651515765,22103.951743938786,21960.844932357115,22305.401879377492,21687.61491055163,20158.3698744317,18489.154059896555,17834.494125813,17284.660967241187,17511.419102357544,17630.651969993487,17590.373122372475,17430.024874605228,17332.21225071778,17100.413718102787,17265.32434479136,17583.235611115328,17621.016426171052,16765.045136235753,16663.851687410406,16590.701352622393,16723.802541483066,16985.114866258322,16593.0355481753,16471.640031975887,16696.597887450287,16125.169083152014,16378.3512371245,16739.993493295122,16229.506275120866,15997.765567333772,16837.669265089873,16721.832642345933,16644.48037006384,17162.46746841675,18282.52860236078,17758.06705077731,17400.11401862672,17120.62735044243,17003.198617436978,16702.71575424213,16396.28271625635,16629.91429591578,16627.062568153167,16596.62550624077,16574.827473616657,17539.494983797355,17178.245936456453,17155.380072010452,17257.932404291452,16815.10794473748,16923.50347587779,16961.345007002812,17433.371968393516,17637.945608285965,17408.515002373486,17604.15856134388,17498.76413877159,17006.78472051392,16770.690766933072,16930.02226147641,17194.215226428223,17022.43019144945,17058.64491741621,16911.331349604803,17116.860062904736,17415.543610204753,17639.943456089917,17165.031035786993,17710.486854886763,17457.498414087742,16902.595945603345,17249.42444461307,17534.456513792982,17789.745418995302,18438.688405093788,18221.045390348765,18422.12062815325,18079.895949191516,18140.624547199433,16727.99966024149,16685.145680284655,16904.46368754452,17149.014522205773,17066.629562402097,17423.38369312089,17665.203268410987,17067.797623925682,16795.264391296394,16797.659302918593,17257.476551898173,16734.459657265073,16846.258179527314,17130.894148636115,17260.86315931886,16743.388774439994,16812.063467548534,16978.032288587678,17457.12255270639,16652.94688861556,17189.390708287083,16618.36667778411,16574.21742168231,16721.583031838833,16423.74565452042,16378.67505616074,16311.465258692342,16622.770038428713,16629.078727152624,16124.6361309882,16041.060943476914,16311.36599273778,15658.79835367708,16085.31813925746,16489.97628490304,16305.81480925936,16502.475121453666,15974.482400379758,16631.435088889557,16828.50981235048,16629.176065612923,16323.902415426543,16685.275786147427,17008.32671592459,16834.110146932613,16878.098457263426,17346.322472472562,17156.95387107647,17393.190459232803,17119.048732640756,17428.685266092205,17563.930792320847,18212.72728885532,18852.496366007443,19520.2112187366,19229.032370350895,20294.558909102245,20586.250470962,20757.755055525457,21134.699688652738,20804.373431778597,21046.794385278856,20889.50507090753,21089.62909029306,21582.08267213951,22017.320514272975,21666.289114022038,21816.50066945838,21151.129649753446,21661.923339515575,22055.61018781422,22335.38598013801,22742.53252087756,22816.60419792345,22961.688618619308,22736.331771832396,22950.60359911084,22893.49772657087,23585.01520595801,23868.742361521643,23113.993432825635,23364.0010037464,23729.072272211506,23739.129937277616,22973.63137307496,23397.151977581587,22463.523871270583,22249.5642980628,22312.79189238314,22788.709500944395,22952.822145007944,22846.366636843682,22788.520606506587,21877.15505893716,22542.761232942223,22292.447190433588,22942.74905998773,23532.242340522025,23836.537787369758,23528.790198296385,23867.27361089298,23642.113368520928,22849.126808628786,23331.68848991577,23079.585732730757,22752.28564185006,22403.07572367798,23068.4371059116,23266.568096228835,23075.580399651535,23764.53816665696,23877.84206193887,23121.481748038714,22225.661441703123,22122.492311257854],\"yhoverformat\":\"$000,.0f\",\"type\":\"scatter\"},{\"mode\":\"markers+lines\",\"name\":\"\\u6700\\u540e\\u7b2c31\\u65f6\\u5e8f\\u9884\\u6d4b\\u503c\",\"showlegend\":true,\"x\":[\"2023-02-12T20:00:00+08:00\",\"2023-02-13T08:00:00+08:00\",\"2023-02-13T20:00:00+08:00\",\"2023-02-14T08:00:00+08:00\",\"2023-02-14T20:00:00+08:00\",\"2023-02-15T08:00:00+08:00\",\"2023-02-15T20:00:00+08:00\"],\"xhoverformat\":\"%y/%m/%d_%H:00\",\"y\":[22122.492311257854,22939.701691557388,22164.95886486776,20690.308176262668,21516.756036566392,21590.94914575087,21630.576500310875],\"yhoverformat\":\"$000,.0f\",\"type\":\"scatter\"},{\"mode\":\"markers+lines\",\"name\":\"\\u6700\\u540e\\u7b2c15\\u65f6\\u5e8f\\u9884\\u6d4b\\u503c\",\"showlegend\":true,\"x\":[\"2023-02-04T20:00:00+08:00\",\"2023-02-05T08:00:00+08:00\",\"2023-02-05T20:00:00+08:00\",\"2023-02-06T08:00:00+08:00\",\"2023-02-06T20:00:00+08:00\",\"2023-02-07T08:00:00+08:00\",\"2023-02-07T20:00:00+08:00\"],\"xhoverformat\":\"%y/%m/%d_%H:00\",\"y\":[23836.537787369758,21824.06608444199,24704.792998245328,23347.33781583983,25138.37897779511,24568.67720835679,24511.26679172321],\"yhoverformat\":\"$000,.0f\",\"type\":\"scatter\"}],                        {\"margin\":{\"b\":10,\"l\":50,\"pad\":0,\"r\":15,\"t\":50},\"title\":{\"font\":{\"color\":\"rgb(0,125,125)\",\"family\":\"SimHei\",\"size\":20},\"text\":\"DLinear+3.5\\u65e5\\u9884\\u6d4b,\\u59cb\\u4e8e:2023\\u5e7402\\u670812\\u65e508\\u65f6,\\u6b62\\u4e8e:2023\\u5e7402\\u670815\\u65e520\\u65f6\"},\"xaxis\":{\"tickangle\":-30,\"tickformat\":\"%y/%m/%d_%H:\",\"title\":{\"text\":\"\\u4ea4\\u6613\\u65e5\\u671f\"}},\"yaxis\":{\"tickformat\":\"$000,.0f\",\"title\":{\"text\":\"\\u6536\\u76d8\\u4ef7\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1ec8f4af-2bd1-47c8-9b38-cda3622374ce');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 计算下预测的起始及结束日期,用于画图标注\n",
    "Predict_Start_date = datetime.datetime.strftime(data0.index[-1].tz_convert('Asia/Shanghai'), \"%Y年%m月%d日%H时\")\n",
    "Predict_End_date = data0.index[-1] + datetime.timedelta(\n",
    "    hours=L_pred * 12\n",
    ")  # 数据为每12小时一次数据\n",
    "Predict_End_date = datetime.datetime.strftime(Predict_End_date.tz_convert('Asia/Shanghai'), \"%Y年%m月%d日%H时\")\n",
    "\n",
    "# 尝试plotly绘制动态交互图\n",
    "# fig = px.scatter(\n",
    "#     x=data0.index[split:data_end],\n",
    "#     y=y_true[split:, -1],\n",
    "#     labels={'x':'日期','y':'$价格'},\n",
    "#     title='BTC',\n",
    "#     # animation_frame=np.arange(split_num,data_end),\n",
    "# )\n",
    "# 准备画布\n",
    "# fig = go.Figure()\n",
    "# 添加几组不同的数据\n",
    "trace1 = go.Scatter(  #\n",
    "    x=data0.index[-y_hat.shape[0]:],\n",
    "    # y=y_true[-y_hat.shape[0]:, -1],\n",
    "    y=data0.iloc[-y_hat.shape[0]:, -1],\n",
    "    mode=\"markers\",  # mode模式\n",
    "    name=\"真实值\",\n",
    "    showlegend=True,\n",
    "    xhoverformat=\"%y/%m/%d_%H:00\",\n",
    "    yhoverformat=\"$000,.0f\",\n",
    "    # hovertemplate='日期:%{x},价格: %{y:$.0f}',\n",
    ")\n",
    "trace2 = go.Scatter(  #\n",
    "    x=data0.index[-y_hat.shape[0]:].shift(freq=\"12h\"),  # 预测是偏离12个小时,即一个时刻\n",
    "    y=y_hat[:, 0, 0],\n",
    "    mode=\"markers\",  # mode模式\n",
    "    name=\"验证集预测值\",\n",
    "    showlegend=True,\n",
    "    xhoverformat=\"%y/%m/%d_%H:00\",\n",
    "    yhoverformat=\"$000,.0f\",\n",
    "    # hovertemplate='日期:%{x},价格: %{y:$.0f}',\n",
    ")\n",
    "\n",
    "trace_data = [trace1, trace2]\n",
    "# fig.add_trace(\n",
    "\n",
    "# )  # 名字\n",
    "# # fig.update_layout()\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=dict(\n",
    "        text=\"DLinear+{}日预测,始于:{},止于:{}\".format(\n",
    "            L_pred / 2, Predict_Start_date, Predict_End_date\n",
    "        ),\n",
    "        font=dict(color=\"rgb(0,125,125)\", family=\"SimHei\", size=20),\n",
    "    ),\n",
    "    margin=dict(l=50, b=10, t=50, r=15, pad=0),  # pad参数是刻度与标签的距离\n",
    "    xaxis=dict(title=\"交易日期\", tickangle=-30, tickformat='%y/%m/%d_%H:'),  # 设置坐标轴的标签\n",
    "    yaxis=dict(title=\"收盘价\", tickformat='$000,.0f'),\n",
    "    # calendar=\n",
    "    # template='presentation',\n",
    "    # template='simple_white'\n",
    "    # template='gridon',\n",
    "    # template='plotly'\n",
    ")\n",
    "fig = go.Figure(data=trace_data, layout=layout)\n",
    "\n",
    "for N in np.arange(Batch_size - 1, 0, -16):\n",
    "    # last_hat_draw = last_hat[N, :]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(  #\n",
    "            x=pd.date_range(\n",
    "                start=data0.index[-Batch_size + N] + datetime.timedelta(hours=12),\n",
    "                periods=7,\n",
    "                freq='12H',\n",
    "            ),\n",
    "            # y=last_hat_draw,\n",
    "            y=y_hat[-Batch_size+N, :, 0],\n",
    "            mode=\"markers+lines\",  # mode模式\n",
    "            name=\"最后第{}时序预测值\".format(N),\n",
    "            showlegend=True,\n",
    "            xhoverformat=\"%y/%m/%d_%H:00\",\n",
    "            yhoverformat=\"$000,.0f\",\n",
    "            # hovertemplate='日期:%{x},价格: %{y:$.0f}',\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.write_html('./checkpoint/LTSF_Linear&FF_{}.html'.format(today_date),\n",
    "                include_plotlyjs=True, auto_open=False)    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d72cd-333d-418d-b721-b0a3ebe7631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "# 定义超参空间Class\n",
    "class HypermodelSpace(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        # 定义超参选项\n",
    "        hp_Batch_size = hp.Int(\"Batch_size\", min_value=32, max_value=128, step=32)\n",
    "        hp_kernel_size = hp.Int(\"kernel_size\", min_value=24, max_value=60, step=1)\n",
    "        hp_L_seq = hp.Int(\"L_seq\", min_value=48, max_value=336, step=32)\n",
    "\n",
    "        model = LTSF_FF_DLinear(\n",
    "            seq_len=hp_L_seq,\n",
    "            pred_len=L_pred,\n",
    "            channels=in_features,\n",
    "            kernel_size=hp_kernel_size,\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        hp_Batch_size = hp.get(\"Batch_size\")\n",
    "        hp_L_seq = hp.get(\"L_seq\")\n",
    "\n",
    "        dataset_train = xs_ys_dataset(\n",
    "            data[:split, :],\n",
    "            hp_L_seq,\n",
    "            L_pred,\n",
    "            hp_Batch_size,\n",
    "            out_features,\n",
    "            shuffle=True,\n",
    "            buffer_size=10000,\n",
    "        )\n",
    "\n",
    "        dataset_val = xs_ys_dataset(\n",
    "            data[split:, :],\n",
    "            hp_L_seq,\n",
    "            L_pred,\n",
    "            hp_Batch_size,\n",
    "            out_features,\n",
    "            shuffle=True,\n",
    "            buffer_size=10000,\n",
    "        )\n",
    "\n",
    "        EPOCHS = 20\n",
    "        train_loss_results = []\n",
    "        logs = {}  # 字典\n",
    "        wait = 0\n",
    "        best = np.infty  # 先设置一个无穷大的数字;\n",
    "\n",
    "        patience = 20\n",
    "\n",
    "        # # Assign the model to the callbacks.\n",
    "        # for callback in callbacks:\n",
    "        #     callback.model = model\n",
    "        # callbacks.set_model(model=model)\n",
    "        callbacks = tf.keras.callbacks.CallbackList(\n",
    "            callbacks=[], add_history=True, add_progbar=True, model=model\n",
    "        )\n",
    "\n",
    "        @tf.function  # 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地执行。\n",
    "        def train_step(dataset):  # dataset是xs与xs_timestamp合集\n",
    "            xs, ys = dataset[0], dataset[1]\n",
    "\n",
    "            # 求导,根据导数优化变量\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_ = model(xs)\n",
    "                loss_value = loss_object(ys, y_)\n",
    "            gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            # 计算metric: 每个单步经过batch次运算后,共batch次 loss的平均值\n",
    "            train_loss.update_state(loss_value)\n",
    "            train_MSE.update_state(ys, y_)\n",
    "            return {\"train_loss\": train_loss.result(), \"train_MSE\": train_MSE.result()}\n",
    "\n",
    "        @tf.function\n",
    "        def test_step(dataset_val):  # validation, test 使用该单步训练\n",
    "            xs, ys = dataset_val[0], dataset_val[1]\n",
    "            y_ = model(xs)\n",
    "            loss_value = loss_object(ys, y_)\n",
    "            val_loss.update_state(loss_value)\n",
    "            val_MSE.update_state(ys, y_)\n",
    "            return {\"val_loss\": val_loss.result(), \"val_MSE\": val_MSE.result()}\n",
    "\n",
    "        train_start = time.time()\n",
    "        callbacks.on_train_begin(logs=logs)\n",
    "        for epoch in range(EPOCHS):\n",
    "            epoch_start = time.time()\n",
    "            callbacks.on_epoch_begin(epoch, logs=logs)\n",
    "\n",
    "            train_loss.reset_states()\n",
    "            train_MSE.reset_states()\n",
    "\n",
    "            for batch, batch_data in enumerate(dataset_train):\n",
    "                callbacks.on_batch_begin(batch, logs=logs)\n",
    "                callbacks.on_train_batch_begin(batch, logs=logs)\n",
    "                train_dict = train_step(batch_data)\n",
    "                logs[\"train_loss\"] = train_dict[\"train_loss\"]\n",
    "                logs[\"train_MSE\"] = train_dict[\"train_MSE\"]\n",
    "\n",
    "                # if batch % 10 == 0:  # 每n次batch,打印\n",
    "                #     print(\n",
    "                #         \"Epoch {} Batch {} train_loss {:.4f} train_MSE {:.4f} \".format(\n",
    "                #             epoch + 1, batch, train_loss.result(), train_MSE.result()\n",
    "                #         )\n",
    "                #     )\n",
    "                callbacks.on_train_batch_end(batch, logs=logs)\n",
    "                callbacks.on_batch_end(batch, logs=logs)\n",
    "            # End epoch 每个epoch\n",
    "            train_loss_results.append(train_loss.result())\n",
    "\n",
    "            val_loss.reset_states()\n",
    "            val_MSE.reset_states()\n",
    "            for batch_data in dataset_val:\n",
    "                callbacks.on_batch_begin(batch, logs=logs)\n",
    "                callbacks.on_test_batch_begin(batch, logs=logs)\n",
    "                test_step(batch_data)\n",
    "                callbacks.on_test_batch_end(batch, logs=logs)\n",
    "                callbacks.on_batch_end(batch, logs=logs)\n",
    "\n",
    "            logs[\"val_loss\"] = val_loss.result()\n",
    "            logs[\"val_MSE\"] = val_MSE.result()\n",
    "            # --------------------\n",
    "            # The early stopping strategy: stop the training if `val_loss` does not\n",
    "            # decrease over a certain number of epochs.\n",
    "            #             wait += 1\n",
    "            #             if (\n",
    "            #                 val_loss.result() < best\n",
    "            #             ):  # 当loss变小,在改进时,计数器恢复为0,存储模型,实现总是存储最佳模型; 当n次loss不再变小,即触发\n",
    "            #                 best = val_loss.result()\n",
    "            #                 wait = 0\n",
    "\n",
    "            #                 ckpt_save_path = ckpt_manager.save()  # 存weight\n",
    "            #                 # print(\"Saving checkpoint for epoch {} at {}\".format(epoch + 1, ckpt_save_path))\n",
    "            #             if wait >= patience:\n",
    "            #                 print(\n",
    "            #                     \"\\nepoch:{}/{} - 共耗时:{:.2f}分,历{}次训练未见val_loss减少,故提前中止\".format(\n",
    "            #                         epoch + 1, EPOCHS, (time.time() - train_start) / 60, patience\n",
    "            #                     )\n",
    "            #                 )\n",
    "            #                 break\n",
    "            # --------------------\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:  # 每n次epoch,打印\n",
    "\n",
    "                print(\n",
    "                    \"\\nepoch:{}/{} - 耗时:{:.2f}分/总{:.2f}分; train_loss {:.4f} train_MSE {:.4f}; val_loss {:.4f} val_MSE {:.4f}\".format(\n",
    "                        epoch + 1,\n",
    "                        EPOCHS,\n",
    "                        (time.time() - epoch_start) / 60,\n",
    "                        (time.time() - train_start) / 60,\n",
    "                        train_loss.result(),\n",
    "                        train_MSE.result(),\n",
    "                        val_loss.result(),\n",
    "                        val_MSE.result(),\n",
    "                    )\n",
    "                )\n",
    "            # print(\"Time taken for 1 epoch: {} mins\\n\".format((time.time() - start) / 60))\n",
    "            best = min(\n",
    "                best, float(logs[\"val_loss\"])\n",
    "            )  # 取最小的val_loss,val_loss需要转换成float数,才能被tunner接受\n",
    "            callbacks.on_epoch_end(epoch, logs=logs)\n",
    "        callbacks.on_train_end(logs=logs)\n",
    "        print(\n",
    "            \"\\nepoch:{}/{} - 共耗时:{:.2f}分,正常结束\".format(\n",
    "                epoch + 1, EPOCHS, (time.time() - train_start) / 60\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a40bd-9d97-4a5c-adf9-803620bd4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    hypermodel=HypermodelSpace(),\n",
    "    objective=kt.Objective(\"val_loss\", \"min\"),\n",
    "    max_epochs=20,\n",
    "    directory=\"Tunner_result\",\n",
    "    project_name=\"custom_training\",\n",
    "    overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79c03f-4c65-4abc-9a3e-557873ccb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行超参数搜索\n",
    "\n",
    "start = time.time()\n",
    "tuner.search(\n",
    "    # inputs_train,\n",
    "    epochs=20,\n",
    "    # validation_data= inputs_val,\n",
    "    # callbacks=callbacks, #callbacks是个objects,而这里必须是可以copy.deepcopy. callbacklists对象不能深度复制\n",
    ")\n",
    "end = time.time()\n",
    "print(\"共耗时{:.3f}分钟\".format((end - start) / 60))\n",
    "\n",
    "# 在Docker上运行时,用于JupyterLab上自动关闭租用连接:\n",
    "# import os\n",
    "# 若释放前要保存环境并命名为 SnapName\n",
    "# os.system(\"export $(cat /proc/1/environ |tr '\\\\0' '\\\\n' | grep MATCLOUD_CANCELTOKEN)&&/public/script/matncli node cancel -url https://matpool.com/api/public/node -save -name snapName\")\n",
    "# 若释放前不需要保存环境\n",
    "# os.system(\"export $(cat /proc/1/environ |tr '\\\\0' '\\\\n' | grep MATCLOUD_CANCELTOKEN)&&/public/script/matncli node cancel -url https://matpool.com/api/public/node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed09a44-e013-4c05-ac3c-1d6d72e54805",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=7)\n",
    "for i in range(7):\n",
    "    print(best_hps[i].values)\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fce86-cce0-44c6-9368-62cb6af93d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
